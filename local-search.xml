<?xml version="1.0" encoding="utf-8"?>
<search>
  
  
  
  <entry>
    <title>[技术笔记]实例：将上市公司数据合并</title>
    <link href="/2021/05/02/%E6%8A%80%E6%9C%AF%E7%AC%94%E8%AE%B0-%E5%AE%9E%E4%BE%8B%EF%BC%9A%E5%B0%86%E4%B8%8A%E5%B8%82%E5%85%AC%E5%8F%B8%E6%95%B0%E6%8D%AE%E5%90%88%E5%B9%B6/"/>
    <url>/2021/05/02/%E6%8A%80%E6%9C%AF%E7%AC%94%E8%AE%B0-%E5%AE%9E%E4%BE%8B%EF%BC%9A%E5%B0%86%E4%B8%8A%E5%B8%82%E5%85%AC%E5%8F%B8%E6%95%B0%E6%8D%AE%E5%90%88%E5%B9%B6/</url>
    
    <content type="html"><![CDATA[<h2 id="上市公司数据合并"><a href="#上市公司数据合并" class="headerlink" title="上市公司数据合并"></a>上市公司数据合并</h2><h3 id="需求描述"><a href="#需求描述" class="headerlink" title="需求描述"></a>需求描述</h3><p>写论文需要2010-2020年间所有上市公司的资产总额、产权性质、营业收入增长率、ROA、公司规模、资产负债率、综合杠杆等数据，目前数据已通过CSMAR下载完毕。现存在的问题是：</p><ol><li>各项指标都是分割的，需要用python进行整合；</li><li>部分指标存在缺失值，需要根据缺失值的具体情况判断是直接赋予一个NAN还是另行赋值；</li><li>对异常值需进行winsorize处理（该部分可以在stata中完成，另议）；</li><li>需根据行业代码去除所有金融类上市公司；</li><li>根据公司名称去除ST、*ST等连续亏损公司。</li></ol><h3 id="功能实现"><a href="#功能实现" class="headerlink" title="功能实现"></a>功能实现</h3><p>话不多说，直接开始。</p><h4 id="合并工作"><a href="#合并工作" class="headerlink" title="合并工作"></a>合并工作</h4><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br></pre></td><td class="code"><pre><code class="hljs python"><span class="hljs-keyword">import</span> pandas <span class="hljs-keyword">as</span> pd<br><span class="hljs-comment">#首先将所有要合并的数据写入内存</span><br>fa = pd.read_excel(<span class="hljs-string">r'C:\Users\wanton\Desktop\论文写作\资产负债表\资产数据.xlsx'</span>)<br>equ = pd.read_excel(<span class="hljs-string">r'C:\Users\wanton\Desktop\论文写作\产权性质\equ.xlsx'</span>)<br>roa = pd.read_excel(<span class="hljs-string">r'C:\Users\wanton\Desktop\论文写作\ROA\ROA.xlsx'</span>)<br>growth = pd.read_excel(<span class="hljs-string">r'C:\Users\wanton\Desktop\论文写作\营业收入增长率\growth.xlsx'</span>)<br>lev = pd.read_excel(<span class="hljs-string">r'C:\Users\wanton\Desktop\论文写作\资产负债率\lev.xlsx'</span>)<br>leverage = pd.read_excel(<span class="hljs-string">r'C:\Users\wanton\Desktop\论文写作\综合杠杆\leverage.xlsx'</span>)<br><br><span class="hljs-comment">#先处理历史遗留问题，把fa里面的证券代码转成str</span><br>fa[<span class="hljs-string">'股票代码'</span>].fillna(method=<span class="hljs-string">'pad'</span>, inplace=<span class="hljs-literal">True</span>)<br>fa[<span class="hljs-string">'股票代码'</span>] = fa[<span class="hljs-string">'股票代码'</span>].astype(<span class="hljs-string">'int'</span>)<br>fa[<span class="hljs-string">'股票代码'</span>] = fa[<span class="hljs-string">'股票代码'</span>].astype(<span class="hljs-string">'str'</span>)<br><br><span class="hljs-comment">#使用merge函数，以股票代码和截止日期为主键将roa和fa合并，其他同理</span><br>roa[<span class="hljs-string">'股票代码'</span>] = roa[<span class="hljs-string">'股票代码'</span>].astype(<span class="hljs-string">'str'</span>)<br>x1 = pd.merge(fa,roa, on=[<span class="hljs-string">'股票代码'</span>,<span class="hljs-string">'截止日期'</span>], how=<span class="hljs-string">'inner'</span>)<br>growth[<span class="hljs-string">'股票代码'</span>] = growth[<span class="hljs-string">'股票代码'</span>].astype(<span class="hljs-string">'str'</span>)<br>x2 = pd.merge(x1,growth, how=<span class="hljs-string">'inner'</span>)<br>lev[<span class="hljs-string">'股票代码'</span>] = lev[<span class="hljs-string">'股票代码'</span>].astype(<span class="hljs-string">'str'</span>)<br>x3 = pd.merge(x2,lev, how=<span class="hljs-string">'inner'</span>)<br>leverage[<span class="hljs-string">'股票代码'</span>] = leverage[<span class="hljs-string">'股票代码'</span>].astype(<span class="hljs-string">'str'</span>)<br>x4 = pd.merge(x3,leverage, how=<span class="hljs-string">'inner'</span>)<br>x4.info() <span class="hljs-comment">#查看可得共有109530行，与上市公司数*季度数基本吻合，说明数据处理应该没有问题</span><br></code></pre></td></tr></table></figure><h4 id="一个小难点：产权性质的合并"><a href="#一个小难点：产权性质的合并" class="headerlink" title="一个小难点：产权性质的合并"></a>一个小难点：产权性质的合并</h4><p>下面要进行产权性质equ的合并，但问题是：CSMAR中获得的数据是每年12月31号的，需要将该数据扩充到3-31，6-30，9-30。并且产权性质不是不变的，就是因为其会改变，所以不能按照一对多的索引来用merge函数，必须将其扩充到一对一。</p><p>我想到的解决方法是：首先使用to_datetime将截止日期都改成年度时间格式，然后用重采样提高其频率至每一季度，其中使用pad()方法填充缺失值，理论上应该可以完成任务。</p><p>下面开始实践：</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br></pre></td><td class="code"><pre><code class="hljs python">equ[<span class="hljs-string">'截至日期'</span>] = equ[<span class="hljs-string">'截至日期'</span>].str.split(<span class="hljs-string">'-'</span>).str.get(<span class="hljs-number">0</span>) <span class="hljs-comment">#按照‘-’拆分日期，保留得到的拆分数组中的第一个数（即年份）</span><br>equ[<span class="hljs-string">'截至日期'</span>] = pd.to_datetime(equ[<span class="hljs-string">'截止日期'</span>], format=<span class="hljs-string">'%Y'</span>) <span class="hljs-comment">#转换成datetime格式</span><br><br><span class="hljs-comment">#先对股权性质编码进行处理，去除缺失值，将（2，3）这样的多值改为单值并转化为int，再以虚拟变量形式赋值</span><br>equ[<span class="hljs-string">'股权性质编码'</span>]= equ[<span class="hljs-string">'股权性质编码'</span>].str.split(<span class="hljs-string">','</span>).str.get(<span class="hljs-number">0</span>)<br>equ = equ.dropna()<br>equ[<span class="hljs-string">'股权性质编码'</span>] = equ[<span class="hljs-string">'股权性质编码'</span>].astype(<span class="hljs-string">'int'</span>)<br>equ[<span class="hljs-string">'股权性质编码'</span>].map(<span class="hljs-keyword">lambda</span> x: <span class="hljs-number">1</span> <span class="hljs-keyword">if</span> x == <span class="hljs-number">1</span> <span class="hljs-keyword">else</span> <span class="hljs-number">0</span>)<br>equ[<span class="hljs-string">'股权性质编码'</span>] = equ[<span class="hljs-string">'股权性质编码'</span>].map(<span class="hljs-keyword">lambda</span> x: <span class="hljs-number">1</span> <span class="hljs-keyword">if</span> x == <span class="hljs-number">1</span> <span class="hljs-keyword">else</span> <span class="hljs-number">0</span>)<br></code></pre></td></tr></table></figure><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><code class="hljs python">equ.resample(<span class="hljs-string">'Q'</span>).pad()<br></code></pre></td></tr></table></figure><p>兴致冲冲使用了上述方法，结果报错：<strong>ValueError: cannot reindex a non-unique index with a method or limit</strong></p><p>网上查了一下，类似的错误其原因是：<strong>An index needs to be unique. Your first record and third record have the same date ‘5/1/2017’ which makes it is impossible to set the date column as a index column.</strong></p><p>就是说<strong>重采样中不能有相同的日期，每一个日期都应该是独一无二的</strong>，但在我的数据里，每一个公司为一个簇类，就有好多相同的值…心态崩了…得另作他法。</p><p>重新翻了翻python的书，想到了另一个方法：<strong>用时间序列的移动（shifting）方法来构造前3个月、6个月、9个月的数据。</strong>然后用concat将其拼接。</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br></pre></td><td class="code"><pre><code class="hljs python">equ = equ.set_index(<span class="hljs-string">'截止日期'</span>)<br><span class="hljs-comment">#数据相同，但移动日期</span><br>equ9 = equ.shift(<span class="hljs-number">-3</span>, freq=<span class="hljs-string">'M'</span>)<br>equ6 = equ.shift(<span class="hljs-number">-6</span>, freq=<span class="hljs-string">'M'</span>)<br>equ3 = equ.shift(<span class="hljs-number">-9</span>, freq=<span class="hljs-string">'M'</span>)<br><span class="hljs-comment">#拼接</span><br>frame = pd.concat([equ3,equ6,equ9,equ], axis=<span class="hljs-number">0</span>)<br>frame = frame.reset_index()<br>frame[<span class="hljs-string">'截止日期'</span>] = frame[<span class="hljs-string">'截止日期'</span>].astype(<span class="hljs-string">'str'</span>)<br></code></pre></td></tr></table></figure><h4 id="最后一步：删除金融公司及亏损公司"><a href="#最后一步：删除金融公司及亏损公司" class="headerlink" title="最后一步：删除金融公司及亏损公司"></a>最后一步：删除金融公司及亏损公司</h4><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><code class="hljs python">x5 = pd.merge(x4,frame, how=<span class="hljs-string">'inner'</span>)<br>x5 = x5[~x5[<span class="hljs-string">'证券简称'</span>].str.contains(<span class="hljs-string">'ST'</span>)]<br>x5 = x5[~x5[<span class="hljs-string">'行业代码'</span>].str.contains(<span class="hljs-string">'J'</span>)] <span class="hljs-comment">#按照证监会标准，金融类公司的代码是J66-69</span><br><span class="hljs-comment">#大功告成，输出文档！</span><br>x5.to_excel(<span class="hljs-string">r'C:\Users\wanton\Desktop\论文写作\处理过的数据（全）.xlsx'</span>)<br></code></pre></td></tr></table></figure><h3 id="总结"><a href="#总结" class="headerlink" title="总结"></a>总结</h3><p>上述过程中可能存在部分代码未列出，如有疑问请直接联系笔者。</p>]]></content>
    
    
    <categories>
      
      <category>技术笔记</category>
      
      <category>python</category>
      
    </categories>
    
    
    <tags>
      
      <tag>数据清洗</tag>
      
    </tags>
    
  </entry>
  
  
  
  <entry>
    <title>[技术笔记]使用重采样将月度数据改为季度数据</title>
    <link href="/2021/04/25/%E6%8A%80%E6%9C%AF%E7%AC%94%E8%AE%B0-%E4%BD%BF%E7%94%A8%E9%87%8D%E9%87%87%E6%A0%B7%E5%B0%86%E6%9C%88%E5%BA%A6%E6%95%B0%E6%8D%AE%E6%94%B9%E4%B8%BA%E5%AD%A3%E5%BA%A6%E6%95%B0%E6%8D%AE/"/>
    <url>/2021/04/25/%E6%8A%80%E6%9C%AF%E7%AC%94%E8%AE%B0-%E4%BD%BF%E7%94%A8%E9%87%8D%E9%87%87%E6%A0%B7%E5%B0%86%E6%9C%88%E5%BA%A6%E6%95%B0%E6%8D%AE%E6%94%B9%E4%B8%BA%E5%AD%A3%E5%BA%A6%E6%95%B0%E6%8D%AE/</url>
    
    <content type="html"><![CDATA[<h2 id="使用重采样功能将月度数据改为季度数据"><a href="#使用重采样功能将月度数据改为季度数据" class="headerlink" title="使用重采样功能将月度数据改为季度数据"></a>使用重采样功能将月度数据改为季度数据</h2><h3 id="需求描述"><a href="#需求描述" class="headerlink" title="需求描述"></a>需求描述</h3><p>在国家统计局下载了2010-2020年每个月的CPI数据，而我想得到CPI的季度数据，因此需要使用公式</p><script type="math/tex; mode=display">CPI_{Season}=CPI_{Month1}*CPI_{Month2}*CPI_{Month3}</script><p>首先将三个月的数据改为季度数据再进行操作。</p><h3 id="功能实现"><a href="#功能实现" class="headerlink" title="功能实现"></a>功能实现</h3><p>Pandas对于时间序列数据有专门的优化和公式（如果我没记错的话，pandas的创始人就是搞金融量化的），此处可以使用重采样函数<strong><em>resample()</em></strong>来实现不同频率间时间的转化。该函数类似与<strong><em>Groupby()</em></strong>，都是将一个DataFrame按照某种规律进行再分组，只不过重采样是特别针对时间的。</p><p>具体操作如下：</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br></pre></td><td class="code"><pre><code class="hljs python"><span class="hljs-keyword">import</span> pandas <span class="hljs-keyword">as</span> pd<br>df = pd.read_csv(<span class="hljs-string">r'C:\Users\wanton\Desktop\论文写作\2010-2020CPI.xlsx'</span>)<br><span class="hljs-comment">#首先将日期列改为时间序列数据，再应用于resample函数</span><br>df[<span class="hljs-string">'Time'</span>] = pd.to_datetime(df[<span class="hljs-string">'Time'</span>])<br>df_new = df.resample(<span class="hljs-string">'Q'</span>, on=<span class="hljs-string">'Time'</span>).prod() <span class="hljs-comment">#应用于‘Time’列并改为连乘数据</span><br><span class="hljs-comment">#保存数据</span><br>df_new.to_excel(<span class="hljs-string">r'C:\Users\wanton\Desktop\论文写作\处理过的CPI.xlsx'</span>)<br></code></pre></td></tr></table></figure>]]></content>
    
    
    <categories>
      
      <category>技术笔记</category>
      
      <category>python</category>
      
    </categories>
    
    
    <tags>
      
      <tag>重采样</tag>
      
    </tags>
    
  </entry>
  
  
  
  <entry>
    <title>[学习笔记]概率论与数理统计复习（含pdf）</title>
    <link href="/2021/04/12/%E5%AD%A6%E4%B9%A0%E7%AC%94%E8%AE%B0-%E6%A6%82%E7%8E%87%E8%AE%BA%E4%B8%8E%E6%95%B0%E7%90%86%E7%BB%9F%E8%AE%A1%E5%A4%8D%E4%B9%A0%EF%BC%88%E5%90%ABpdf%EF%BC%89/"/>
    <url>/2021/04/12/%E5%AD%A6%E4%B9%A0%E7%AC%94%E8%AE%B0-%E6%A6%82%E7%8E%87%E8%AE%BA%E4%B8%8E%E6%95%B0%E7%90%86%E7%BB%9F%E8%AE%A1%E5%A4%8D%E4%B9%A0%EF%BC%88%E5%90%ABpdf%EF%BC%89/</url>
    
    <content type="html"><![CDATA[<p>终于学会了如何在hexo上传pdf，于是数学笔记可以以pdf形式上传了！这是属于懒惰党的胜利！（话说hexo这个静态体系太折磨了，各种问题+上传麻烦，等有空了考虑换个体系了。</p><object data="./概率论与数理统计.pdf" type="application/pdf" width="100%" height="877px"></object>]]></content>
    
    
    <categories>
      
      <category>学习笔记</category>
      
      <category>数学</category>
      
    </categories>
    
    
    <tags>
      
      <tag>概率论</tag>
      
    </tags>
    
  </entry>
  
  
  
  <entry>
    <title>[学习笔记]无穷级数</title>
    <link href="/2021/03/30/%E5%AD%A6%E4%B9%A0%E7%AC%94%E8%AE%B0-%E6%97%A0%E7%A9%B7%E7%BA%A7%E6%95%B0/"/>
    <url>/2021/03/30/%E5%AD%A6%E4%B9%A0%E7%AC%94%E8%AE%B0-%E6%97%A0%E7%A9%B7%E7%BA%A7%E6%95%B0/</url>
    
    <content type="html"><![CDATA[<p><img src="/2021/03/30/%E5%AD%A6%E4%B9%A0%E7%AC%94%E8%AE%B0-%E6%97%A0%E7%A9%B7%E7%BA%A7%E6%95%B0/1.jpg" srcset="/img/loading.gif" alt></p><p><img src="/2021/03/30/%E5%AD%A6%E4%B9%A0%E7%AC%94%E8%AE%B0-%E6%97%A0%E7%A9%B7%E7%BA%A7%E6%95%B0/2.jpg" srcset="/img/loading.gif" alt><br><img src="/2021/03/30/%E5%AD%A6%E4%B9%A0%E7%AC%94%E8%AE%B0-%E6%97%A0%E7%A9%B7%E7%BA%A7%E6%95%B0/3.jpg" srcset="/img/loading.gif" alt><br><img src="/2021/03/30/%E5%AD%A6%E4%B9%A0%E7%AC%94%E8%AE%B0-%E6%97%A0%E7%A9%B7%E7%BA%A7%E6%95%B0/4.jpg" srcset="/img/loading.gif" alt></p>]]></content>
    
    
    <categories>
      
      <category>学习笔记</category>
      
      <category>数学</category>
      
    </categories>
    
    
    <tags>
      
      <tag>高等数学</tag>
      
    </tags>
    
  </entry>
  
  
  
  <entry>
    <title>[学习笔记]关于新古典分配理论和柯布-道格拉斯函数的一点思考</title>
    <link href="/2021/03/25/%E5%AD%A6%E4%B9%A0%E7%AC%94%E8%AE%B0-%E5%85%B3%E4%BA%8E%E6%96%B0%E5%8F%A4%E5%85%B8%E5%88%86%E9%85%8D%E7%90%86%E8%AE%BA%E5%92%8C%E6%9F%AF%E5%B8%83-%E9%81%93%E6%A0%BC%E6%8B%89%E6%96%AF%E5%87%BD%E6%95%B0%E7%9A%84%E4%B8%80%E7%82%B9%E6%80%9D%E8%80%83/"/>
    <url>/2021/03/25/%E5%AD%A6%E4%B9%A0%E7%AC%94%E8%AE%B0-%E5%85%B3%E4%BA%8E%E6%96%B0%E5%8F%A4%E5%85%B8%E5%88%86%E9%85%8D%E7%90%86%E8%AE%BA%E5%92%8C%E6%9F%AF%E5%B8%83-%E9%81%93%E6%A0%BC%E6%8B%89%E6%96%AF%E5%87%BD%E6%95%B0%E7%9A%84%E4%B8%80%E7%82%B9%E6%80%9D%E8%80%83/</url>
    
    <content type="html"><![CDATA[<p>今天看了中宏的新古典分配理论，讲到国民收入会分配到劳动回报和资本回报这两项上，联想之前看到清华大学汪小涓教授讲的鲍莫尔定理：服务业的低效会拖慢整体经济的发展，因为这其中存在部门间的工资平均化。</p><script type="math/tex; mode=display">F(K,L)=MPL*L+MPK*K</script><p>既然此处涉及到收入分配，我就在想是否可以用这个模型解释鲍莫尔定理。正思索着，就看到了柯布-道格拉斯函数：这是保罗·道格拉斯（Paul Douglas）与查尔斯·柯布（Charles Cobb）发现的一个事实，即从美国经济的实证研究上来看，<strong>国民收入在劳动力和资本间的分配在长时间内大体不变</strong>。从数学上来看是这样的：</p><script type="math/tex; mode=display">MPL*L=(1-\alpha)*Y\\MPK*K=\alpha*Y</script><p>与这两项生产要素的生产效率无关，只和一个参数alpha有关，所以常年来两者间的分配比例基本不变——一个分配到alpha%的收入，另一个分配到1-alpha%的收入。明明在以前的学习中经常看到k-b函数，却从来没有去深想为什么，为什么每年分配的比例都是固定的呢？为什么和劳动力、资本两者的生产效率毫无关系？直觉上讲肯定是哪个要素生产效率高，哪个要素能获得更多的回报。</p><p>现在好像有点明白了（虽然最终的逻辑推导仍然可能是错的），这不就是侧面体现了鲍莫尔定理吗——虽然劳动力的生产效率低，但其是必要的存在，所以要求生产效率高的资本给予劳动力一定的补偿，导致收入在两者间的分配比例基本不变。</p><p>到了大三下才感觉自己学的东西有点用，不是学了=不如电子厂上班了，知识间产生关联的感觉太好</p>]]></content>
    
    
    <categories>
      
      <category>学习笔记</category>
      
      <category>经济学</category>
      
    </categories>
    
    
    <tags>
      
      <tag>柯布-道格拉斯函数</tag>
      
    </tags>
    
  </entry>
  
  
  
  <entry>
    <title>[学习笔记]多元函数微分学与二重积分</title>
    <link href="/2021/03/20/%E5%AD%A6%E4%B9%A0%E7%AC%94%E8%AE%B0-%E5%A4%9A%E5%85%83%E5%87%BD%E6%95%B0%E5%BE%AE%E5%88%86%E5%AD%A6/"/>
    <url>/2021/03/20/%E5%AD%A6%E4%B9%A0%E7%AC%94%E8%AE%B0-%E5%A4%9A%E5%85%83%E5%87%BD%E6%95%B0%E5%BE%AE%E5%88%86%E5%AD%A6/</url>
    
    <content type="html"><![CDATA[<p><img src="/2021/03/20/%E5%AD%A6%E4%B9%A0%E7%AC%94%E8%AE%B0-%E5%A4%9A%E5%85%83%E5%87%BD%E6%95%B0%E5%BE%AE%E5%88%86%E5%AD%A6/1.jpg" srcset="/img/loading.gif" alt></p><p><img src="/2021/03/20/%E5%AD%A6%E4%B9%A0%E7%AC%94%E8%AE%B0-%E5%A4%9A%E5%85%83%E5%87%BD%E6%95%B0%E5%BE%AE%E5%88%86%E5%AD%A6/2.jpg" srcset="/img/loading.gif" alt><br><img src="/2021/03/20/%E5%AD%A6%E4%B9%A0%E7%AC%94%E8%AE%B0-%E5%A4%9A%E5%85%83%E5%87%BD%E6%95%B0%E5%BE%AE%E5%88%86%E5%AD%A6/3.jpg" srcset="/img/loading.gif" alt><br><img src="/2021/03/20/%E5%AD%A6%E4%B9%A0%E7%AC%94%E8%AE%B0-%E5%A4%9A%E5%85%83%E5%87%BD%E6%95%B0%E5%BE%AE%E5%88%86%E5%AD%A6/4.jpg" srcset="/img/loading.gif" alt><br><img src="/2021/03/20/%E5%AD%A6%E4%B9%A0%E7%AC%94%E8%AE%B0-%E5%A4%9A%E5%85%83%E5%87%BD%E6%95%B0%E5%BE%AE%E5%88%86%E5%AD%A6/5.jpg" srcset="/img/loading.gif" alt></p>]]></content>
    
    
    <categories>
      
      <category>学习笔记</category>
      
      <category>数学</category>
      
    </categories>
    
    
    <tags>
      
      <tag>高等数学</tag>
      
    </tags>
    
  </entry>
  
  
  
  <entry>
    <title>[学习笔记]一元函数积分学的概念与计算</title>
    <link href="/2021/03/18/%E5%AD%A6%E4%B9%A0%E7%AC%94%E8%AE%B0-%E4%B8%80%E5%85%83%E5%87%BD%E6%95%B0%E7%A7%AF%E5%88%86%E5%AD%A6%E7%9A%84%E6%A6%82%E5%BF%B5%E4%B8%8E%E8%AE%A1%E7%AE%97/"/>
    <url>/2021/03/18/%E5%AD%A6%E4%B9%A0%E7%AC%94%E8%AE%B0-%E4%B8%80%E5%85%83%E5%87%BD%E6%95%B0%E7%A7%AF%E5%88%86%E5%AD%A6%E7%9A%84%E6%A6%82%E5%BF%B5%E4%B8%8E%E8%AE%A1%E7%AE%97/</url>
    
    <content type="html"><![CDATA[<p><img src="/2021/03/18/%E5%AD%A6%E4%B9%A0%E7%AC%94%E8%AE%B0-%E4%B8%80%E5%85%83%E5%87%BD%E6%95%B0%E7%A7%AF%E5%88%86%E5%AD%A6%E7%9A%84%E6%A6%82%E5%BF%B5%E4%B8%8E%E8%AE%A1%E7%AE%97/1.jpg" srcset="/img/loading.gif" alt></p><p><img src="/2021/03/18/%E5%AD%A6%E4%B9%A0%E7%AC%94%E8%AE%B0-%E4%B8%80%E5%85%83%E5%87%BD%E6%95%B0%E7%A7%AF%E5%88%86%E5%AD%A6%E7%9A%84%E6%A6%82%E5%BF%B5%E4%B8%8E%E8%AE%A1%E7%AE%97/2.jpg" srcset="/img/loading.gif" alt></p><p><img src="/2021/03/18/%E5%AD%A6%E4%B9%A0%E7%AC%94%E8%AE%B0-%E4%B8%80%E5%85%83%E5%87%BD%E6%95%B0%E7%A7%AF%E5%88%86%E5%AD%A6%E7%9A%84%E6%A6%82%E5%BF%B5%E4%B8%8E%E8%AE%A1%E7%AE%97/3.jpg" srcset="/img/loading.gif" alt></p><p><img src="/2021/03/18/%E5%AD%A6%E4%B9%A0%E7%AC%94%E8%AE%B0-%E4%B8%80%E5%85%83%E5%87%BD%E6%95%B0%E7%A7%AF%E5%88%86%E5%AD%A6%E7%9A%84%E6%A6%82%E5%BF%B5%E4%B8%8E%E8%AE%A1%E7%AE%97/4.jpg" srcset="/img/loading.gif" alt></p>]]></content>
    
    
    <categories>
      
      <category>学习笔记</category>
      
      <category>数学</category>
      
    </categories>
    
    
    <tags>
      
      <tag>高等数学</tag>
      
    </tags>
    
  </entry>
  
  
  
  <entry>
    <title>[学习笔记]中值定理</title>
    <link href="/2021/03/17/%E5%AD%A6%E4%B9%A0%E7%AC%94%E8%AE%B0-%E4%B8%AD%E5%80%BC%E5%AE%9A%E7%90%86/"/>
    <url>/2021/03/17/%E5%AD%A6%E4%B9%A0%E7%AC%94%E8%AE%B0-%E4%B8%AD%E5%80%BC%E5%AE%9A%E7%90%86/</url>
    
    <content type="html"><![CDATA[<p><img src="/2021/03/17/%E5%AD%A6%E4%B9%A0%E7%AC%94%E8%AE%B0-%E4%B8%AD%E5%80%BC%E5%AE%9A%E7%90%86/1.jpg" srcset="/img/loading.gif" alt></p><p><img src="/2021/03/17/%E5%AD%A6%E4%B9%A0%E7%AC%94%E8%AE%B0-%E4%B8%AD%E5%80%BC%E5%AE%9A%E7%90%86/2.jpg" srcset="/img/loading.gif" alt></p>]]></content>
    
    
    <categories>
      
      <category>学习笔记</category>
      
      <category>数学</category>
      
    </categories>
    
    
    <tags>
      
      <tag>高等数学</tag>
      
    </tags>
    
  </entry>
  
  
  
  <entry>
    <title>[学习笔记]一元函数微分学的几何应用</title>
    <link href="/2021/03/16/%E5%AD%A6%E4%B9%A0%E7%AC%94%E8%AE%B0-%E4%B8%80%E5%85%83%E5%87%BD%E6%95%B0%E5%BE%AE%E5%88%86%E5%AD%A6%E7%9A%84%E5%87%A0%E4%BD%95%E5%BA%94%E7%94%A8/"/>
    <url>/2021/03/16/%E5%AD%A6%E4%B9%A0%E7%AC%94%E8%AE%B0-%E4%B8%80%E5%85%83%E5%87%BD%E6%95%B0%E5%BE%AE%E5%88%86%E5%AD%A6%E7%9A%84%E5%87%A0%E4%BD%95%E5%BA%94%E7%94%A8/</url>
    
    <content type="html"><![CDATA[<p><img src="/2021/03/16/%E5%AD%A6%E4%B9%A0%E7%AC%94%E8%AE%B0-%E4%B8%80%E5%85%83%E5%87%BD%E6%95%B0%E5%BE%AE%E5%88%86%E5%AD%A6%E7%9A%84%E5%87%A0%E4%BD%95%E5%BA%94%E7%94%A8/1.jpg" srcset="/img/loading.gif" alt></p><p><img src="/2021/03/16/%E5%AD%A6%E4%B9%A0%E7%AC%94%E8%AE%B0-%E4%B8%80%E5%85%83%E5%87%BD%E6%95%B0%E5%BE%AE%E5%88%86%E5%AD%A6%E7%9A%84%E5%87%A0%E4%BD%95%E5%BA%94%E7%94%A8/2.jpg" srcset="/img/loading.gif" alt></p>]]></content>
    
    
    <categories>
      
      <category>学习笔记</category>
      
      <category>数学</category>
      
    </categories>
    
    
    <tags>
      
      <tag>高等数学</tag>
      
    </tags>
    
  </entry>
  
  
  
  <entry>
    <title>[学习笔记]一元函数微分学的概念与计算</title>
    <link href="/2021/03/15/%E5%AD%A6%E4%B9%A0%E7%AC%94%E8%AE%B0-%E4%B8%80%E5%85%83%E5%87%BD%E6%95%B0%E5%BE%AE%E5%88%86%E5%AD%A6%E7%9A%84%E6%A6%82%E5%BF%B5%E4%B8%8E%E8%AE%A1%E7%AE%97/"/>
    <url>/2021/03/15/%E5%AD%A6%E4%B9%A0%E7%AC%94%E8%AE%B0-%E4%B8%80%E5%85%83%E5%87%BD%E6%95%B0%E5%BE%AE%E5%88%86%E5%AD%A6%E7%9A%84%E6%A6%82%E5%BF%B5%E4%B8%8E%E8%AE%A1%E7%AE%97/</url>
    
    <content type="html"><![CDATA[<p><img src="/2021/03/15/%E5%AD%A6%E4%B9%A0%E7%AC%94%E8%AE%B0-%E4%B8%80%E5%85%83%E5%87%BD%E6%95%B0%E5%BE%AE%E5%88%86%E5%AD%A6%E7%9A%84%E6%A6%82%E5%BF%B5%E4%B8%8E%E8%AE%A1%E7%AE%97/1.jpg" srcset="/img/loading.gif" alt></p><p><img src="/2021/03/15/%E5%AD%A6%E4%B9%A0%E7%AC%94%E8%AE%B0-%E4%B8%80%E5%85%83%E5%87%BD%E6%95%B0%E5%BE%AE%E5%88%86%E5%AD%A6%E7%9A%84%E6%A6%82%E5%BF%B5%E4%B8%8E%E8%AE%A1%E7%AE%97/2.jpg" srcset="/img/loading.gif" alt></p><p><img src="/2021/03/15/%E5%AD%A6%E4%B9%A0%E7%AC%94%E8%AE%B0-%E4%B8%80%E5%85%83%E5%87%BD%E6%95%B0%E5%BE%AE%E5%88%86%E5%AD%A6%E7%9A%84%E6%A6%82%E5%BF%B5%E4%B8%8E%E8%AE%A1%E7%AE%97/3.jpg" srcset="/img/loading.gif" alt></p><p><img src="/2021/03/15/%E5%AD%A6%E4%B9%A0%E7%AC%94%E8%AE%B0-%E4%B8%80%E5%85%83%E5%87%BD%E6%95%B0%E5%BE%AE%E5%88%86%E5%AD%A6%E7%9A%84%E6%A6%82%E5%BF%B5%E4%B8%8E%E8%AE%A1%E7%AE%97/4.jpg" srcset="/img/loading.gif" alt></p>]]></content>
    
    
    <categories>
      
      <category>学习笔记</category>
      
      <category>数学</category>
      
    </categories>
    
    
    <tags>
      
      <tag>高等数学</tag>
      
    </tags>
    
  </entry>
  
  
  
  <entry>
    <title>[学习笔记]函数极限及连续性</title>
    <link href="/2021/03/12/%E5%AD%A6%E4%B9%A0%E7%AC%94%E8%AE%B0-%E5%87%BD%E6%95%B0%E6%9E%81%E9%99%90%E5%8F%8A%E8%BF%9E%E7%BB%AD%E6%80%A7/"/>
    <url>/2021/03/12/%E5%AD%A6%E4%B9%A0%E7%AC%94%E8%AE%B0-%E5%87%BD%E6%95%B0%E6%9E%81%E9%99%90%E5%8F%8A%E8%BF%9E%E7%BB%AD%E6%80%A7/</url>
    
    <content type="html"><![CDATA[<p><img src="/2021/03/12/%E5%AD%A6%E4%B9%A0%E7%AC%94%E8%AE%B0-%E5%87%BD%E6%95%B0%E6%9E%81%E9%99%90%E5%8F%8A%E8%BF%9E%E7%BB%AD%E6%80%A7/1.jpg" srcset="/img/loading.gif" alt></p><p><img src="/2021/03/12/%E5%AD%A6%E4%B9%A0%E7%AC%94%E8%AE%B0-%E5%87%BD%E6%95%B0%E6%9E%81%E9%99%90%E5%8F%8A%E8%BF%9E%E7%BB%AD%E6%80%A7/2.jpg" srcset="/img/loading.gif" alt></p><p><img src="/2021/03/12/%E5%AD%A6%E4%B9%A0%E7%AC%94%E8%AE%B0-%E5%87%BD%E6%95%B0%E6%9E%81%E9%99%90%E5%8F%8A%E8%BF%9E%E7%BB%AD%E6%80%A7/3.jpg" srcset="/img/loading.gif" alt></p><p><img src="/2021/03/12/%E5%AD%A6%E4%B9%A0%E7%AC%94%E8%AE%B0-%E5%87%BD%E6%95%B0%E6%9E%81%E9%99%90%E5%8F%8A%E8%BF%9E%E7%BB%AD%E6%80%A7/4.jpg" srcset="/img/loading.gif" alt></p><p><img src="/2021/03/12/%E5%AD%A6%E4%B9%A0%E7%AC%94%E8%AE%B0-%E5%87%BD%E6%95%B0%E6%9E%81%E9%99%90%E5%8F%8A%E8%BF%9E%E7%BB%AD%E6%80%A7/5.jpg" srcset="/img/loading.gif" alt></p>]]></content>
    
    
    <categories>
      
      <category>学习笔记</category>
      
      <category>数学</category>
      
    </categories>
    
    
    <tags>
      
      <tag>高等数学</tag>
      
    </tags>
    
  </entry>
  
  
  
  <entry>
    <title>[学习笔记]数列极限</title>
    <link href="/2021/03/12/%E5%AD%A6%E4%B9%A0%E7%AC%94%E8%AE%B0-%E6%95%B0%E5%88%97%E6%9E%81%E9%99%90/"/>
    <url>/2021/03/12/%E5%AD%A6%E4%B9%A0%E7%AC%94%E8%AE%B0-%E6%95%B0%E5%88%97%E6%9E%81%E9%99%90/</url>
    
    <content type="html"><![CDATA[<p><img src="/2021/03/12/%E5%AD%A6%E4%B9%A0%E7%AC%94%E8%AE%B0-%E6%95%B0%E5%88%97%E6%9E%81%E9%99%90/1.jpg" srcset="/img/loading.gif" alt></p><p><img src="/2021/03/12/%E5%AD%A6%E4%B9%A0%E7%AC%94%E8%AE%B0-%E6%95%B0%E5%88%97%E6%9E%81%E9%99%90/2.jpg" srcset="/img/loading.gif" alt></p>]]></content>
    
    
    <categories>
      
      <category>学习笔记</category>
      
      <category>数学</category>
      
    </categories>
    
    
    <tags>
      
      <tag>高等数学</tag>
      
    </tags>
    
  </entry>
  
  
  
  <entry>
    <title>[学习笔记]高数预备知识</title>
    <link href="/2021/03/10/%E5%AD%A6%E4%B9%A0%E7%AC%94%E8%AE%B0-%E9%AB%98%E6%95%B0%E9%A2%84%E5%A4%87%E7%9F%A5%E8%AF%86/"/>
    <url>/2021/03/10/%E5%AD%A6%E4%B9%A0%E7%AC%94%E8%AE%B0-%E9%AB%98%E6%95%B0%E9%A2%84%E5%A4%87%E7%9F%A5%E8%AF%86/</url>
    
    <content type="html"><![CDATA[<p><img src="/2021/03/10/%E5%AD%A6%E4%B9%A0%E7%AC%94%E8%AE%B0-%E9%AB%98%E6%95%B0%E9%A2%84%E5%A4%87%E7%9F%A5%E8%AF%86/1.jpg" srcset="/img/loading.gif" alt></p><p><img src="/2021/03/10/%E5%AD%A6%E4%B9%A0%E7%AC%94%E8%AE%B0-%E9%AB%98%E6%95%B0%E9%A2%84%E5%A4%87%E7%9F%A5%E8%AF%86/2.jpg" srcset="/img/loading.gif" alt></p><p><img src="/2021/03/10/%E5%AD%A6%E4%B9%A0%E7%AC%94%E8%AE%B0-%E9%AB%98%E6%95%B0%E9%A2%84%E5%A4%87%E7%9F%A5%E8%AF%86/3.jpg" srcset="/img/loading.gif" alt></p><p><img src="/2021/03/10/%E5%AD%A6%E4%B9%A0%E7%AC%94%E8%AE%B0-%E9%AB%98%E6%95%B0%E9%A2%84%E5%A4%87%E7%9F%A5%E8%AF%86/4.jpg" srcset="/img/loading.gif" alt></p><p><img src="/2021/03/10/%E5%AD%A6%E4%B9%A0%E7%AC%94%E8%AE%B0-%E9%AB%98%E6%95%B0%E9%A2%84%E5%A4%87%E7%9F%A5%E8%AF%86/5.jpg" srcset="/img/loading.gif" alt></p>]]></content>
    
    
    <categories>
      
      <category>学习笔记</category>
      
      <category>数学</category>
      
    </categories>
    
    
    <tags>
      
      <tag>高等数学</tag>
      
    </tags>
    
  </entry>
  
  
  
  <entry>
    <title>[学习笔记]美赛的总结与感想：继续出发</title>
    <link href="/2021/02/10/%E5%AD%A6%E4%B9%A0%E7%AC%94%E8%AE%B0-%E7%BE%8E%E8%B5%9B%E7%9A%84%E6%80%BB%E7%BB%93%E4%B8%8E%E6%84%9F%E6%83%B3%EF%BC%9A%E7%BB%A7%E7%BB%AD%E5%87%BA%E5%8F%91/"/>
    <url>/2021/02/10/%E5%AD%A6%E4%B9%A0%E7%AC%94%E8%AE%B0-%E7%BE%8E%E8%B5%9B%E7%9A%84%E6%80%BB%E7%BB%93%E4%B8%8E%E6%84%9F%E6%83%B3%EF%BC%9A%E7%BB%A7%E7%BB%AD%E5%87%BA%E5%8F%91/</url>
    
    <content type="html"><![CDATA[<h2 id="美赛后的一点总结"><a href="#美赛后的一点总结" class="headerlink" title="美赛后的一点总结"></a>美赛后的一点总结</h2><p>2021年的美赛落下帷幕，基本也宣告本科的最后一次数学建模比赛也结束了（大四应该不会再参加了，除非是国赛想再弥补一下遗憾）。其实说来也挺无奈的，为了保研啥的，明明是个经济类专业，还要和数学、统计一类专业的大佬一起竞争数学建模的奖项。国赛因为准备不足，一度很失望，觉得确实比不过其他人，还好亚太赛拿了个二等奖，总算是找回了一些自信，觉得还有些努力的意义。</p><p>不光是数学建模的比赛，创新创业比赛、英语比赛乃至论文，哪一点不是被推着向前呢？因为资源太稀缺了，在中国就是有一种这样的紧迫性，要非常努力，时刻感受着被别人推着向前的压力继续向前。说到这里就想起了之前宏观经济学老师推荐的文章《中国资本积累、私有财产与不平等的增长》，里面写中国的财富不平等程度高于欧洲，但低于美国，因此年轻人想要实现财富的迅速积累，必然就要从原本的一小撮人中“抢”一部分财富，因此竞争自然激烈，乃至到了内卷的程度。</p><p>这是无奈的事实，但它确实也是事实，因此只能面对。还好如今我也算是较为适应这种残忍式地竞争了，也知道不要给自己过多的压力，不要去想不可企及的事情。因此在又一个比赛结束后，也只能对自己说，继续努力吧，再往前走一点，继续出发。</p>]]></content>
    
    
    <categories>
      
      <category>学习笔记</category>
      
      <category>数学建模</category>
      
    </categories>
    
    
    <tags>
      
      <tag>美赛</tag>
      
    </tags>
    
  </entry>
  
  
  
  <entry>
    <title>[技术笔记]SVM常用核函数</title>
    <link href="/2020/10/30/%E6%8A%80%E6%9C%AF%E7%AC%94%E8%AE%B0-SVM%E5%B8%B8%E7%94%A8%E6%A0%B8%E5%87%BD%E6%95%B0/"/>
    <url>/2020/10/30/%E6%8A%80%E6%9C%AF%E7%AC%94%E8%AE%B0-SVM%E5%B8%B8%E7%94%A8%E6%A0%B8%E5%87%BD%E6%95%B0/</url>
    
    <content type="html"><![CDATA[<p>本文转载于<a href="https://blog.csdn.net/yefcion/article/details/81099390" target="_blank" rel="noopener">https://blog.csdn.net/yefcion/article/details/81099390</a></p><p>SVM核函数的选择对于其性能的表现有至关重要的作用，尤其是针对线性不可分的数据。核函数的作用是，通过将空间内线性不可分的数据映射到一个高维的特征空间，使得数据在特征空间内是可分的（动画）。我们定义这种映射为 ϕ(x)，那么我们就可以把求解约束最优化问题变为</p><p>minα−−&gt;12∑Ni=1∑Ni=1αiαjyiyj(ϕi∗ϕj)−∑Ni=1αi<br>s.t.−−&gt;∑Ni=1αiyi=0<br>αi≥0,−−&gt;i=1,2,…,N</p><p>但是由于从输入空间到特征空间的这种映射会使得维度发生爆炸式的增长，因此上述约束问题中内积(\phi_i*\phi_j)的运算会非常的大以至于无法承受，因此通常我们会构造一个核函数κ(xi,xj)=ϕ(xi)∗ϕ(xj)。从而避免了在特征空间内的运算，只需要在输入空间内就可以进行特征空间的内积运算。</p><p>通过上面的描述可知，构造核函数κ首先应确定输入空间到特征空间的映射，想要获取输入空间到映射空间的映射，我们需要明确输入空间内数据的分布情况，但大多数情况下，我们并不知道自己所处理的数据的具体分布，故一般很难构造出完全符合输入空间的核函数，因此我们常用如下几种常用的核函数来代替自己构造核函数：</p><p><strong>线性核函数 LINEAR</strong><br>κ(x,xi)=x∗xi</p><p>线性核，主要用于线性可分的情况。我们可以看到特征空间到输入空间的维度是一样的，其参数少|速度快。对于线性可分数据，其分类效果很理想，因此我们通常首先尝试用线性核函数来做分类，看看效果如何，如果不行再换别的。</p><p><strong>高斯径向基核函数 RBF</strong><br>κ(x,xi)=exp(−||x−xi||2δ2)</p><p>高斯径向基函数是一种局部性强的核函数，其可以将一个样本映射到一个更高维的空间内，该核函数是应用最广的一个，无论大样本还是小样本都有比较好的性能，而且其相对于多项式核函数参数要少，因此大多数情况下在不知道用什么核函数的时候，优先使用高斯核函数。</p><p><strong>多项式核函数 POLY</strong><br>κ(x,xi)=((x∗xi)+1)d</p><p>多项式核函数可以实现将低维的输入空间映射到高纬的特征空间，但是多项式核函数的参数多，当多项式的阶数比较高的时候，核矩阵的元素值将趋于无穷大或者无穷小，计算复杂度会大到无法计算。</p><p><strong>神经元的非线性作用核函数 Sigmoid</strong><br>κ(x,xi)=tanh(η<x,xi>+θ)</x,xi></p><p>采用sigmoid核函数，支持向量机实现的就是一种多层神经网络。</p><p>因此，在选用核函数的时候，如果我们对我们的数据有一定的先验知识，就利用先验来选择符合数据分布的核函数；如果不知道的话，通常使用交叉验证1的方法，来试用不同的核函数，误差最小的即为效果最好的核函数，或者也可以将多个核函数结合起来，形成混合核函数。在吴恩达的课上，也曾经给出过一系列的选择核函数的方法：</p><p>如果特征的数量大到和样本数量差不多，则选用LR或者线性核的SVM；</p><p>如果特征的数量小，样本的数量正常，则选用SVM+高斯核函数；</p><p>如果特征的数量小，而样本的数量很大，则需要手工添加一些特征从而变成第一种情况。</p>]]></content>
    
    
    
  </entry>
  
  
  
  <entry>
    <title>[技术笔记]专题：决策树与随机森林</title>
    <link href="/2020/10/28/%E6%8A%80%E6%9C%AF%E7%AC%94%E8%AE%B0-%E4%B8%93%E9%A2%98%EF%BC%9A%E5%86%B3%E7%AD%96%E6%A0%91%E4%B8%8E%E9%9A%8F%E6%9C%BA%E6%A3%AE%E6%9E%97/"/>
    <url>/2020/10/28/%E6%8A%80%E6%9C%AF%E7%AC%94%E8%AE%B0-%E4%B8%93%E9%A2%98%EF%BC%9A%E5%86%B3%E7%AD%96%E6%A0%91%E4%B8%8E%E9%9A%8F%E6%9C%BA%E6%A3%AE%E6%9E%97/</url>
    
    <content type="html"><![CDATA[<pre><code>import numpy as npimport matplotlib.pyplot as pltimport seaborn as sns; sns.set()%matplotlib inline</code></pre><h2 id="随机森林的诱因：决策树"><a href="#随机森林的诱因：决策树" class="headerlink" title="随机森林的诱因：决策树"></a>随机森林的诱因：决策树</h2><h3 id="创建一课决策树"><a href="#创建一课决策树" class="headerlink" title="创建一课决策树"></a>创建一课决策树</h3><pre><code># 构建一组数据from sklearn.datasets import make_blobsX, y = make_blobs(n_samples=300, centers=4, random_state=0, cluster_std=1)plt.scatter(X[:,0], X[:,1], c=y, s=50, cmap=&#39;rainbow&#39;)plt.savefig(&#39;1.jpg&#39;)</code></pre><p><img src="/2020/10/28/%E6%8A%80%E6%9C%AF%E7%AC%94%E8%AE%B0-%E4%B8%93%E9%A2%98%EF%BC%9A%E5%86%B3%E7%AD%96%E6%A0%91%E4%B8%8E%E9%9A%8F%E6%9C%BA%E6%A3%AE%E6%9E%97/1.jpg" srcset="/img/loading.gif" alt></p><pre><code># 引入决策树模型，写一个辅助函数，对分类器结构进行可视化from sklearn.tree import DecisionTreeClassifier#tree = DecisionTreeClassifier().fit(X,y)def visualize_classifier(model, X, y, ax=None, cmap=&#39;rainbow&#39;):    ax = ax or plt.gca()  # gca的含义是获得当前所在的Axes对象    # 画出训练数据    ax.scatter(X[:, 0],               X[:, 1],               c=y,               s=50,               cmap=cmap,               clim=(y.min(), y.max()),               zorder=3)  # zorder的用法详见技术笔记-matplotlib下对象的一些不常用的参数    ax.axis(&#39;tight&#39;)    ax.axis(&#39;off&#39;)  # 去除轴标签，还可以用ax.set_xticks=[];ax.set_yticks=[]替代    xlim = ax.get_xlim()    ylim = ax.get_ylim()    # 用评估器拟合数据    model.fit(X, y)    xx, yy = np.meshgrid(np.linspace(*xlim, num=200),                         np.linspace(*ylim, num=200))  # 设置网格矩阵    Z = model.predict(np.c_[xx.ravel(), yy.ravel()]).reshape(xx.shape)    # 为结果生成彩色图    n_classes = len(np.unique(y))  #    contours = ax.contourf(xx,                           yy,                           Z,                           alpha=0.3,                           levels=np.arange(n_classes + 1) - 0.5,                           cmap=cmap,                           clim=(y.min(), y.max()),                           zorder=1)    ax.set(xlim=xlim, ylim=ylim)visualize_classifier(DecisionTreeClassifier(), X, y)plt.savefig(&#39;2.jpg&#39;)</code></pre><p><img src="/2020/10/28/%E6%8A%80%E6%9C%AF%E7%AC%94%E8%AE%B0-%E4%B8%93%E9%A2%98%EF%BC%9A%E5%86%B3%E7%AD%96%E6%A0%91%E4%B8%8E%E9%9A%8F%E6%9C%BA%E6%A3%AE%E6%9E%97/2.jpg" srcset="/img/loading.gif" alt></p><p>由上述数据图像可知，随着决策树深度的不断加深，我们可能会看到非常奇怪的分类区域，这显然不是数据根据本身的分布情况生成的正确分类结果，而更像是一个特殊的数据样本或数据噪音形成的干扰结果——即出现了过拟合。</p><p>从一种角度看，决策树训练的是数据的不同子集，那么这种总是存在的过拟合就很好理解了，因此我们产生一个想法：对数据进行多组决策树，然后将其结果综合起来，效果会不会更好？这就是随机森林模型。</p><h2 id="评估器集成算法：随机森林"><a href="#评估器集成算法：随机森林" class="headerlink" title="评估器集成算法：随机森林"></a>评估器集成算法：随机森林</h2><p>通过组合多个过拟合评估器来降低过拟合程度的想法其实是一种集成学习方法，称为<strong>装袋算法</strong>。</p><pre><code>from sklearn.ensemble import RandomForestClassifiermodel = RandomForestClassifier(n_estimators=100,                               random_state=0)  # n_estimators是引进的决策树的数量visualize_classifier(model, X, y)plt.savefig(&#39;3.jpg&#39;)</code></pre><p><img src="/2020/10/28/%E6%8A%80%E6%9C%AF%E7%AC%94%E8%AE%B0-%E4%B8%93%E9%A2%98%EF%BC%9A%E5%86%B3%E7%AD%96%E6%A0%91%E4%B8%8E%E9%9A%8F%E6%9C%BA%E6%A3%AE%E6%9E%97/3.jpg" srcset="/img/loading.gif" alt></p><p>可以看到，通过RandomForestClassifier，<strong>一些很小的分类边界被软化</strong>，过拟合现象被进行了处理。</p><h3 id="随机森林回归"><a href="#随机森林回归" class="headerlink" title="随机森林回归"></a>随机森林回归</h3><p>RandomForestClassifier()是随机森林的分类评估器，而RandomForestRegressor()则是随机森林的回归评估器，<strong>随机森林回归非常适用于处理多周期数据，而不需要我们配置多周期模型</strong>。下面给出一个范例：</p><pre><code># 首先生成一组由快慢震荡组合而成的数据rng = np.random.RandomState(42)x = 10 * rng.rand(200)  # 生成两百个数据点def model(x, sigma=0.3):    fast = np.sin(5 * x)    slow = np.sin(0.5 * x)    noise = sigma * rng.rand(len(x))    return slow + fast + noisey = model(x)plt.errorbar(x, y, 0.3, fmt=&#39;o&#39;)plt.savefig(&#39;4.jpg&#39;)</code></pre><p><img src="/2020/10/28/%E6%8A%80%E6%9C%AF%E7%AC%94%E8%AE%B0-%E4%B8%93%E9%A2%98%EF%BC%9A%E5%86%B3%E7%AD%96%E6%A0%91%E4%B8%8E%E9%9A%8F%E6%9C%BA%E6%A3%AE%E6%9E%97/4.jpg" srcset="/img/loading.gif" alt></p><pre><code># 用随机森林回归器拟合该曲线from sklearn.ensemble import RandomForestRegressorforest = RandomForestRegressor(200)forest.fit(x[:, None], y)# 需要注意的是，x本身是一个一维数组，而模型所需要的特征值一定要是二维数组（即使该数组只存在一种特征），所以此处把x转换为x[:,None]这样的二维数组才可以带入模型进行拟合和预测xfit = np.linspace(0, 10, 1000)yfit = forest.predict(xfit[:, None])ytrue = model(xfit, sigma=0)#plt.errorbar(x, y, 0.3, fmt=&#39;o&#39;, alpha=0.4)plt.plot(xfit, yfit, &#39;-r&#39;)plt.plot(xfit, ytrue, &#39;-k&#39;, alpha=0.4)plt.savefig(&#39;5.jpg&#39;)</code></pre><p><img src="/2020/10/28/%E6%8A%80%E6%9C%AF%E7%AC%94%E8%AE%B0-%E4%B8%93%E9%A2%98%EF%BC%9A%E5%86%B3%E7%AD%96%E6%A0%91%E4%B8%8E%E9%9A%8F%E6%9C%BA%E6%A3%AE%E6%9E%97/5.jpg" srcset="/img/loading.gif" alt></p><p>可以看到，真实曲线（黑色）和预测曲线（红色）还是非常重合的，只不过真实模型是平滑曲线，而随机森林模型是锯齿线。</p>]]></content>
    
    
    <categories>
      
      <category>技术笔记</category>
      
      <category>python</category>
      
    </categories>
    
    
    <tags>
      
      <tag>机器学习</tag>
      
      <tag>决策树模型</tag>
      
      <tag>随机森林模型</tag>
      
    </tags>
    
  </entry>
  
  
  
  <entry>
    <title>[技术笔记]matplotlib下对象的一些不常用的参数或方法</title>
    <link href="/2020/10/21/%E6%8A%80%E6%9C%AF%E7%AC%94%E8%AE%B0-matplotlib%E4%B8%8B%E5%AF%B9%E8%B1%A1%E7%9A%84%E4%B8%80%E4%BA%9B%E4%B8%8D%E5%B8%B8%E7%94%A8%E7%9A%84%E5%8F%82%E6%95%B0/"/>
    <url>/2020/10/21/%E6%8A%80%E6%9C%AF%E7%AC%94%E8%AE%B0-matplotlib%E4%B8%8B%E5%AF%B9%E8%B1%A1%E7%9A%84%E4%B8%80%E4%BA%9B%E4%B8%8D%E5%B8%B8%E7%94%A8%E7%9A%84%E5%8F%82%E6%95%B0/</url>
    
    <content type="html"><![CDATA[<h3 id="zoreder参数"><a href="#zoreder参数" class="headerlink" title="zoreder参数"></a>zoreder参数</h3><p>作用：当一个图上出现了很多线条、补丁以及图例中的文本时，当这几种对象重合，<strong>会有一个参数来规定重合时谁在谁的上方，这个参数就是zorder</strong>。默认的参数设置如下表：</p><div class="table-container"><table><thead><tr><th>Artist</th><th>Z-order</th></tr></thead><tbody><tr><td>Patch/PatchCollection</td><td>1</td></tr><tr><td>Line2D/LineCollection</td><td>2</td></tr><tr><td>Text</td><td>3</td></tr></tbody></table></div><p>任何单独的绘图调用方法都可以为该特定项的zorder设置一个值。<br>设置zorder=x意味着第x个绘制这个对象，x越小，越先被绘制，重合时越容易出现在最下方。</p><p>一个例子（源于matplotlib官方文档）：<br>    import matplotlib.pyplot as plt<br>    import numpy as np</p><pre><code># Fixing random state for reproducibilitynp.random.seed(19680801)x = np.random.random(20)y = np.random.random(20)plt.figure()plt.subplot(211)plt.plot(x, y, &#39;C3&#39;, lw=3)plt.scatter(x, y, s=120)plt.title(&#39;Lines on top of dots&#39;)# Scatter plot on top of linesplt.subplot(212)plt.plot(x, y, &#39;C3&#39;, zorder=1, lw=3)plt.scatter(x, y, s=120, zorder=2)plt.title(&#39;Dots on top of lines&#39;)plt.tight_layout()</code></pre><p><img src="/2020/10/21/%E6%8A%80%E6%9C%AF%E7%AC%94%E8%AE%B0-matplotlib%E4%B8%8B%E5%AF%B9%E8%B1%A1%E7%9A%84%E4%B8%80%E4%BA%9B%E4%B8%8D%E5%B8%B8%E7%94%A8%E7%9A%84%E5%8F%82%E6%95%B0/1.jpg" srcset="/img/loading.gif" alt></p><p>由图就可以看出绘制先后的差别。</p><h3 id="跑题之np-meshgrid"><a href="#跑题之np-meshgrid" class="headerlink" title="跑题之np.meshgrid()"></a>跑题之np.meshgrid()</h3><p>从描述来看，np.meshgrid()是用来制造网格的，但单看代码真的看不出来原理，而这个函数在matplotlib作图时又很常用，所以跑题学习一下。</p><p>语法：X,Y = meshgrid(x,y)</p><p>解释：输出X的每一行的数值都是复制的x的值；输出Y的每一列的数值都是复制的y的值。</p><p>实例：</p><pre><code>x=-3:1:3;y=-2:1:2X,Y= meshgrid(x,y)</code></pre><p>这里meshgrid（x，y）的作用是分别产生以向量x为行，向量y为列的两个大小相同的矩阵，其中x的行是从-3开始到3，每间隔1记下一个数据，并把这些数据集成矩阵X；同理y的列则是从-2到2，每间隔1记下一个数据，并集成矩阵Y。</p><p>即X =</p><p>-3 -2 -1 0 1 2 3</p><p>-3 -2 -1 0 1 2 3</p><p>-3 -2 -1 0 1 2 3</p><p>-3 -2 -1 0 1 2 3</p><p>-3 -2 -1 0 1 2 3</p><p>Y =</p><p>-2 -2 -2 -2 -2 -2 -2</p><p>-1 -1 -1 -1 -1 -1 -1</p><p>0 0 0 0 0 0 0</p><p>1 1 1 1 1 1 1</p><p>2 2 2 2 2 2 2</p><p>效果是把x扩展成了5行，把y扩展成了7列（<strong>有点类似于pandas的广播机制</strong>）。</p><pre><code>x = np.linspace(0, 10, 30)y = np.linspace(0, 5, 30)X,Y = np.meshgrid(x,y)plt.plot(X, Y, linestyle=&#39;&#39;)plt.savefig(&#39;111.jpg&#39;)</code></pre><p>然后再plt.plot(X, Y, linestyle=’’)就做出了网格，如图所示：<br><img src="/2020/10/21/%E6%8A%80%E6%9C%AF%E7%AC%94%E8%AE%B0-matplotlib%E4%B8%8B%E5%AF%B9%E8%B1%A1%E7%9A%84%E4%B8%80%E4%BA%9B%E4%B8%8D%E5%B8%B8%E7%94%A8%E7%9A%84%E5%8F%82%E6%95%B0/2.jpg" srcset="/img/loading.gif" alt></p><p>(我的os:numpy真牛逼)</p>]]></content>
    
    
    <categories>
      
      <category>技术笔记</category>
      
      <category>python</category>
      
    </categories>
    
    
    <tags>
      
      <tag>matplotlib</tag>
      
      <tag>numpy</tag>
      
    </tags>
    
  </entry>
  
  
  
  <entry>
    <title>[技术笔记]面向对象API下matplotlib的一些坑</title>
    <link href="/2020/10/10/%E6%8A%80%E6%9C%AF%E7%AC%94%E8%AE%B0-%E9%9D%A2%E5%90%91%E5%AF%B9%E8%B1%A1API%E4%B8%8Bmatplotlib%E7%9A%84%E4%B8%80%E4%BA%9B%E5%9D%91/"/>
    <url>/2020/10/10/%E6%8A%80%E6%9C%AF%E7%AC%94%E8%AE%B0-%E9%9D%A2%E5%90%91%E5%AF%B9%E8%B1%A1API%E4%B8%8Bmatplotlib%E7%9A%84%E4%B8%80%E4%BA%9B%E5%9D%91/</url>
    
    <content type="html"><![CDATA[<p>虽然matplotlib的面向对象的API好像更符合操作逻辑，在处理复杂问题时能更好地在多个图像间进行转换，但也因为matlab封装下的API实在太有群众基础了，导致很多网上的教程都是此API。这两个API下一些细微的区别就会造成本人搜索时巨大的时间浪费，因此本文想总结一些面向对象API下matplotlib的坑，希望后人不要再踩坑了……</p><h3 id="旋转坐标轴标签"><a href="#旋转坐标轴标签" class="headerlink" title="旋转坐标轴标签"></a>旋转坐标轴标签</h3><p>在遇到时间刻度或者一些较长的刻度时，原本水平排列的坐标轴标签可能会出现重叠的现象，观感上很不好。此时，可以选用ax[0].set_xticklabels(t.index,rotation=45)此方法来旋转刻度，第一个参数t.index是要带入的坐标轴刻度，rotation即为刻度旋转的数值（<strong>千万注意不能忽略第一个参数</strong>，理解t.index在此处的作用是理解matplotlib中xlabels，ylabels的作用机制的关键所在）。</p><h3 id="在figure中添加子图"><a href="#在figure中添加子图" class="headerlink" title="在figure中添加子图"></a>在figure中添加子图</h3><p>添加子图通常有两种方法，简单的一种是fig, ax = plt.subplots(2,2)。</p><p>然而，如果后续还想要继续添加子图，可以使用axe1 = fig.add_subplot(3,3,3)这样的操作来实现。</p>]]></content>
    
    
    
  </entry>
  
  
  
  <entry>
    <title>[技术笔记]Jupyter与Stata关联：Windows系统（转载）</title>
    <link href="/2020/09/28/%E6%8A%80%E6%9C%AF%E7%AC%94%E8%AE%B0-Jupyter%E4%B8%8EStata%E5%85%B3%E8%81%94%EF%BC%9AWindows%E7%B3%BB%E7%BB%9F/"/>
    <url>/2020/09/28/%E6%8A%80%E6%9C%AF%E7%AC%94%E8%AE%B0-Jupyter%E4%B8%8EStata%E5%85%B3%E8%81%94%EF%BC%9AWindows%E7%B3%BB%E7%BB%9F/</url>
    
    <content type="html"><![CDATA[<p>作者：韩少真(西北大学) || 展金永（对外经济贸易大学）</p><h2 id="将stata添加到命令行注册"><a href="#将stata添加到命令行注册" class="headerlink" title="将stata添加到命令行注册"></a>将stata添加到命令行注册</h2><p>根据下图步骤，以管理员身份运行Windows PowerShell。</p><p>划重点：<strong>请务必以管理员身份运行</strong>。</p><p><img src="/2020/09/28/%E6%8A%80%E6%9C%AF%E7%AC%94%E8%AE%B0-Jupyter%E4%B8%8EStata%E5%85%B3%E8%81%94%EF%BC%9AWindows%E7%B3%BB%E7%BB%9F/1.jpg" srcset="/img/loading.gif" alt></p><p>打开stata的安装的文件夹，根据下图获取stata的安装路径：</p><p><img src="/2020/09/28/%E6%8A%80%E6%9C%AF%E7%AC%94%E8%AE%B0-Jupyter%E4%B8%8EStata%E5%85%B3%E8%81%94%EF%BC%9AWindows%E7%B3%BB%E7%BB%9F/2.jpg" srcset="/img/loading.gif" alt></p><p>在Windows PowerShell执行cd命令，以进入stata程序安装的路径。cd命令后接上步所获取的stata安装路径。根据个人电脑安装路径不同有所差异。路径请以英文引号包围，这样可以避免路径文件夹名称中包含空格导致无法顺利进入目标路径。</p><pre><code>cd &quot;D:\Stata15&quot;</code></pre><p>执行上述命令后，请根据下图提示，确认是否已进入stata安装路径：</p><p><img src="/2020/09/28/%E6%8A%80%E6%9C%AF%E7%AC%94%E8%AE%B0-Jupyter%E4%B8%8EStata%E5%85%B3%E8%81%94%EF%BC%9AWindows%E7%B3%BB%E7%BB%9F/3.jpg" srcset="/img/loading.gif" alt></p><p>在Windows PowerShell中执行.\StataMP-64.exe /Register命令，则可以成功将stata添加到命令行注册。需要注意的是，.\StataMP-64.exe /Register中的.\StataMP-64.exe部分，根据个人电脑安装stata15版本有所差异。我电脑安装的是MP版，所以为.\StataMP-64.exe。如果安装的是SE版，应该为.\StataSE-64.exe。</p><pre><code>.\StataMP-64.exe /Register# or.\StataSE-64.exe /Register</code></pre><h2 id="安装stata-kernel包"><a href="#安装stata-kernel包" class="headerlink" title="安装stata_kernel包"></a>安装stata_kernel包</h2><p>在cmd逐行执行以下代码,安装stata_kernel包。安装结束后可根据cmd窗口的提示，判断是否成功安装。注意：<strong>不能省略第二行命令，下载stata_kernal包后要将其手动安装。</strong></p><pre><code>pip install stata_kernelpython -m stata_kernel.install</code></pre><h2 id="打开jupyter-notebook，新建stata语法格式的notebook，执行stata代码，检验是否关联成功"><a href="#打开jupyter-notebook，新建stata语法格式的notebook，执行stata代码，检验是否关联成功" class="headerlink" title="打开jupyter notebook，新建stata语法格式的notebook，执行stata代码，检验是否关联成功"></a>打开jupyter notebook，新建stata语法格式的notebook，执行stata代码，检验是否关联成功</h2><p>根据下图，在jupyter notebook中执行以下操作，新建一个支持stata语法的notebook。这会弹出一个新的网页标签。</p><p><img src="/2020/09/28/%E6%8A%80%E6%9C%AF%E7%AC%94%E8%AE%B0-Jupyter%E4%B8%8EStata%E5%85%B3%E8%81%94%EF%BC%9AWindows%E7%B3%BB%E7%BB%9F/4.jpg" srcset="/img/loading.gif" alt></p><p>在新建的notebook中，通过下图可以初步判断是否关联成功。</p><p><img src="/2020/09/28/%E6%8A%80%E6%9C%AF%E7%AC%94%E8%AE%B0-Jupyter%E4%B8%8EStata%E5%85%B3%E8%81%94%EF%BC%9AWindows%E7%B3%BB%E7%BB%9F/5.jpg" srcset="/img/loading.gif" alt></p><p>在命令行输入stata命令，并点击运行执行。如果关联成功，则会在命令的下方显示stata结果窗口的结果。具体如下图所示：</p><pre><code>dis 1+3sysuse auto,clearreg price weightscatter price weight</code></pre><p><img src="/2020/09/28/%E6%8A%80%E6%9C%AF%E7%AC%94%E8%AE%B0-Jupyter%E4%B8%8EStata%E5%85%B3%E8%81%94%EF%BC%9AWindows%E7%B3%BB%E7%BB%9F/6.jpg" srcset="/img/loading.gif" alt></p><p>作者：mailshaozhen<br>链接：<a href="https://www.jianshu.com/p/790c86824411" target="_blank" rel="noopener">https://www.jianshu.com/p/790c86824411</a><br>来源：简书<br>著作权归作者所有。商业转载请联系作者获得授权，非商业转载请注明出处。</p>]]></content>
    
    
    <categories>
      
      <category>技术笔记</category>
      
      <category>stata</category>
      
    </categories>
    
    
    <tags>
      
      <tag>stata</tag>
      
      <tag>jupyter</tag>
      
    </tags>
    
  </entry>
  
  
  
  <entry>
    <title>[技术笔记]留出集不止train_test_split</title>
    <link href="/2020/09/24/%E6%8A%80%E6%9C%AF%E7%AC%94%E8%AE%B0-%E7%95%99%E5%87%BA%E9%9B%86%E4%B8%8D%E6%AD%A2train-test-split/"/>
    <url>/2020/09/24/%E6%8A%80%E6%9C%AF%E7%AC%94%E8%AE%B0-%E7%95%99%E5%87%BA%E9%9B%86%E4%B8%8D%E6%AD%A2train-test-split/</url>
    
    <content type="html"><![CDATA[<p>在kaggle初识machine learning时就知道了不能检验拟合的同一套数据，这样会造成overfitting，所以用model_selection里的train_test_split方法来解决这一问题，这被我们称为<strong>留出集</strong>。</p><p>然而用留出集进行模型验证有一个缺点，就是<strong>模型失去了部分训练机会</strong>。当训练集数据规模较小时，问题就比较严重了。因此，我们可以考虑让每个子集既是训练集，又是验证集，最后将几者结合，获取一个更准确的模型总体性能。这种方法被称为<strong>交叉检验</strong>。</p><p>如一个五轮交叉检验的代码如下：</p><pre><code>from skleran.model_selection import cross_val_scorecross_val_score(model, X, y, cv=5)</code></pre><p>如果每次只有一个样本做测试，其他样本全用于训练，这种交叉检验的方法就被称为<strong>LOO（leave-one-out）交叉检验</strong>，代码如下：</p><pre><code>from sklearn.model_selection import LeaveOneOutscores = cross_val_score(model, X, y, cv=LeaveOneOut(len(X)))scores.mean() #均值即为平均得分</code></pre>]]></content>
    
    
    <categories>
      
      <category>技术笔记</category>
      
      <category>python</category>
      
    </categories>
    
    
    <tags>
      
      <tag>机器学习</tag>
      
      <tag>交叉检验</tag>
      
    </tags>
    
  </entry>
  
  
  
  <entry>
    <title>[技术笔记]matplotlib两种画图接口的不同与其他常用知识</title>
    <link href="/2020/09/23/%E6%8A%80%E6%9C%AF%E7%AC%94%E8%AE%B0-matplotlib%E4%B8%A4%E7%A7%8D%E7%94%BB%E5%9B%BE%E6%8E%A5%E5%8F%A3%E7%9A%84%E4%B8%8D%E5%90%8C/"/>
    <url>/2020/09/23/%E6%8A%80%E6%9C%AF%E7%AC%94%E8%AE%B0-matplotlib%E4%B8%A4%E7%A7%8D%E7%94%BB%E5%9B%BE%E6%8E%A5%E5%8F%A3%E7%9A%84%E4%B8%8D%E5%90%8C/</url>
    
    <content type="html"><![CDATA[<h2 id="接口区别"><a href="#接口区别" class="headerlink" title="接口区别"></a>接口区别</h2><p>相比于matlab风格的画图接口，我还是觉得面向对象的画图接口更符合python的设计哲学，但两者之间的一些函数就无法共用。</p><ul><li>plt.xlabel() → ax.set_xlabel()</li><li>plt.ylabel() → ax.set_ylabel()</li><li>plt.xlim() → ax.set_xlim()</li><li>plt.ylim() → ax.set_ylim()</li><li>plt.title() → ax.set_title()</li></ul><p>但是，面向对象接口中，一般都可以用一个ax.set()函数涵盖这些内容：</p><pre><code>ax.set(xlim=(0, 10), ylim=(-2, 2),       xlabel=&#39;x&#39;, ylabel=&#39;sin(x)&#39;,       title=&#39;A Simple Plot&#39;)</code></pre><h2 id="其他常用知识"><a href="#其他常用知识" class="headerlink" title="其他常用知识"></a>其他常用知识</h2><h3 id="plot与scatter在画散点图时的区别"><a href="#plot与scatter在画散点图时的区别" class="headerlink" title="plot与scatter在画散点图时的区别"></a>plot与scatter在画散点图时的区别</h3><p>在样本数据量小时，两者运行效率相差无几，并且由于scatter函数能使每个散点拥有各自的属性，所以效果更好。但在样本量大时，plot的执行效率会更高。</p><h3 id="基本误差线（errorbar）"><a href="#基本误差线（errorbar）" class="headerlink" title="基本误差线（errorbar）"></a>基本误差线（errorbar）</h3><p><strong>ax.errorbar(x, y, yerr=dy, fmt=’K.’, color=XXX, ecolor=XXX)</strong></p><p>其中yerr指垂直方向上的误差线，水平方向上的误差线为xerr，ecolor为误差线的颜色，一般来说，让误差线的颜色比数据点的颜色浅一点效果会非常好。</p><h3 id="连续误差"><a href="#连续误差" class="headerlink" title="连续误差"></a>连续误差</h3><p>想要刻画连续函数的误差，可以先构造一个ax.plot()，再构造一个ax.fill_between(x,y-dy,y+dy,alpha = 0.2)的函数，效果如图所示：<br><img src="/2020/09/23/%E6%8A%80%E6%9C%AF%E7%AC%94%E8%AE%B0-matplotlib%E4%B8%A4%E7%A7%8D%E7%94%BB%E5%9B%BE%E6%8E%A5%E5%8F%A3%E7%9A%84%E4%B8%8D%E5%90%8C/1.jpg" srcset="/img/loading.gif" alt></p><h3 id="密度图与等高线图"><a href="#密度图与等高线图" class="headerlink" title="密度图与等高线图"></a>密度图与等高线图</h3><p>有contour、contourf、imshow三个函数，如果要显示颜色条，需要增加fig.colorbar(m, ax = ax1)，具体内容参阅Python DataScience Handbook P21-214。</p><h3 id="频次直方图"><a href="#频次直方图" class="headerlink" title="频次直方图"></a>频次直方图</h3><p>ax.hist(data, bins=xxx, normed=True/False, alpha=xxx, hsittype=xxx, color=xxx, edgecolor=xxx)</p><p>bins参数设置被切割的柱体数；normed参数为是否归一化，默认为False，如果设为True，将会调整纵坐标的值，使得直方图中每个长方形块的面积之和为1。</p><h4 id="二维频次直方图"><a href="#二维频次直方图" class="headerlink" title="二维频次直方图"></a>二维频次直方图</h4><p>ax.hist2d(x, y, bins=30, cmap=’Blues’)<br><img src="/2020/09/23/%E6%8A%80%E6%9C%AF%E7%AC%94%E8%AE%B0-matplotlib%E4%B8%A4%E7%A7%8D%E7%94%BB%E5%9B%BE%E6%8E%A5%E5%8F%A3%E7%9A%84%E4%B8%8D%E5%90%8C/2.jpg" srcset="/img/loading.gif" alt></p><h4 id="六边形直方图"><a href="#六边形直方图" class="headerlink" title="六边形直方图"></a>六边形直方图</h4><p>ax.hexbin(x, y, gridszie=30, cmap=’Blues’)<br><img src="/2020/09/23/%E6%8A%80%E6%9C%AF%E7%AC%94%E8%AE%B0-matplotlib%E4%B8%A4%E7%A7%8D%E7%94%BB%E5%9B%BE%E6%8E%A5%E5%8F%A3%E7%9A%84%E4%B8%8D%E5%90%8C/3.jpg" srcset="/img/loading.gif" alt></p>]]></content>
    
    
    <categories>
      
      <category>技术笔记</category>
      
      <category>python</category>
      
    </categories>
    
    
    <tags>
      
      <tag>matplotlib</tag>
      
    </tags>
    
  </entry>
  
  
  
  <entry>
    <title>[技术笔记]numpy入门</title>
    <link href="/2020/09/19/%E6%8A%80%E6%9C%AF%E7%AC%94%E8%AE%B0-numpy%E5%85%A5%E9%97%A8/"/>
    <url>/2020/09/19/%E6%8A%80%E6%9C%AF%E7%AC%94%E8%AE%B0-numpy%E5%85%A5%E9%97%A8/</url>
    
    <content type="html"><![CDATA[<h2 id="NumPy数组基础"><a href="#NumPy数组基础" class="headerlink" title="NumPy数组基础"></a>NumPy数组基础</h2><h3 id="创建数组"><a href="#创建数组" class="headerlink" title="创建数组"></a>创建数组</h3><h4 id="直接创建"><a href="#直接创建" class="headerlink" title="直接创建"></a>直接创建</h4><p>要创建一维数组，即np.array([1,2,3,4]);创建多维数组的一种方法：np.array([range(i,i+3) for i in [2,4,6]])，输出结果为：</p><pre><code>array([[2, 3, 4],      [4, 5, 6],      [6, 7, 8]])</code></pre><h4 id="大批量创建"><a href="#大批量创建" class="headerlink" title="大批量创建"></a>大批量创建</h4><p>创建长度为10的0值数组：np.zeros(10)</p><p>创建3*5大小的1值数组：np.ones((3,5))</p><p>创建3*5大小的定值数组：np.full((3,5), 5.5)</p><p>创建一个0-20，步长为2的线性数组（类似于range函数)：np.arange(0,20,2)</p><p>创建一个5分的区间为[0,1]的数组：np.linspace(0,1,6)</p><p>创建一个0-1之间的3*3随机数组：np.random.random((3,3))</p><p>创建一个均值为0，标准差为1的正态分布数组：np.random.normal(0,1,10)</p><p>创建一个0-10间随机整数的3*3数组：np.random.randint(0,10,(3,3))</p><p>创建一个3*3的单位矩阵：np.eye(3)</p><h3 id="数组的属性"><a href="#数组的属性" class="headerlink" title="数组的属性"></a>数组的属性</h3><p>数组属性一般有.ndim（数组的维度）；.shape（各个维度的大小）；.size（总大小）</p><h3 id="数组索引和切片"><a href="#数组索引和切片" class="headerlink" title="数组索引和切片"></a>数组索引和切片</h3><p>数组索引的方式与一般的python序列基本相同，有两点需要注意：1、因为不单是一维，可以多重索引；2、<strong>numpy数组类型是固定的，一个浮点数加入整型数组会被自动截短，且不会有提示，要小心！</strong></p><p>还需要注意的是，数组的索引和切片并不是一个副本，而是原数组的视图，所有修改都会直接体现在原数组上，可以使用array.copy()函数来制造副本，从而避免这一点。</p><h3 id="数组的变形"><a href="#数组的变形" class="headerlink" title="数组的变形"></a>数组的变形</h3><p>np.arange(1,10).reshape(3,3) —- 把一维数组转换成3*3的二维数组。</p><p>x[np.newaxis,:] —- 获得数组的行向量</p><p>x[:,np.newaxis] —- 获得数组的列向量</p><h3 id="数组的拼接和分裂"><a href="#数组的拼接和分裂" class="headerlink" title="数组的拼接和分裂"></a>数组的拼接和分裂</h3><h4 id="数组的拼接"><a href="#数组的拼接" class="headerlink" title="数组的拼接"></a>数组的拼接</h4><p>纵向拼接：np.concatence([x,y,z]) 或 np.vstack([x,y,z])</p><p>横向拼接：np.concatence([x,y,z], axis = 1) 或 np.hstack([x,y,z])</p><h4 id="数组的分裂"><a href="#数组的分裂" class="headerlink" title="数组的分裂"></a>数组的分裂</h4><p>split、vsplit、hsplit三个函数，和数组的拼接差不多，用到了再看。</p><h3 id="通用函数"><a href="#通用函数" class="headerlink" title="通用函数"></a>通用函数</h3><p>由于python的循环十分缓慢，因此numpy寻求一种优化的函数，改进这一点，这样的函数叫<strong>通用函数(ufunc)</strong>。通用函数作用于数组中的每一个元素，且执行效率很高。</p><h4 id="常用通用函数"><a href="#常用通用函数" class="headerlink" title="常用通用函数"></a>常用通用函数</h4><p>+、-、<em>、/、//、*</em>、%都可以对数组直接使用</p><p>绝对值函数：np.abs()</p><p>三角函数：np.sin() np.cos() np.tan() np.arcsin() np.arccos() np.arctan()</p><p>指数和对数：np.exp() np.exp2() np.power(n,x) np.log() np.log2() np.log10()</p><p>其他专用的通用函数可以在numpy或scipy.special中找到</p><h4 id="高级通用函数特性"><a href="#高级通用函数特性" class="headerlink" title="高级通用函数特性"></a>高级通用函数特性</h4><ul><li>指定输出：所有通用函数都可以通过<strong>参数out</strong>指定结果的存放位置</li><li><p>聚合：任何通用函数都可以用<strong>outer方法</strong>获得两隔不同输入数组<strong>所有元素对</strong>的函数运算结果。</p><pre><code>  In [30]:  x = np.arange(1, 6)  np.multiply.outer(x, x)  Out[30]:  array([[ 1,  2,  3,  4,  5],    [ 2,  4,  6,  8, 10],    [ 3,  6,  9, 12, 15],    [ 4,  8, 12, 16, 20],    [ 5, 10, 15, 20, 25]])</code></pre></li></ul><h3 id="聚合-amp-广播-amp-比较、掩码和布尔逻辑"><a href="#聚合-amp-广播-amp-比较、掩码和布尔逻辑" class="headerlink" title="聚合&amp;广播&amp;比较、掩码和布尔逻辑"></a>聚合&amp;广播&amp;比较、掩码和布尔逻辑</h3><p>pandas都学过了，不赘述。</p><h3 id="数组的排序"><a href="#数组的排序" class="headerlink" title="数组的排序"></a>数组的排序</h3><h4 id="快速排序"><a href="#快速排序" class="headerlink" title="快速排序"></a>快速排序</h4><p>numpy具有np.sort()和array.sort()两种方法，前者是产生一个副本，后者直接替换掉原值。另外还可以选择<strong>并归排序</strong>和<strong>堆排序</strong>。</p><h4 id="部分排序"><a href="#部分排序" class="headerlink" title="部分排序"></a>部分排序</h4><p>可以只对数组部分排序：np.partition(x,3) —- 对x数组的前三小的值排前三，其他随便排。</p>]]></content>
    
    
    <categories>
      
      <category>技术笔记</category>
      
      <category>python</category>
      
    </categories>
    
    
    <tags>
      
      <tag>numpy</tag>
      
    </tags>
    
  </entry>
  
  
  
  <entry>
    <title>[技术笔记]pandas学习小笔记2</title>
    <link href="/2020/09/17/%E6%8A%80%E6%9C%AF%E7%AC%94%E8%AE%B0-pandas%E5%AD%A6%E4%B9%A0%E5%B0%8F%E7%AC%94%E8%AE%B02/"/>
    <url>/2020/09/17/%E6%8A%80%E6%9C%AF%E7%AC%94%E8%AE%B0-pandas%E5%AD%A6%E4%B9%A0%E5%B0%8F%E7%AC%94%E8%AE%B02/</url>
    
    <content type="html"><![CDATA[<p>1、可以将Series看成是一个定长的有序字典，因为它是索引值到数据值的一个映射，它可以用在许多原本需要字典参数的函数中。如果数据被存放在一个Python字典中，也可以直接通过这个字典来创建Series（在传入字典的前提下也可以通过index参数再来修改索引顺序）。</p><p>2、IPython提供了类似属性的访问（即frame2.year）和tab补全。 frame2[column]适用于任何列的名，但是frame2.column只有在列名是一个合理的Python变量名时才适用。所以说还是使用frame2[column]这样的形式更加普遍、通用，一些地方也不容易报错，<strong>需要注意的是，这样获取的一个列即为Series，可以用那些Series的方法，而失去了DataFrame独有的方法</strong>。</p><p>3、将列表或数组赋值给某个列时，其长度必须跟DataFrame的长度相匹配。如果赋值的是一个Series，就会精确匹配DataFrame的索引，所有的空位都将被填上缺失值。（所以不用担心元素级别的操作，实操上就是元素级别的）</p><p>4、小技巧：DataFrame是可以进行转置的：<strong>df.T</strong></p><p>5、Index还是有很多常见的函数的，如果能利用起来确实能解决很多问题。<img src="/2020/09/17/%E6%8A%80%E6%9C%AF%E7%AC%94%E8%AE%B0-pandas%E5%AD%A6%E4%B9%A0%E5%B0%8F%E7%AC%94%E8%AE%B02/1.jpg" srcset="/img/loading.gif" alt></p><p>6、对两个Series或者DataFrame使用算术方法时，没有交集的地方会产生nan值，这其实可以通过<img src="/2020/09/17/%E6%8A%80%E6%9C%AF%E7%AC%94%E8%AE%B0-pandas%E5%AD%A6%E4%B9%A0%E5%B0%8F%E7%AC%94%E8%AE%B02/2.jpg" srcset="/img/loading.gif" alt>解决。传入fill_value = xxx</p><p>7、<strong>函数应用和映射：</strong>NumPy的ufuncs（元素级数组方法）也可用于操作pandas对象。另一个常见的操作是，将函数应用到由各列或行所形成的一维数组上。DataFrame的apply方法即可实现此功能。当然，apply是对行或者列的整体操作，<strong>若要具体到元素级的操作，可以使用.applymap()</strong>。针对Series的元素级操作则为series.map(f)</p><p>8、数据加载的一些常见参数：header = none：不将数据集中的数据作为列名，另开默认一行作为列行；names = xxx：用于结果的列名列表；index_col = ‘’：用作行索引的列名或列编号（可能存在没有列名的情况，所以只能用列编号）；nrows = 5：如果只想读取几行（避免读取整个文件），通过nrows进行指定即可<br>。</p><p>9、若是通过一个字典调用fillna，就可以实现对不同的列填充不同的值：In [34]: df.fillna({1: 0.5, 2: 0})</p><p>10、通过data.map，所有字符串和正则表达式方法都能被应用于（传入lambda表达式或其他函数）各个值，但是如果存在NA（null）就会报错。为了解决这个问题，<strong>Series有一些能够跳过NA值的面向数组方法，进行字符串操作</strong>。通过Series的str属性即可访问这些方法（相当于DataFrame和Series内部自己构造的字符串方法了）。</p><p>11、对于层次化索引，有时，你需要重新调整某条轴上各级别的顺序，或根据指定级别上的值对数据进行排序。swaplevel接受两个级别编号或名称，并返回一个互换了级别的新对象（但数据不会发生变化）：frame.swaplevel(‘key1’, ‘key2’)</p>]]></content>
    
    
    <categories>
      
      <category>技术笔记</category>
      
      <category>python</category>
      
    </categories>
    
    
    <tags>
      
      <tag>pandas</tag>
      
    </tags>
    
  </entry>
  
  
  
  <entry>
    <title>[技术笔记]Intermediate ML的一些小技巧</title>
    <link href="/2020/09/16/%E6%8A%80%E6%9C%AF%E7%AC%94%E8%AE%B0-Intermediate-ML%E7%9A%84%E4%B8%80%E4%BA%9B%E5%B0%8F%E6%8A%80%E5%B7%A7/"/>
    <url>/2020/09/16/%E6%8A%80%E6%9C%AF%E7%AC%94%E8%AE%B0-Intermediate-ML%E7%9A%84%E4%B8%80%E4%BA%9B%E5%B0%8F%E6%8A%80%E5%B7%A7/</url>
    
    <content type="html"><![CDATA[<p>在收集特征变量X的时候，其实可以用X = X_full.copy()的形式，防止源数据的后续改动影响到前面跑模型的结果。</p><p>from sklearn.model_selection import train_test_split 的参数：train_size = 0.8,test_size = 0.2,random_state = 0 </p><p>在剔除具有无效值的列时，除了使用df.dropna(axis =1)外，还可以用</p><pre><code># Fill in the line below: get names of columns with missing valuesmissing_values_columns = [col for col in X_train.columns if X_train[col].isnull().any()] # Your code here# Fill in the lines below: drop columns in training and validation datareduced_X_train = X_train.drop(missing_values_columns, axis = 1)</code></pre><p>这样的方法。</p><h3 id="分类变量的三种处理办法"><a href="#分类变量的三种处理办法" class="headerlink" title="分类变量的三种处理办法"></a>分类变量的三种处理办法</h3><h4 id="Drop-Categorical-Variables"><a href="#Drop-Categorical-Variables" class="headerlink" title="Drop Categorical Variables"></a>Drop Categorical Variables</h4><p>当分类变量压根儿没啥用的时候，就用这个方法。</p><pre><code>drop_X_train = X_train.select_dtypes(exclude = [&#39;object&#39;])</code></pre><h4 id="Label-Encoding"><a href="#Label-Encoding" class="headerlink" title="Label Encoding"></a>Label Encoding</h4><p>当变量是ordinal variables时，    可以为其排名。</p><h4 id="One-Hot-Encoding"><a href="#One-Hot-Encoding" class="headerlink" title="One-Hot Encoding"></a>One-Hot Encoding</h4><p>对于之间有互斥关系的nominal variables，可以用这种方法，就类似dummies。</p>]]></content>
    
    
    <categories>
      
      <category>技术笔记</category>
      
      <category>python</category>
      
    </categories>
    
    
    <tags>
      
      <tag>机器学习</tag>
      
    </tags>
    
  </entry>
  
  
  
  <entry>
    <title>[技术笔记]机器学习初识</title>
    <link href="/2020/09/15/%E6%8A%80%E6%9C%AF%E7%AC%94%E8%AE%B0-%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0%E5%88%9D%E8%AF%86/"/>
    <url>/2020/09/15/%E6%8A%80%E6%9C%AF%E7%AC%94%E8%AE%B0-%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0%E5%88%9D%E8%AF%86/</url>
    
    <content type="html"><![CDATA[<h2 id="学习前应知小常识"><a href="#学习前应知小常识" class="headerlink" title="学习前应知小常识"></a>学习前应知小常识</h2><p>机器学习一般可以分为两类，有监督学习和无监督学习。<strong>有监督学习</strong>是对数据的若干特征与若干标签之间的关联性进行建模的过程，具体来说，又分<strong>分类</strong>（classification）、<strong>回归</strong>（regression）。<strong>无监督学习</strong>是指不带任何标签的数据特征进行建模，包括<strong>聚类</strong>（clustering）、<strong>降维</strong>（dimensionality reduction）。</p><p>对于高维数据，我们通常采用先降维再聚类的方法，就可以通过数据可视化的视角（因为高维数据的可视化是非常困难的）先研究一下不同数据的特征。一般来说，通过降维就可以首先将数据做出一个分类，聚类后则是一个更清晰的分类，这说明某些样本通过看似不同的特征组合是存在关联性的。<strong>降维/聚合的效果好其实是告诉我们：用一个非常简单的有监督分类算法就可以完成任务。</strong></p><h2 id="一般的Machine-Learning步骤"><a href="#一般的Machine-Learning步骤" class="headerlink" title="一般的Machine Learning步骤"></a>一般的Machine Learning步骤</h2><p>搜据数据—数据清洗—确定预测的column—选择特征变量—建立模型（选择合适的模型—带入数据进行学习—预测—评估模型准确性、稳定性等）</p><p>下面以最简单的决策树模型为例，过一下整个流程（代码来自Kaggle的课程）</p><h3 id="Selecting-Data-for-Modeling"><a href="#Selecting-Data-for-Modeling" class="headerlink" title="Selecting Data for Modeling"></a>Selecting Data for Modeling</h3><pre><code># Code you have previously used to load dataimport pandas as pd# Path of the file to readiowa_file_path = &#39;../input/home-data-for-ml-course/train.csv&#39;home_data = pd.read_csv(iowa_file_path)# Set up code checkingfrom learntools.core import binderbinder.bind(globals())from learntools.machine_learning.ex3 import *print(&quot;Setup Complete&quot;)</code></pre><h3 id="Selecting-The-Prediction-Target"><a href="#Selecting-The-Prediction-Target" class="headerlink" title="Selecting The Prediction Target"></a>Selecting The Prediction Target</h3><p>约定俗称的是用y代表要预测的序列</p><pre><code>y = home_data.SalePrice</code></pre><h3 id="Choosing-“Features”"><a href="#Choosing-“Features”" class="headerlink" title="Choosing “Features”"></a>Choosing “Features”</h3><p>这一串Featues通常被称为X</p><pre><code># Create the list of features belowfeature_names = [&#39;LotArea&#39;,&#39;YearBuilt&#39;,&#39;1stFlrSF&#39;,&#39;2ndFlrSF&#39;,&#39;FullBath&#39;,&#39;BedroomAbvGr&#39;,&#39;TotRmsAbvGrd&#39;]# Select data corresponding to features in feature_namesX = home_data[feature_names]</code></pre><h3 id="Building-Model"><a href="#Building-Model" class="headerlink" title="Building Model"></a>Building Model</h3><p>The steps to building and using a model are:</p><p><strong>Define:</strong> What type of model will it be? A decision tree? Some other type of model? Some other parameters of the model type are specified too.</p><p>这里选择决策树模型</p><pre><code>from sklearn.tree import DecisionTreeRegressor#specify the model. #For model reproducibility, set a numeric value for random_state when specifying the modeliowa_model = DecisionTreeRegressor(random_state = 1)</code></pre><p><strong>Fit:</strong>Capture patterns from provided data. This is the heart of modeling.</p><pre><code>iowa_model.fit(X,y)</code></pre><p><strong>Predict:</strong> Just what it sounds like</p><pre><code>predictions = iowa_model.predict(X)print(predictions)</code></pre><p><strong>Evaluate:</strong> Determine how accurate the model’s predictions are.</p><p>one method for summarizing model quality: <strong>Mean Absolute Error(MSE)</strong></p><p>在Evaluate模型时’In-Sample’的问题：sample可能与整体不是同分布的，对样本的过度拟合会使模型带上一些样本显著二总体不显著的特征（这里举的一个例子是可能样本中带绿色门的房子都很贵，模型就将绿色门和贵相联系，但其实总体中可能根本没有这种特征）。</p><p>其他注意点：</p><p>决策树张有许多可以选择的变量，其中最重要的就是树枝的分支数，但要注意的是，分支太多，可能造成overfitting的问题；分支太少，可能造成uderfitting的问题。可以使用max_leaf_nodes这个参数来控制分支数。</p><pre><code>def get_mae(max_leaf_nodes, train_X, val_X, train_y, val_y):    model = DecisionTreeRegressor(max_leaf_nodes=max_leaf_nodes, random_state=0)    model.fit(train_X, train_y)    val_predictions = model.predict(val_X)    mae = mean_absolute_error(val_y, preds_val)    return(mae)# compare MAE with differing values of max_leaf_nodesfor max_leaf_nodes in [5, 50, 500, 5000]:    my_mae = get_mae(max_leaf_nodes, train_X, val_X, train_y, val_y)    print(&quot;Max leaf nodes: %d  \t\t Mean Absolute Error:  %d&quot; %(max_leaf_nodes, my_mae))</code></pre><p>在决策树模型的基础上诞生的另一种模型：random forest（随机森林）。</p><p>The random forest uses many trees, and it makes a prediction by averaging the predictions of each component tree. It generally has much better predictive accuracy than a single decision tree and <strong>it works well with default parameters.</strong></p><p>其他算法可能会比random forest更加精确，但这需要更精确的参数匹配，不像random forest跑默认参数也运行地很好。</p>]]></content>
    
    
    <categories>
      
      <category>技术笔记</category>
      
      <category>python</category>
      
    </categories>
    
    
    <tags>
      
      <tag>机器学习</tag>
      
      <tag>决策树模型</tag>
      
      <tag>随机森林模型</tag>
      
    </tags>
    
  </entry>
  
  
  
  <entry>
    <title>[技术笔记]序列的一些用法</title>
    <link href="/2020/09/09/%E6%8A%80%E6%9C%AF%E7%AC%94%E8%AE%B0-%E5%BA%8F%E5%88%97%E7%9A%84%E4%B8%80%E4%BA%9B%E8%AF%AD%E6%B3%95%E7%B3%96/"/>
    <url>/2020/09/09/%E6%8A%80%E6%9C%AF%E7%AC%94%E8%AE%B0-%E5%BA%8F%E5%88%97%E7%9A%84%E4%B8%80%E4%BA%9B%E8%AF%AD%E6%B3%95%E7%B3%96/</url>
    
    <content type="html"><![CDATA[<p>容器序列如list,tuple,collections.deque可以存放不同类型的数据，而扁平序列如str,bytes,array.array则只可以存放同一类型的数据。</p><p>但是，容器序列存放的是它们所包含的对象的引用，扁平序列则存放值，是一段更加紧凑的内存空间。</p><h2 id="列表推导和生成器表达式"><a href="#列表推导和生成器表达式" class="headerlink" title="列表推导和生成器表达式"></a>列表推导和生成器表达式</h2><h3 id="列表推导式"><a href="#列表推导式" class="headerlink" title="列表推导式"></a>列表推导式</h3><p>列表推导式是用来创建新列表的一个方法，通常能够对for循环、if条件语句等进行精简，是非常好用的语法糖。例如：</p><pre><code>方法一：symbols = &#39;ABCDE&#39;codes = []for symbol in symbols:    codes.append(ord(symbol))codes方法二：codes = [ord(symbol) for symbol in symbols]    codes</code></pre><p>两者的输出都是[65, 66, 67, 68, 69]，但显然方法二在可读性和简洁性上更胜一筹。</p><p><strong>列表推导式可以结合条件语句</strong>，如[ord(x) for x in xs if len(x) &gt;10].</p><p><strong>列表推导式还可以构成多循环结构</strong>，如[(x,y) for x in xs for y in ys].</p><h3 id="生成器表达式"><a href="#生成器表达式" class="headerlink" title="生成器表达式"></a>生成器表达式</h3><p>用来初始化元组、数组或其他序列类型，与列表推导式相比，表面上看只是将[]换为了()，但其原理上有本质的不同。</p><p>生成器表达式背后遵守了迭代器协议，可以逐个地产出元素，而不是先建立一个完整的列表，当数据规模很大时，可以有效地节省内存。</p><h2 id="元组"><a href="#元组" class="headerlink" title="元组"></a>元组</h2><h3 id="元组拆包"><a href="#元组拆包" class="headerlink" title="元组拆包"></a>元组拆包</h3><ol><li><p>平行赋值</p><pre><code> In[3]:a,b,c = (1,2,3)     a,b,c Out[3]:(1,2,3)</code></pre></li><li><p>用运算符把一个可迭代对象拆开（<strong>只有传参的时候可以这样用</strong>）</p><pre><code> In[6]:t = (20, 8)       divmod(*t) Out[6]:(2,4)</code></pre></li><li><p>占位符_在元组拆包中的运用</p><pre><code> In[9]:sample = [(1,a), (2,b), (3,c)]       for x, _ in sample:           print(x) Out[9]:1         2         3</code></pre></li><li><p>用*args来获取不确定数量的参数</p><pre><code> In[10]:a,b,*rest = range(5)        rest Out[10]:[2,3,4]</code></pre></li></ol><h2 id="切片"><a href="#切片" class="headerlink" title="切片"></a>切片</h2><h3 id="为什么切片和区间操作会忽略最后一个元素"><a href="#为什么切片和区间操作会忽略最后一个元素" class="headerlink" title="为什么切片和区间操作会忽略最后一个元素"></a>为什么切片和区间操作会忽略最后一个元素</h3><p>这样做的好处有：range(3)、list[:3]这种只有单个位置信息的一看就知道里面有三个元素；</p><p>stop-start即为所包含的元素数；</p><p>可以用任意一个下标把序列分割成不重叠的两部分。</p><h3 id="多维切片和省略"><a href="#多维切片和省略" class="headerlink" title="多维切片和省略"></a>多维切片和省略</h3><p>如pandas库中的df.iloc[1:3, 5:20]或者numpy库中的a[1:2, 4:5]都是多维切片。</p><p>省略是在numpy中比较有用，等学到了再用。</p><h3 id="给切片赋值"><a href="#给切片赋值" class="headerlink" title="给切片赋值"></a>给切片赋值</h3><p>如果赋值的对象是一个切片，那么赋值语句的右侧必须是一个可迭代对象。<strong>即便只有单独的一个值，也要把它转换成一个序列，如列表。</strong>例如 a[2:5] = 100是错误的，但a[2:5] = [100]就是正确的，并且只回替换a序列中第一个值为100。</p>]]></content>
    
    
    <categories>
      
      <category>技术笔记</category>
      
      <category>python</category>
      
    </categories>
    
    
    <tags>
      
      <tag>序列</tag>
      
      <tag>语法糖</tag>
      
    </tags>
    
  </entry>
  
  
  
  <entry>
    <title>[技术笔记]Python数据模型</title>
    <link href="/2020/09/09/%E6%8A%80%E6%9C%AF%E7%AC%94%E8%AE%B0-Python%E6%95%B0%E6%8D%AE%E6%A8%A1%E5%9E%8B%E4%B9%8B%E9%AD%94%E6%9C%AF%E6%96%B9%E6%B3%95/"/>
    <url>/2020/09/09/%E6%8A%80%E6%9C%AF%E7%AC%94%E8%AE%B0-Python%E6%95%B0%E6%8D%AE%E6%A8%A1%E5%9E%8B%E4%B9%8B%E9%AD%94%E6%9C%AF%E6%96%B9%E6%B3%95/</url>
    
    <content type="html"><![CDATA[<p><strong>参考代码：</strong></p><pre><code>from  math import hypotclass Vector:    def __init__(self, x=0, y=0):        self.x = x         self.y = y    def __repr__(self):        return &#39;Vector(%r,%r)&#39; % (self.x, self.y)    def __abs__(self):        return hypot(self.x, self.y)    def __add__(self, other):        y = self.y + other.y        x = self.x + other.x        return Vector(x, y)</code></pre><h3 id="字符串表现形式"><a href="#字符串表现形式" class="headerlink" title="字符串表现形式"></a>字符串表现形式</h3><p>python的一个内置函数是repr(),其本质是调用了魔术方法__repr__，它能把一个对象用字符串的形式表达出来，以便辨认。</p><p>字符串的格式化方法<strong>%和format</strong>本质上也是调用了该魔术方法。</p><p>注意点：__str__和__repr__都有讲对象字符串化的作用，但在自定义类时，应优先构造repr的魔术方法，因为如果一个对象没有str函数，而python又需要调用它时，解释器会使用repr作为替代，反之则不会。</p><h3 id="算术运算符"><a href="#算术运算符" class="headerlink" title="算术运算符"></a>算术运算符</h3><p>通过__add__可以实现+的运算，同理加入mul可以实现*的运算</p><h3 id="其他魔术方法"><a href="#其他魔术方法" class="headerlink" title="其他魔术方法"></a>其他魔术方法</h3><p>Python语言参考手册的“Data Model”一章列出了83个特殊方法，其中47个用于实现算术运算、位运算和比较操作。</p>]]></content>
    
    
    <categories>
      
      <category>技术笔记</category>
      
      <category>python</category>
      
    </categories>
    
    
    <tags>
      
      <tag>魔术方法</tag>
      
    </tags>
    
  </entry>
  
  
  
  <entry>
    <title>[学习笔记]短面板数据回归模型</title>
    <link href="/2020/09/07/%E5%AD%A6%E4%B9%A0%E7%AC%94%E8%AE%B0-%E9%9D%A2%E6%9D%BF%E6%95%B0%E6%8D%AE%E5%9B%9E%E5%BD%92%E6%A8%A1%E5%9E%8B/"/>
    <url>/2020/09/07/%E5%AD%A6%E4%B9%A0%E7%AC%94%E8%AE%B0-%E9%9D%A2%E6%9D%BF%E6%95%B0%E6%8D%AE%E5%9B%9E%E5%BD%92%E6%A8%A1%E5%9E%8B/</url>
    
    <content type="html"><![CDATA[<h2 id="面板数据的分类"><a href="#面板数据的分类" class="headerlink" title="面板数据的分类"></a>面板数据的分类</h2><h2 id="面板数据的优势"><a href="#面板数据的优势" class="headerlink" title="面板数据的优势"></a>面板数据的优势</h2><p><strong>可以处理一些不可观测的遗漏变量</strong>——如果漏掉的变量不随时间变化，则面板数据可以帮助消除遗漏变量偏差。</p><p>由上一篇笔记可知，由于各人/地/企业…各自存在一些属于自己的，影响因变量而不随时间变化的特征（异质性特征），横截面数据很难消除这些固定效应，因此选择面板数据回归模型进行处理。</p><h2 id="差分估计"><a href="#差分估计" class="headerlink" title="差分估计"></a>差分估计</h2><h3 id="两期差分模型"><a href="#两期差分模型" class="headerlink" title="两期差分模型"></a>两期差分模型</h3><p><img src="/2020/09/07/%E5%AD%A6%E4%B9%A0%E7%AC%94%E8%AE%B0-%E9%9D%A2%E6%9D%BF%E6%95%B0%E6%8D%AE%E5%9B%9E%E5%BD%92%E6%A8%A1%E5%9E%8B/1.jpg" srcset="/img/loading.gif" alt></p><h3 id="多期差分模型"><a href="#多期差分模型" class="headerlink" title="多期差分模型"></a>多期差分模型</h3><h4 id="方法一：个体中心化方法处理固定效应"><a href="#方法一：个体中心化方法处理固定效应" class="headerlink" title="方法一：个体中心化方法处理固定效应"></a>方法一：个体中心化方法处理固定效应</h4><p><img src="/2020/09/07/%E5%AD%A6%E4%B9%A0%E7%AC%94%E8%AE%B0-%E9%9D%A2%E6%9D%BF%E6%95%B0%E6%8D%AE%E5%9B%9E%E5%BD%92%E6%A8%A1%E5%9E%8B/2.jpg" srcset="/img/loading.gif" alt></p><p>其原理是针对同一样本，将其不同时期的做均值化处理，而<strong>个体与组均值的离差</strong>这个差分方程就巧妙地消除了固定效应的影响。</p><p>该方法类似于差分，但不同的是此处为’中心化’的数据，标准误也需要重新计算。</p><h4 id="方法二：’n-1个二值变量’模型"><a href="#方法二：’n-1个二值变量’模型" class="headerlink" title="方法二：’n-1个二值变量’模型"></a>方法二：’n-1个二值变量’模型</h4><p>以一个样本为基础，例如：要考虑江苏、浙江、广州三个省的面板数据，将江苏作为基础，赋予浙江一个虚拟变量ZJ，广州一个虚拟变量GZ，引入这n-1个虚拟变量就可以刻画n条截距项不同的回归直线。</p><p>优点：可以描绘出各个样本具体的异质性大小，还可以检验个体固定效应的显著性</p><p>缺点：在截面样本量很大时实现起来比较困难且耗费自由度高</p><h2 id="时间固定效应"><a href="#时间固定效应" class="headerlink" title="时间固定效应"></a>时间固定效应</h2><h3 id="定义"><a href="#定义" class="headerlink" title="定义"></a>定义</h3><p>遗漏的变量可能随时间而变化，但不随个体的变化而变化。</p><h3 id="只有时间固定效应的模型"><a href="#只有时间固定效应的模型" class="headerlink" title="只有时间固定效应的模型"></a>只有时间固定效应的模型</h3><p>将时间固定效应与截距项合并，形成一个新的截距项。</p><p>方法一：做<strong>‘年份中心化’</strong>处理：将某一时间点，这一横截面的所有数据做中心化处理，以消除这个新的截距项（固定时间点不变，对该时间点所有样本取了平均值）。</p><p>方法二：’T-1二值变量’形式</p><h3 id="同时包含个体和时间固定效应的模型"><a href="#同时包含个体和时间固定效应的模型" class="headerlink" title="同时包含个体和时间固定效应的模型"></a>同时包含个体和时间固定效应的模型</h3><p>当T=2时，继续使用一阶差分即可。</p><p>当T&gt;2时，有2*2=4种处理方法，其中最常用的时对个体中心化&amp;加入时间虚拟变量的方法。</p><h2 id="个体固定效应模型假设"><a href="#个体固定效应模型假设" class="headerlink" title="个体固定效应模型假设"></a>个体固定效应模型假设</h2><ol><li>假设一：给定某个x的所有时期的取值和该个体的固定效应时，u的均值为0</li></ol><p>该假设要求u的条件均值不依赖于任何时期的x值。</p><ol><li>假设二：个体与个体之间是要求相互独立的，但对于某一个体不同时期的相关性不做要求，即允许数据存在自相关（序列相关）性</li></ol><p>结果：OLS估计量是无偏、一致且接近正态的，但一般的OLS估计的标准误是错误的，这个问题可以通过<strong>‘群聚’</strong>解决。面板数据中群聚标准误是横截面数据中异方差—稳健标准误的推广。在面板数据中，无论是否存在异方差或序列相关，群聚标准误均有效。</p><h2 id="Hausman检验"><a href="#Hausman检验" class="headerlink" title="Hausman检验"></a>Hausman检验</h2><p>这是用来检验个体存在固定效应还是随机效应。</p><p>基本思想：<strong>在a和其他解释变量不相关假定下</strong>，采用中心化变换法估计固定效应模型和采用GLS法随机效应模型得到的参数估计都是无偏且一致的，只是前者不具有效性。<br>若原假设不成立，则固定效应模型的参数估计仍然是一致的，但随机效应模型不一致。因此，在原假设下，二者的参数估计应该不会有显著的差异，<strong>可以基于二者参数估计的差异构造统计检验量</strong>。</p><p><strong><em>H0：a和其他解释变量不相关</em></strong></p><p>注意点：当模型误差项存在序列相关或异方差时，经典的Hausman检验不再试用，需要做其他考虑。</p>]]></content>
    
    
    <categories>
      
      <category>学习笔记</category>
      
      <category>计量经济学</category>
      
    </categories>
    
    
    <tags>
      
      <tag>面板数据</tag>
      
    </tags>
    
  </entry>
  
  
  
  <entry>
    <title>[学习笔记]跨时横截面的混合：简单面板数据方法</title>
    <link href="/2020/09/07/%E5%AD%A6%E4%B9%A0%E7%AC%94%E8%AE%B0-%E8%B7%A8%E6%97%B6%E6%A8%AA%E6%88%AA%E9%9D%A2%E7%9A%84%E6%B7%B7%E5%90%88%EF%BC%9A%E7%AE%80%E5%8D%95%E9%9D%A2%E6%9D%BF%E6%95%B0%E6%8D%AE%E6%96%B9%E6%B3%95/"/>
    <url>/2020/09/07/%E5%AD%A6%E4%B9%A0%E7%AC%94%E8%AE%B0-%E8%B7%A8%E6%97%B6%E6%A8%AA%E6%88%AA%E9%9D%A2%E7%9A%84%E6%B7%B7%E5%90%88%EF%BC%9A%E7%AE%80%E5%8D%95%E9%9D%A2%E6%9D%BF%E6%95%B0%E6%8D%AE%E6%96%B9%E6%B3%95/</url>
    
    <content type="html"><![CDATA[<h2 id="跨时独立横截面的混合"><a href="#跨时独立横截面的混合" class="headerlink" title="跨时独立横截面的混合"></a>跨时独立横截面的混合</h2><h3 id="定义"><a href="#定义" class="headerlink" title="定义"></a>定义</h3><p>跨时独立混合横截面数据指的是在不同时点从一个大总体里进行随机抽样的结果，各个时期都是各自进行一次随机抽样，样本量可以不同，完全独立。这可能造成<strong>观测点不是同分布的</strong>。</p><h3 id="年度虚拟变量"><a href="#年度虚拟变量" class="headerlink" title="年度虚拟变量"></a>年度虚拟变量</h3><p>年度虚拟变量就是用来解决不同时间的观测点不是同分布问题的，即以最初一年为基年，后续几年分别设立一个虚拟变量，容许截距项甚至斜率（通过交互项）随时间的改变而改变。</p><h3 id="利用混合截面做政策分析"><a href="#利用混合截面做政策分析" class="headerlink" title="利用混合截面做政策分析"></a>利用混合截面做政策分析</h3><p>当某些外生事件（常常是政府的政策改变）改变了个人、家庭、企业或城市运行的环境时，便产生了<strong>自然实验</strong>。可以用混合截面的处理方法来处理自然实验的数据。</p><h2 id="两时期面板数据分析"><a href="#两时期面板数据分析" class="headerlink" title="两时期面板数据分析"></a>两时期面板数据分析</h2><h3 id="一些名词解释"><a href="#一些名词解释" class="headerlink" title="一些名词解释"></a>一些名词解释</h3><p><img src="/2020/09/07/%E5%AD%A6%E4%B9%A0%E7%AC%94%E8%AE%B0-%E8%B7%A8%E6%97%B6%E6%A8%AA%E6%88%AA%E9%9D%A2%E7%9A%84%E6%B7%B7%E5%90%88%EF%BC%9A%E7%AE%80%E5%8D%95%E9%9D%A2%E6%9D%BF%E6%95%B0%E6%8D%AE%E6%96%B9%E6%B3%95/1.jpg" srcset="/img/loading.gif" alt></p><ol><li><strong>非观测效应（固定效应）</strong>：指变量a这样影响着y但又不随时间而变化的所有无法观测的因素</li><li><strong>特异性误差（时变误差）</strong>：指误差u这样因时而便影响着y的所有无法观测的因素</li><li><strong>异质性偏误</strong>：遗漏了固定效应而造成的误差，存在遗漏变量问题</li></ol><h3 id="一阶差分方程"><a href="#一阶差分方程" class="headerlink" title="一阶差分方程"></a>一阶差分方程</h3><p><img src="/2020/09/07/%E5%AD%A6%E4%B9%A0%E7%AC%94%E8%AE%B0-%E8%B7%A8%E6%97%B6%E6%A8%AA%E6%88%AA%E9%9D%A2%E7%9A%84%E6%B7%B7%E5%90%88%EF%BC%9A%E7%AE%80%E5%8D%95%E9%9D%A2%E6%9D%BF%E6%95%B0%E6%8D%AE%E6%96%B9%E6%B3%95/2.jpg" srcset="/img/loading.gif" alt></p><p>（13.17）就被称为一阶差分方程，相应的系数被称为一阶差分估计量（<em>first-differenced estimator</em>）。</p>]]></content>
    
    
    <categories>
      
      <category>学习笔记</category>
      
      <category>计量经济学</category>
      
    </categories>
    
    
    <tags>
      
      <tag>面板数据</tag>
      
      <tag>混合横截面</tag>
      
    </tags>
    
  </entry>
  
  
  
  <entry>
    <title>[学习笔记]计量小复习</title>
    <link href="/2020/09/07/%E5%AD%A6%E4%B9%A0%E7%AC%94%E8%AE%B0-%E8%AE%A1%E9%87%8F%E5%B0%8F%E5%A4%8D%E4%B9%A0/"/>
    <url>/2020/09/07/%E5%AD%A6%E4%B9%A0%E7%AC%94%E8%AE%B0-%E8%AE%A1%E9%87%8F%E5%B0%8F%E5%A4%8D%E4%B9%A0/</url>
    
    <content type="html"><![CDATA[<p>1、<strong>方差膨胀因子（VIF）</strong>：测度某一自变量是否存在多重共线性，一般认为VIF&gt;10则存在较强的多重共线性，VIF&gt;100则存在严重的多重共线性。</p><p>2、<strong>含ln的回归系数的解释</strong>：</p><p>lny = alnx x变动1%，y变动a%</p><p>lny = ax x变动1，y变动100a%</p><p>y = alnx x变动1%，y变动a/100</p><p>3、<strong>Wald Test注意点</strong>：在WT中，c(n)的n是从1开始的，不是从0开始的。</p><p>4、<strong>异方差性注意点</strong>：异方差性不会改变系数的无偏性，也不会对拟合优度产生影响，但会造成假设检验无效。</p><p>4.1 检验异方差的方法：<strong>BP检验</strong>（布罗施-帕甘异方差检验），原理是检验残差平方和各自变量的线性关系；<strong>WHite检验</strong>（怀特检验），是BP检验的升级版，加上了一些非线性关系，但会消耗大量的自由度。</p><p>EViwes操作：eq01—View—Residual Diagnostics—Heteroskedasticity Test（怀特检验是在此基础上勾选<em>Include White cross terms</em>）</p><p>4.2 异方差修正的方法：稳健标准误法；加权最小二乘法（WLS），一定要知道异方差的具体形式才好用。</p><p>5、工具变量注意点：是对遗漏变量的另一种解决方法，有点复杂，等用到了再重新复习。</p>]]></content>
    
    
    <categories>
      
      <category>学习笔记</category>
      
      <category>计量经济学</category>
      
    </categories>
    
    
    <tags>
      
      <tag>计量经济学</tag>
      
    </tags>
    
  </entry>
  
  
  
  <entry>
    <title>[技术笔记]pandas学习小笔记1</title>
    <link href="/2020/08/30/%E6%8A%80%E6%9C%AF%E7%AC%94%E8%AE%B0-pandas%E5%AD%A6%E4%B9%A0%E5%B0%8F%E7%AC%94%E8%AE%B01/"/>
    <url>/2020/08/30/%E6%8A%80%E6%9C%AF%E7%AC%94%E8%AE%B0-pandas%E5%AD%A6%E4%B9%A0%E5%B0%8F%E7%AC%94%E8%AE%B01/</url>
    
    <content type="html"><![CDATA[<p>1、在使用<strong>pd.to_datetime()</strong>替换相关数据时，可能<em>df[XXX] = pd.to_datetime(df[XXX])</em>还是很好想到的，但如要对df的行标签进行转换，就应该是<em>df.index = pd.to_datetime(df.index)</em>这样子。</p><p>2、<strong>当要删除某些具有特定数据的行或者列时</strong>，应该使用df.replace()和df.dropna()结合的方法。</p><p>如想要删除那些全是0的列，可以写如下代码：</p><pre><code>df.replace(0, np.nan, inplace = True)cleaned = df.dropna()</code></pre><p>3、除了一般情况下的直接赋值，大部分情况下函数和方法都有<strong>inplace = True</strong>的属性，不说pd下的方法，就是set_index,fillna,dropna这些Series和DataFrame自带的方法都有inplace属性。</p><p>一个技巧：在jupyter notebook下，打出这样一行代码，直接产生交互的表格之类的，说明这就是一个新的表格，想要其直接继承就表格，就要使用inplace = True。</p><p>4、<strong>删除某行/列的两种方法：</strong>1.如果只想删除列，在df中，用del df[XXX]即可。 2.如果想对行或者列进行操作，则使用df.drop(‘’,axis = XXX, inpalace = XXX)</p><p>5、<strong>检查是否有缺失数据：</strong>对于比较小的数据量，直接使用df.isnull()即可，但是对于很大的数据量，df中间一些数据是省略的，这样做非常不直观。</p><p>所以在这里使用：<strong>df.isnull().sum()</strong>,直接就输出各列存在的缺失值数(因为Flase对应的是0，True对应的是1，全是False则自然是0，没有缺失值)。</p><p>6、<strong>Reset the index so it begins with 0 again:</strong> df.reset_index(drop = True,inplace = True)</p><p>7、<strong>解决使用drop方法删除多列时想要使用列整数索引指定而不是列索引名指定的问题</strong>：</p><p>问题描述：在使用df.drop()方法时，若要删除多行/列，只能输入一个包含行/列名的列表，而不能输入一个整数索引的列表，在使用整数索引更方便的时候就很难搞。</p><p>解决思想：我们可以把整数索引通过某种方式转换成名称组成的索引，再带入drop()中。</p><p>解决方法：若要删除df的1，3，7，9列，则应使用df.drop(df.columns[[0,2,6,8]], axis = 1)，巧妙地将整数索引进行了转化。</p><p>8、关于loc的优化</p><p>平常我们可能使用的是df.loc[1],df.loc[‘xxx’]这样的形式，但其实<strong>women = train.loc[train.Sex == ‘female’,”Survived”]</strong>这样将a condition expression带进去。</p><p>所以除了column names, row labels，这里用这种方法能够更加specific地索引一些需要的值。</p><p>9、stack与unstack</p><p><strong>unstack()可以将一个多级索引的Series转换成普通的DataFrame；stack()可以将一个普通的DataFrame转换成多级索引的Series。</strong></p><p>10、多级索引中只取其中一级</p><p>在一些涉及画图或者机器学习的问题中，我们可能前期通过groupby构造了一个多级索引，但是要画图的时候，不需要用到一级索引，而只需要二级索引，此时就需要找到一种针对MultiIndex此类对象的方法。网上查阅可知，若要取二级索引，<strong>可以使用df.index.get_level_values(1)或者df.index.get_level_values(‘#index_name#’)</strong>选取所需索引。</p>]]></content>
    
    
    <categories>
      
      <category>技术笔记</category>
      
      <category>python</category>
      
    </categories>
    
    
    <tags>
      
      <tag>pandas</tag>
      
    </tags>
    
  </entry>
  
  
  
  <entry>
    <title>[技术笔记]重装硬盘后安装软件遇到的各种问题及解决办法</title>
    <link href="/2020/08/17/%E6%8A%80%E6%9C%AF%E7%AC%94%E8%AE%B0-%E9%87%8D%E8%A3%85%E7%B3%BB%E7%BB%9F%E5%90%8E%E5%AE%89%E8%A3%85%E8%BD%AF%E4%BB%B6%E9%81%87%E5%88%B0%E7%9A%84%E5%90%84%E7%A7%8D%E9%97%AE%E9%A2%98%E5%8F%8A%E8%A7%A3%E5%86%B3%E5%8A%9E%E6%B3%95/"/>
    <url>/2020/08/17/%E6%8A%80%E6%9C%AF%E7%AC%94%E8%AE%B0-%E9%87%8D%E8%A3%85%E7%B3%BB%E7%BB%9F%E5%90%8E%E5%AE%89%E8%A3%85%E8%BD%AF%E4%BB%B6%E9%81%87%E5%88%B0%E7%9A%84%E5%90%84%E7%A7%8D%E9%97%AE%E9%A2%98%E5%8F%8A%E8%A7%A3%E5%86%B3%E5%8A%9E%E6%B3%95/</url>
    
    <content type="html"><![CDATA[<h3 id="win10安装nodejs，报错there-is-a-problem-in-the-windows-installer-package…"><a href="#win10安装nodejs，报错there-is-a-problem-in-the-windows-installer-package…" class="headerlink" title="win10安装nodejs，报错there is a problem in the windows installer package…"></a>win10安装nodejs，报错there is a problem in the windows installer package…</h3><p>原因：win10和win8下必须以管理员模式打开此exe文件。</p><p>解决方法：首先以管理员身份打开cmd，将cmd路径通过cd方法转到nodejs.exe所在文件夹，再通过c：和键入文件名（注意要加后缀.msi）打开此程序。</p><h3 id="markdownpad2没有预览界面，一打文字就报错"><a href="#markdownpad2没有预览界面，一打文字就报错" class="headerlink" title="markdownpad2没有预览界面，一打文字就报错"></a>markdownpad2没有预览界面，一打文字就报错</h3><p>原因：装markdownpad的时候少装了一个html的渲染文件。</p><p>解决方法：补装一个即可。<a href="https://pan.baidu.com/s/1Gs1raE_8L0-A9oWSpGOIhg" target="_blank" rel="noopener">地址</a></p><p>提取码：qd0x</p><h3 id="迁移之前的python环境"><a href="#迁移之前的python环境" class="headerlink" title="迁移之前的python环境"></a>迁移之前的python环境</h3><p>原因：把库再装一遍太折磨了，建议是迁移一下环境。</p><p>解决方法：在原电脑上git下输入：</p><pre><code>pip freeze &gt; requirements.txt #会在当前目录下创建一个txt文档，保存了所有环境信息，可能会报错，不用管它。</code></pre><p>把这个文件转移到新电脑，git下输入：</p><pre><code>pip install -r requirements.txt #然后git就开始进行缓慢的拷贝过程了- -，它其实是去网上找所有的库再下载一遍，不是完全意义上的拷贝，然而此刻我却发现，我没有把pip换源...难怪下载速度这么慢，建议是换源了再下载。</code></pre><h3 id="把pip换成国内源"><a href="#把pip换成国内源" class="headerlink" title="把pip换成国内源"></a>把pip换成国内源</h3><p>原因：默认的源下载太慢了，除非时刻开着vpn…</p><p>解决方法：</p><pre><code>pip config set global.index-url https://mirrors.aliyun.com/pypi/simple/</code></pre>]]></content>
    
    
    
    <tags>
      
      <tag>git</tag>
      
      <tag>nodejs</tag>
      
      <tag>markdownpad2</tag>
      
      <tag>pip</tag>
      
    </tags>
    
  </entry>
  
  
  
  <entry>
    <title>Hello World</title>
    <link href="/2020/08/17/hello-world/"/>
    <url>/2020/08/17/hello-world/</url>
    
    <content type="html"><![CDATA[<p>Welcome to <a href="https://hexo.io/" target="_blank" rel="noopener">Hexo</a>! This is your very first post. Check <a href="https://hexo.io/docs/" target="_blank" rel="noopener">documentation</a> for more info. If you get any problems when using Hexo, you can find the answer in <a href="https://hexo.io/docs/troubleshooting.html" target="_blank" rel="noopener">troubleshooting</a> or you can ask me on <a href="https://github.com/hexojs/hexo/issues" target="_blank" rel="noopener">GitHub</a>.</p><h2 id="Quick-Start"><a href="#Quick-Start" class="headerlink" title="Quick Start"></a>Quick Start</h2><h3 id="Create-a-new-post"><a href="#Create-a-new-post" class="headerlink" title="Create a new post"></a>Create a new post</h3><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><code class="hljs bash">$ hexo new <span class="hljs-string">"My New Post"</span><br></code></pre></td></tr></table></figure><p>More info: <a href="https://hexo.io/docs/writing.html" target="_blank" rel="noopener">Writing</a></p><h3 id="Run-server"><a href="#Run-server" class="headerlink" title="Run server"></a>Run server</h3><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><code class="hljs bash">$ hexo server<br></code></pre></td></tr></table></figure><p>More info: <a href="https://hexo.io/docs/server.html" target="_blank" rel="noopener">Server</a></p><h3 id="Generate-static-files"><a href="#Generate-static-files" class="headerlink" title="Generate static files"></a>Generate static files</h3><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><code class="hljs bash">$ hexo generate<br></code></pre></td></tr></table></figure><p>More info: <a href="https://hexo.io/docs/generating.html" target="_blank" rel="noopener">Generating</a></p><h3 id="Deploy-to-remote-sites"><a href="#Deploy-to-remote-sites" class="headerlink" title="Deploy to remote sites"></a>Deploy to remote sites</h3><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><code class="hljs bash">$ hexo deploy<br></code></pre></td></tr></table></figure><p>More info: <a href="https://hexo.io/docs/one-command-deployment.html" target="_blank" rel="noopener">Deployment</a></p>]]></content>
    
    
    
  </entry>
  
  
  
  <entry>
    <title>[技术笔记]一些常用库的引入规定（持续更新）</title>
    <link href="/2020/08/13/%E6%8A%80%E6%9C%AF%E7%AC%94%E8%AE%B0-%E4%B8%80%E4%BA%9B%E5%B8%B8%E7%94%A8%E5%BA%93%E7%9A%84%E5%BC%95%E5%85%A5%E8%A7%84%E5%AE%9A%EF%BC%88%E6%8C%81%E7%BB%AD%E6%9B%B4%E6%96%B0%EF%BC%89/"/>
    <url>/2020/08/13/%E6%8A%80%E6%9C%AF%E7%AC%94%E8%AE%B0-%E4%B8%80%E4%BA%9B%E5%B8%B8%E7%94%A8%E5%BA%93%E7%9A%84%E5%BC%95%E5%85%A5%E8%A7%84%E5%AE%9A%EF%BC%88%E6%8C%81%E7%BB%AD%E6%9B%B4%E6%96%B0%EF%BC%89/</url>
    
    <content type="html"><![CDATA[<pre><code>import pandas as pdfrom pandas import Series, DataFrameimport matplotlib.pyplot as plt # 常用的绘图库from datetime import datetime/date/time/timedelta # python标准库里常用的时间方法from dateutil.parser import prase # pandas自动安装的时间包，parse方法可以解析几乎所有人类能够理解的日期表达形式import pytz #下载pandas自带的一个时区库from sklearn.tree import DecisionTreeRegressor #引用决策树模型from sklearn.model_Selection import train_test_split #用于在将数据带入模型前先将清理好的数据分成train类和test类from sklearn.metrics import mean_absolute_error # 引入平均绝对离差from sklearn.ensamble import RandomForestRegressor # 引入随机森林模型from sklearn.linear_model import LinearRegression #引入简单线性回归模型from sklearn.naive_bayes import GaussainNB #引入高斯朴素贝叶斯模型from sklearn.metrics import accuracy_score #引入准确率预测工具from sklearn.decomposition import PCA #引入主成分分析模型from sklearn.mixture import GMM #引入高斯混合模型</code></pre>]]></content>
    
    
    <categories>
      
      <category>技术笔记</category>
      
      <category>python</category>
      
    </categories>
    
    
    <tags>
      
      <tag>常用库</tag>
      
    </tags>
    
  </entry>
  
  
  
  <entry>
    <title>[技术笔记]plt.plot()的marker、color、linestyle参数</title>
    <link href="/2020/08/04/%E6%8A%80%E6%9C%AF%E7%AC%94%E8%AE%B0-plt-plot-%E7%9A%84marker%E3%80%81color%E3%80%81linestyle%E5%8F%82%E6%95%B0/"/>
    <url>/2020/08/04/%E6%8A%80%E6%9C%AF%E7%AC%94%E8%AE%B0-plt-plot-%E7%9A%84marker%E3%80%81color%E3%80%81linestyle%E5%8F%82%E6%95%B0/</url>
    
    <content type="html"><![CDATA[<p><em>ax.plot(x, y, ‘g—‘)</em>和<em>ax.plot(x, y, linestyle=’—‘, color=’g’)</em>是等价的，前者通过格式字符串书写，较为简单，其格式可以为：</p><pre><code>fmt = &#39;[marker][line][color]&#39;</code></pre><p>或者：</p><pre><code>fmt = &#39;[color][marker][line]&#39;</code></pre><p>当然也可以通过color(c) = …, linestyle(ls) = …, marker = …获得。三者的具体常用标记如下：</p><h3 id="Colors"><a href="#Colors" class="headerlink" title="Colors"></a>Colors</h3><div class="table-container"><table><thead><tr><th>character</th><th>color</th></tr></thead><tbody><tr><td>‘b’</td><td>blue</td></tr><tr><td>‘g’</td><td>green</td></tr><tr><td>‘r’</td><td>red</td></tr><tr><td>‘c’</td><td>青色</td></tr><tr><td>‘m’</td><td>品红</td></tr><tr><td>‘y’</td><td>yellow</td></tr><tr><td>‘k’</td><td>black</td></tr><tr><td>‘w’</td><td>white</td></tr></tbody></table></div><p>如果颜色是格式字符串的唯一部分，则可以另外使用任何<a href="https://matplotlib.org/api/colors_api.html#module-matplotlib.colors" target="_blank" rel="noopener">matplotlib.colors</a>规格，例如全名（’green’）或十六进制字符串（’#008000’）。</p><h3 id="Markers"><a href="#Markers" class="headerlink" title="Markers"></a>Markers</h3><div class="table-container"><table><thead><tr><th>character</th><th>marker</th></tr></thead><tbody><tr><td>‘.’</td><td>点标记</td></tr><tr><td>‘,’</td><td>像素标记</td></tr><tr><td>‘o’</td><td>圆圈标记</td></tr><tr><td>‘v’</td><td>triangle_down标记</td></tr><tr><td>‘^’</td><td>三角形标记</td></tr><tr><td>‘&lt;’</td><td>triangle_left标记</td></tr><tr><td>‘&gt;’</td><td>triangle_right标记</td></tr><tr><td>‘1’</td><td>tri_down标记</td></tr><tr><td>‘2’</td><td>tri_up标记</td></tr><tr><td>‘3’</td><td>tri_left标记</td></tr><tr><td>‘4’</td><td>tri_right标记</td></tr><tr><td>‘s’</td><td>方形标记</td></tr><tr><td>‘p’</td><td>五边形标记</td></tr><tr><td>‘*’</td><td>星标</td></tr><tr><td>‘h’</td><td>六角形标记1</td></tr><tr><td>‘H’</td><td>六角形标记2</td></tr><tr><td>‘+’</td><td>加号</td></tr><tr><td>‘x’</td><td>X标记</td></tr><tr><td>‘D’</td><td>钻石标记</td></tr><tr><td>‘d’</td><td>小钻石标记</td></tr><tr><td>‘_’</td><td>水平线标记</td></tr></tbody></table></div><h3 id="Linestyles"><a href="#Linestyles" class="headerlink" title="Linestyles"></a>Linestyles</h3><div class="table-container"><table><thead><tr><th>character</th><th>linestyle</th></tr></thead><tbody><tr><td>‘-‘</td><td>实线</td></tr><tr><td>‘—‘</td><td>虚线</td></tr><tr><td>‘-.’</td><td>点划线</td></tr><tr><td>‘:’</td><td>点线</td></tr></tbody></table></div>]]></content>
    
    
    <categories>
      
      <category>技术笔记</category>
      
      <category>python</category>
      
    </categories>
    
    
    <tags>
      
      <tag>matplotlib</tag>
      
    </tags>
    
  </entry>
  
  
  
  <entry>
    <title>[技术笔记]Jupyter Notebook 和绘图有关的几个魔术指令（%matplotlib inline, auto, notebook）</title>
    <link href="/2020/08/02/%E6%8A%80%E6%9C%AF%E7%AC%94%E8%AE%B0-Jupyter-Notebook-%E5%92%8C%E7%BB%98%E5%9B%BE%E6%9C%89%E5%85%B3%E7%9A%84%E5%87%A0%E4%B8%AA%E9%AD%94%E6%9C%AF%E6%8C%87%E4%BB%A4%EF%BC%88-matplotlib-inline-auto-notebook%EF%BC%89/"/>
    <url>/2020/08/02/%E6%8A%80%E6%9C%AF%E7%AC%94%E8%AE%B0-Jupyter-Notebook-%E5%92%8C%E7%BB%98%E5%9B%BE%E6%9C%89%E5%85%B3%E7%9A%84%E5%87%A0%E4%B8%AA%E9%AD%94%E6%9C%AF%E6%8C%87%E4%BB%A4%EF%BC%88-matplotlib-inline-auto-notebook%EF%BC%89/</url>
    
    <content type="html"><![CDATA[<p>Jupyter notebook默认输出的图片是静态的，无法进行放大等操作，可以添加一条魔术指令：</p><pre><code>%matplotlib notebook</code></pre><p>这样就能够在notebook中进行放大缩小等交互操作了。</p><p>在notebook中使用plt绘图共有三种模式：</p><ol><li>%matplotlib inline：这是默认的模式，输出的图片是静态的</li><li>%matplotlib auto：在这个模式下会弹出一个单独 的绘图窗口，和在pycharm中一样</li><li>%matplotlib notebook：在这个模式下会在notebook中产生一个绘图窗口，能够对图片进行放大缩小等操作。</li></ol><p>注：本文为转载，原文链接：<a href="https://blog.csdn.net/qq_26822029/article/details/103064856" target="_blank" rel="noopener">https://blog.csdn.net/qq_26822029/article/details/103064856</a></p>]]></content>
    
    
    <categories>
      
      <category>技术笔记</category>
      
      <category>python</category>
      
    </categories>
    
    
    <tags>
      
      <tag>Jupyter Notebook</tag>
      
      <tag>转载</tag>
      
    </tags>
    
  </entry>
  
  
  
  <entry>
    <title>[技术笔记]pandas中常用的汇总和统计方法</title>
    <link href="/2020/07/30/%E6%8A%80%E6%9C%AF%E7%AC%94%E8%AE%B0-pandas%E4%B8%AD%E5%B8%B8%E7%94%A8%E7%9A%84%E6%B1%87%E6%80%BB%E5%92%8C%E7%BB%9F%E8%AE%A1%E6%96%B9%E6%B3%95/"/>
    <url>/2020/07/30/%E6%8A%80%E6%9C%AF%E7%AC%94%E8%AE%B0-pandas%E4%B8%AD%E5%B8%B8%E7%94%A8%E7%9A%84%E6%B1%87%E6%80%BB%E5%92%8C%E7%BB%9F%E8%AE%A1%E6%96%B9%E6%B3%95/</url>
    
    <content type="html"><![CDATA[<div class="table-container"><table><thead><tr><th>方法</th><th>说明</th></tr></thead><tbody><tr><td>count</td><td>计算非NA值的数量</td></tr><tr><td>describe</td><td>汇总统计</td></tr><tr><td>min、max</td><td>计算最大最小值</td></tr><tr><td>argmin、argmax</td><td>最大最小值所在的索引位置（整数）</td></tr><tr><td>idxmin、idxmax</td><td>最大最小值所在的索引标签</td></tr><tr><td>quantile</td><td>计算样本的分位数</td></tr><tr><td>sum</td><td>值的总和</td></tr><tr><td>mean</td><td>值的平均数</td></tr><tr><td>median</td><td>值的算术中位数</td></tr><tr><td>mad</td><td>平均绝对离差</td></tr><tr><td>var</td><td>方差</td></tr><tr><td>std</td><td>标准差</td></tr><tr><td>skew</td><td>偏度</td></tr><tr><td>kurt</td><td>峰度</td></tr><tr><td>cumsum</td><td>累计和</td></tr><tr><td>cummin、cummax</td><td>累计最大值和累计最小值</td></tr><tr><td>cumprod</td><td>累计积</td></tr><tr><td>diff</td><td>一阶差分</td></tr><tr><td>pct_change</td><td>百分数变化</td></tr></tbody></table></div><p><sup id="fnref:1" class="footnote-ref"><a href="#fn:1" rel="footnote"><span class="hint--top hint--rounded" aria-label="上述统计方法都是基于样本而言，自由度为N-1">[1]</span></a></sup></p><p>注释：</p><section class="footnotes"><div class="footnote-list"><ol><li><span id="fn:1" class="footnote-text"><span>上述统计方法都是基于样本而言，自由度为N-1<a href="#fnref:1" rev="footnote" class="footnote-backref"> ↩</a></span></span></li></ol></div></section>]]></content>
    
    
    <categories>
      
      <category>技术笔记</category>
      
      <category>python</category>
      
    </categories>
    
    
    <tags>
      
      <tag>统计</tag>
      
    </tags>
    
  </entry>
  
  
  
  <entry>
    <title>[技术笔记]dataframe.apply和groupby.apply的区别</title>
    <link href="/2020/07/28/%E6%8A%80%E6%9C%AF%E7%AC%94%E8%AE%B0-dataframe-apply%E5%92%8Cgroupby-apply%E7%9A%84%E5%8C%BA%E5%88%AB/"/>
    <url>/2020/07/28/%E6%8A%80%E6%9C%AF%E7%AC%94%E8%AE%B0-dataframe-apply%E5%92%8Cgroupby-apply%E7%9A%84%E5%8C%BA%E5%88%AB/</url>
    
    <content type="html"><![CDATA[<p>在看书学习apply函数的过程中，我发现书上还是比较集中于讲解apply在groupby分组、聚合这方面的作用，如下面这个用特定于分组的值填充缺失值<sup id="fnref:1" class="footnote-ref"><a href="#fn:1" rel="footnote"><span class="hint--top hint--rounded" aria-label="参考了书上代码">[1]</span></a></sup>：<br>    In [91]: s = pd.Series(np.random.randn(6))</p><pre><code>In [92]: s[::2] = np.nanIn [93]: sOut[93]: 0         NaN1   -0.1259212         NaN3   -0.8844754         NaN5    0.227290dtype: float64In [94]: s.fillna(s.mean())Out[94]: 0   -0.2610351   -0.1259212   -0.2610353   -0.8844754   -0.2610355    0.227290dtype: float64</code></pre><p>这里用mean()函数对整体做了平均，而事实上我们大多数时候可能需要对各分组赋予不同的填充值，于是可以用以下方法实现填充：</p><p>假设你需要对不同的分组填充不同的值。一种方法是将数据分组，并使用apply和一个能够对各数据块调用fillna的函数即可。下面是一些有关美国几个州的示例数据，这些州又被分为东部和西部：</p><pre><code>In [95]: states = [&#39;Ohio&#39;, &#39;New York&#39;, &#39;Vermont&#39;, &#39;Florida&#39;,   ....:           &#39;Oregon&#39;, &#39;Nevada&#39;, &#39;California&#39;, &#39;Idaho&#39;]In [96]: group_key = [&#39;East&#39;] * 4 + [&#39;West&#39;] * 4In [97]: data = pd.Series(np.random.randn(8), index=states)In [98]: dataOut[98]: Ohio          0.922264New York     -2.153545Vermont      -0.365757Florida      -0.375842Oregon        0.329939Nevada        0.981994California    1.105913Idaho        -1.613716dtype: float64#将一些数据点设置为缺失值In [99]: data[[&#39;Vermont&#39;, &#39;Nevada&#39;, &#39;Idaho&#39;]] = np.nanIn [100]: dataOut[100]: Ohio          0.922264New York     -2.153545Vermont            NaNFlorida      -0.375842Oregon        0.329939Nevada             NaNCalifornia    1.105913Idaho              NaNdtype: float64In [101]: data.groupby(group_key).mean()Out[101]: East   -0.535707West    0.717926dtype: float64</code></pre><p>接下来可以用分组平均值去填充NA：</p><pre><code>In [102]: fill_mean = lambda g: g.fillna(g.mean())In [103]: data.groupby(group_key).apply(fill_mean)Out[103]: Ohio          0.922264New York     -2.153545Vermont      -0.535707Florida      -0.375842Oregon        0.329939Nevada        0.717926California    1.105913Idaho         0.717926dtype: float64</code></pre><p>可以看出，当apply函数作用与groupby时，<strong>他的对象就是groupby()中的分组键，或者更确切地说，是分组键分割开来的各个组</strong>，因此，apply中函数的对象也应该就考虑是一个dataframe或者series。</p><p>但这一点再直接应用到DataFrame时就有所不同，<strong>此时apply中函数的对象是dataframe的一列或者一行的每一个元素。</strong></p><p><img src="/2020/07/28/%E6%8A%80%E6%9C%AF%E7%AC%94%E8%AE%B0-dataframe-apply%E5%92%8Cgroupby-apply%E7%9A%84%E5%8C%BA%E5%88%AB/1.jpg" srcset="/img/loading.gif" alt></p><p><strong>可以看到majority函数的x的对象就是column age的每一个元素。</strong></p><p>参考：</p><section class="footnotes"><div class="footnote-list"><ol><li><span id="fn:1" class="footnote-text"><span>参考了书上代码<a href="#fnref:1" rev="footnote" class="footnote-backref"> ↩</a></span></span></li></ol></div></section>]]></content>
    
    
    <categories>
      
      <category>技术笔记</category>
      
      <category>python</category>
      
    </categories>
    
    
    <tags>
      
      <tag>apply()函数</tag>
      
    </tags>
    
  </entry>
  
  
  
  <entry>
    <title>[学习笔记]综合评价模型</title>
    <link href="/2020/07/27/%E5%AD%A6%E4%B9%A0%E7%AC%94%E8%AE%B0-%E7%BB%BC%E5%90%88%E8%AF%84%E4%BB%B7%E6%A8%A1%E5%9E%8B/"/>
    <url>/2020/07/27/%E5%AD%A6%E4%B9%A0%E7%AC%94%E8%AE%B0-%E7%BB%BC%E5%90%88%E8%AF%84%E4%BB%B7%E6%A8%A1%E5%9E%8B/</url>
    
    <content type="html"><![CDATA[<p>综合评价问题：综合考虑事物的多个指标所包含的信息，对各个备选决策方案优劣进行排序，最终选出最优方案。</p><p>主要步骤：（1）选择综合评价指标（不遗漏、不重复、尽可能独立）；（2）确定各参评方案的指标值，形成决策矩阵；（3）指标值预处理（目的：消除指标值在单位、数量级、方向性三个方面的差异）；（4）确定各项指标的权重系数（重要程度）；（5）对预处理后的指标值进行加权综合，给出各方案的综合得分，按照综合得分对各个参评方案进行优劣排序。</p><p>评价方法分类：（1）主观复权法：综合指数法、模糊综合评判法、层次分析法、功效系数法等。（2）客观赋权法：主成分分析法、因子分析法、熵权法、理想解法（TOPSIS法）等。</p><h2 id="层次分析法（AHP）"><a href="#层次分析法（AHP）" class="headerlink" title="层次分析法（AHP）"></a>层次分析法（AHP）</h2><p>假设有n个指标，我们虽然不知道他们的各自重要程度（权重），但知道它们的重要程度之比，则可以以这个比值建立一个成对比较矩阵A，根据矩阵获得各个指标的权重。</p><p>根据特征向量的定义，可以得出这个矩<strong>阵A具有特征值n和特征向量W = (W1,W2,W3,W4….Wn).T</strong>。</p><p><img src="/2020/07/27/%E5%AD%A6%E4%B9%A0%E7%AC%94%E8%AE%B0-%E7%BB%BC%E5%90%88%E8%AF%84%E4%BB%B7%E6%A8%A1%E5%9E%8B/1.jpg" srcset="/img/loading.gif" alt></p><p>并且有定理：1、A的秩为1，A的唯一非零特征值为n；2、A的任一列向量都是对应于特征值n 的特征向量。在此定理下，对任一列向量归一化后，就给出了这n个指标的权重的真实值。</p><p><strong>比值的确定就是主观的</strong>,Saaty等人提出1~9尺度——aij 取值1,2,… , 9及其互反数1,1/2, … , 1/9，因为心理学家认为成对比较的因素不宜超过9个。需要注意的是，对影响因素为负的指标，要提前做处理，不然性质不符，无法使用此方法。</p><p>性质1和性质2是较好满足的，但性质3这种传递性在主观下很难满足。但Saaty认为，我们在实际操作时不需要完全满足一致性，只要能通过<strong>一致性检验</strong>即可。</p><h3 id="一致性检验"><a href="#一致性检验" class="headerlink" title="一致性检验"></a>一致性检验</h3><p><img src="/2020/07/27/%E5%AD%A6%E4%B9%A0%E7%AC%94%E8%AE%B0-%E7%BB%BC%E5%90%88%E8%AF%84%E4%BB%B7%E6%A8%A1%E5%9E%8B/2.png" srcset="/img/loading.gif" alt></p><p>CI越大，不一致越严重。为衡量CI的大小，引入随机一致性指标RI——随机模拟得到aij, 形成A，计算CI即得RI。</p><p>令<strong>CR = CI/RI</strong>，一般认为当CR&lt;0.1时，通过一致性检验。</p><h2 id="熵权法"><a href="#熵权法" class="headerlink" title="熵权法"></a>熵权法</h2><p>熵权法是一种<strong>客观赋权法</strong>，基础是各项指标都已经量化好，利用指标值数据的离散程度来确定各项指标在综合评价中的权重，离散程度越大，该项指标权重越大。</p><p>在信息论中，熵是对不确定性的一种度量。不确定性越大，熵就越小。</p><h3 id="step1：数据预处理"><a href="#step1：数据预处理" class="headerlink" title="step1：数据预处理"></a>step1：数据预处理</h3><p><img src="/2020/07/27/%E5%AD%A6%E4%B9%A0%E7%AC%94%E8%AE%B0-%E7%BB%BC%E5%90%88%E8%AF%84%E4%BB%B7%E6%A8%A1%E5%9E%8B/2.jpg" srcset="/img/loading.gif" alt></p><h3 id="step2：数据归一化"><a href="#step2：数据归一化" class="headerlink" title="step2：数据归一化"></a>step2：数据归一化</h3><p>让各个指标数据的和为1，即Pi = Yi / （Y1+Y2+Y3+….+Yn）。</p><h3 id="step3：计算第j项指标的熵"><a href="#step3：计算第j项指标的熵" class="headerlink" title="step3：计算第j项指标的熵"></a>step3：计算第j项指标的熵</h3><p><img src="/2020/07/27/%E5%AD%A6%E4%B9%A0%E7%AC%94%E8%AE%B0-%E7%BB%BC%E5%90%88%E8%AF%84%E4%BB%B7%E6%A8%A1%E5%9E%8B/3.png" srcset="/img/loading.gif" alt></p><h3 id="step4：计算指标的离散程度并计算权重"><a href="#step4：计算指标的离散程度并计算权重" class="headerlink" title="step4：计算指标的离散程度并计算权重"></a>step4：计算指标的离散程度并计算权重</h3><p>令Dj = 1 - Ej（因为熵越大，不确定性越小），接下来再把各个指标的离散程度归一化处理。</p><h3 id="step6：计算结果并排序"><a href="#step6：计算结果并排序" class="headerlink" title="step6：计算结果并排序"></a>step6：计算结果并排序</h3><h2 id="理想点法"><a href="#理想点法" class="headerlink" title="理想点法"></a>理想点法</h2><p>理想点法是综合各个方案与理想的最优方案以及最差方案之间的距离，对各个方案的优劣进行排序，与最优方案越接近同时与最差方案距离越远的方案，综合得分越高。</p><h3 id="step1：数据的预处理"><a href="#step1：数据的预处理" class="headerlink" title="step1：数据的预处理"></a>step1：数据的预处理</h3><p>方法有很多，此处就不再赘述了。</p><h3 id="step2：确定各个指标的权重"><a href="#step2：确定各个指标的权重" class="headerlink" title="step2：确定各个指标的权重"></a>step2：确定各个指标的权重</h3><p>可以用所有用于确定指标权重的方法。</p><h3 id="step3：计算加权的指标值"><a href="#step3：计算加权的指标值" class="headerlink" title="step3：计算加权的指标值"></a>step3：计算加权的指标值</h3><h3 id="step4：确定正理想方案和负理想方案"><a href="#step4：确定正理想方案和负理想方案" class="headerlink" title="step4：确定正理想方案和负理想方案"></a>step4：确定正理想方案和负理想方案</h3><h3 id="step5：计算各个方案到正负理想方案的距离"><a href="#step5：计算各个方案到正负理想方案的距离" class="headerlink" title="step5：计算各个方案到正负理想方案的距离"></a>step5：计算各个方案到正负理想方案的距离</h3><h3 id="step6：计算各个方案的综合得分"><a href="#step6：计算各个方案的综合得分" class="headerlink" title="step6：计算各个方案的综合得分"></a>step6：计算各个方案的综合得分</h3>]]></content>
    
    
    <categories>
      
      <category>学习笔记</category>
      
      <category>数学建模</category>
      
    </categories>
    
    
    <tags>
      
      <tag>综合评价模型</tag>
      
    </tags>
    
  </entry>
  
  
  
  <entry>
    <title>[学习笔记]微分方程模型</title>
    <link href="/2020/07/27/%E5%AD%A6%E4%B9%A0%E7%AC%94%E8%AE%B0-%E5%BE%AE%E5%88%86%E6%96%B9%E7%A8%8B%E6%A8%A1%E5%9E%8B/"/>
    <url>/2020/07/27/%E5%AD%A6%E4%B9%A0%E7%AC%94%E8%AE%B0-%E5%BE%AE%E5%88%86%E6%96%B9%E7%A8%8B%E6%A8%A1%E5%9E%8B/</url>
    
    <content type="html"><![CDATA[<p><strong>微分方程模型的思想</strong>：假设我们要研究量x,y,z 与t的关系,微分方程模型的思想是从考察量x,y,z对t的导数(即x,y,z对t的变化率)入手，找出导数符合的规律，建立包含未知函数的导数(偏导数)的方程(方程组)，通过分析、求解微分方程（组）来获得x,y,z与t的函数关系。</p><p>以下是几个常见的根据微分方程构建的模型：</p><h2 id="人口增长模型"><a href="#人口增长模型" class="headerlink" title="人口增长模型"></a>人口增长模型</h2><h3 id="马尔萨斯的指数增长模型"><a href="#马尔萨斯的指数增长模型" class="headerlink" title="马尔萨斯的指数增长模型"></a>马尔萨斯的指数增长模型</h3><p>基本假设：单位时间内人口的增长率为常数r，即<img src="/2020/07/27/%E5%AD%A6%E4%B9%A0%E7%AC%94%E8%AE%B0-%E5%BE%AE%E5%88%86%E6%96%B9%E7%A8%8B%E6%A8%A1%E5%9E%8B/1.png" srcset="/img/loading.gif" alt></p><p>x(t)可以用指数形式来表示，再通过求导即可得到每年的人口增长速度。这个模型有它的优点和缺陷：<strong>可用于短期人口增长预测</strong>（与19世纪以前欧洲一些地区人口统计数据吻合/适用于19世纪后迁往加拿大的欧洲移民后代），但<strong>不能预测较长期的人口增长过程</strong>（不符合19世纪后多数地区人口增长规律，人口增长率r逐渐下降）。</p><h3 id="阻滞增长模型（Logistic模型）"><a href="#阻滞增长模型（Logistic模型）" class="headerlink" title="阻滞增长模型（Logistic模型）"></a>阻滞增长模型（Logistic模型）</h3><p>基本思想：人口增长到一定程度时，由于资源、环境等约束，人口本身会对r产生影响，即r是x的减函数。最简单的函数是线性函数，因此令<strong>r（x） = r - sx， 其中s = r/Smax</strong>，在此条件下可以求得<img src="/2020/07/27/%E5%AD%A6%E4%B9%A0%E7%AC%94%E8%AE%B0-%E5%BE%AE%E5%88%86%E6%96%B9%E7%A8%8B%E6%A8%A1%E5%9E%8B/2.png" srcset="/img/loading.gif" alt></p><p>两个未知参数r和Smax可以用以前的数据去拟合（ols）。</p><p>进一步改进则引入其他的非线性函数，并求解相关系数。</p><h3 id="传染病传播模型"><a href="#传染病传播模型" class="headerlink" title="传染病传播模型"></a>传染病传播模型</h3><p>比较科学的两个模型：SIS（传染病可治愈但无免疫性）和SIR（传染病可治愈且有免疫性）。</p>]]></content>
    
    
    <categories>
      
      <category>学习笔记</category>
      
      <category>数学建模</category>
      
    </categories>
    
    
    <tags>
      
      <tag>微分方程模型</tag>
      
    </tags>
    
  </entry>
  
  
  
  <entry>
    <title>[技术笔记]jupyter不能通过浏览器自动打开</title>
    <link href="/2020/07/27/%E6%8A%80%E6%9C%AF%E7%AC%94%E8%AE%B0-jupyter%E4%B8%8D%E8%83%BD%E9%80%9A%E8%BF%87%E6%B5%8F%E8%A7%88%E5%99%A8%E8%87%AA%E5%8A%A8%E6%89%93%E5%BC%80/"/>
    <url>/2020/07/27/%E6%8A%80%E6%9C%AF%E7%AC%94%E8%AE%B0-jupyter%E4%B8%8D%E8%83%BD%E9%80%9A%E8%BF%87%E6%B5%8F%E8%A7%88%E5%99%A8%E8%87%AA%E5%8A%A8%E6%89%93%E5%BC%80/</url>
    
    <content type="html"><![CDATA[<p>这两天用win+R打开juypter的时候发现不能通过浏览器自动打开了，只能手动打开。之前我配置的默认浏览器是chrome，中间因为chrome版本太低Google帮我重装过一次，怀疑是重装过后的chrome被改了文件路径，从而导致打不开了，因此决定重新配置juypter的路径即可：</p><p>1、在cmd下执行<em>jupyter notebook —generate-config</em>，会提示该文件所在的目录，我的是C:\Users\Administrator.jupyter\jupyter_notebook_config.py。</p><p>2、进入该目录，用编辑器打开这个文件（我用的是Geany，应该txt编辑器也可以）。</p><p>3、用crtl+F找到<em>#c.NotebookApp.browser</em>，在其下方复制</p><pre><code>import webbrowserwebbrowser.register(&quot;chrome&quot;,None,webbrowser.GenericBrowser(r&quot;C:\Program Files (x86)\Google\Chrome\Application\chrome.exe&quot;))c.NotebookApp.browser = &#39;chrome&#39;</code></pre><p>我这里用的是chrome，其他浏览器同理，位置路径的确变了，因此替换了位置路径。如果不想改变字符串中的反斜杠\，则在字符串前加上r。</p><p>4、保存并运行，发现成功自动打开浏览器了。</p>]]></content>
    
    
    <categories>
      
      <category>技术笔记</category>
      
      <category>python</category>
      
    </categories>
    
    
    <tags>
      
      <tag>jupyter notebook</tag>
      
    </tags>
    
  </entry>
  
  
  
  <entry>
    <title>[学习笔记]差分方程模型</title>
    <link href="/2020/07/26/%E5%AD%A6%E4%B9%A0%E7%AC%94%E8%AE%B0-%E5%B7%AE%E5%88%86%E6%96%B9%E7%A8%8B%E6%A8%A1%E5%9E%8B/"/>
    <url>/2020/07/26/%E5%AD%A6%E4%B9%A0%E7%AC%94%E8%AE%B0-%E5%B7%AE%E5%88%86%E6%96%B9%E7%A8%8B%E6%A8%A1%E5%9E%8B/</url>
    
    <content type="html"><![CDATA[<p>差分方程，顾名思义，研究的是一组有规律序列相邻两个时间段间的规律，这种规律能够全部（部分）运用（使用迭代或递推）到一个总体，从而求解问题。</p><h2 id="一阶线性差分方程模型"><a href="#一阶线性差分方程模型" class="headerlink" title="一阶线性差分方程模型"></a>一阶线性差分方程模型</h2><p><strong><em>ΔAn = An+1 - An = f(An,其他因素)</em></strong> 这样一个方程可以被称为一阶差分方程模型，如果f(An,其他因素)是关于An的线性模式，则被称为一阶线性差分方程模型，即<img src="/2020/07/26/%E5%AD%A6%E4%B9%A0%E7%AC%94%E8%AE%B0-%E5%B7%AE%E5%88%86%E6%96%B9%E7%A8%8B%E6%A8%A1%E5%9E%8B/1.png" srcset="/img/loading.gif" alt></p><h3 id="一阶线性差分方程的解及其长期行为"><a href="#一阶线性差分方程的解及其长期行为" class="headerlink" title="一阶线性差分方程的解及其长期行为"></a>一阶线性差分方程的解及其长期行为</h3><p>很容易得到<img src="/2020/07/26/%E5%AD%A6%E4%B9%A0%E7%AC%94%E8%AE%B0-%E5%B7%AE%E5%88%86%E6%96%B9%E7%A8%8B%E6%A8%A1%E5%9E%8B/2.png" srcset="/img/loading.gif" alt></p><p>当n趋于无穷时，<img src="/2020/07/26/%E5%AD%A6%E4%B9%A0%E7%AC%94%E8%AE%B0-%E5%B7%AE%E5%88%86%E6%96%B9%E7%A8%8B%E6%A8%A1%E5%9E%8B/3.png" srcset="/img/loading.gif" alt><img src="/2020/07/26/%E5%AD%A6%E4%B9%A0%E7%AC%94%E8%AE%B0-%E5%B7%AE%E5%88%86%E6%96%B9%E7%A8%8B%E6%A8%A1%E5%9E%8B/4.jpg" srcset="/img/loading.gif" alt></p><h3 id="差分方程模型的平衡点"><a href="#差分方程模型的平衡点" class="headerlink" title="差分方程模型的平衡点"></a>差分方程模型的平衡点</h3><p>平衡点是指An = a, An+1 = a 的情况，如果长期行为等于平衡点，则称之为稳定的平衡点。</p><h2 id="一阶非线性差分方程模型"><a href="#一阶非线性差分方程模型" class="headerlink" title="一阶非线性差分方程模型"></a>一阶非线性差分方程模型</h2><p>我们一般通过变化的散点图，猜想出ΔAn变化的规律，即f(An,其他因素)的形式，再和OLS相结合来拟合关于ΔAn的曲线。当然，差分方程也只是解决拟合问题的一种方法，存在其他更加合适的方法时，也可以用其他方法解决。</p>]]></content>
    
    
    <categories>
      
      <category>学习笔记</category>
      
      <category>数学建模</category>
      
    </categories>
    
    
    <tags>
      
      <tag>差分方程模型</tag>
      
      <tag>动力系统模型</tag>
      
    </tags>
    
  </entry>
  
  
  
  <entry>
    <title>[技术笔记]pandas中agg()与apply()的区别</title>
    <link href="/2020/07/19/%E6%8A%80%E6%9C%AF%E7%AC%94%E8%AE%B0-pandas%E4%B8%ADagg-%E4%B8%8Eapply-%E7%9A%84%E5%8C%BA%E5%88%AB/"/>
    <url>/2020/07/19/%E6%8A%80%E6%9C%AF%E7%AC%94%E8%AE%B0-pandas%E4%B8%ADagg-%E4%B8%8Eapply-%E7%9A%84%E5%8C%BA%E5%88%AB/</url>
    
    <content type="html"><![CDATA[<p>对数据集进行分组并对各组应用一个函数（无论是聚合还是转换），通常是数据分析工作中的重要环节<sup id="fnref:1" class="footnote-ref"><a href="#fn:1" rel="footnote"><span class="hint--top hint--rounded" aria-label="源自‘python for data analysis’ chapter 10">[1]</span></a></sup>。<br><img src="/2020/07/19/%E6%8A%80%E6%9C%AF%E7%AC%94%E8%AE%B0-pandas%E4%B8%ADagg-%E4%B8%8Eapply-%E7%9A%84%E5%8C%BA%E5%88%AB/1.png" srcset="/img/loading.gif" alt></p><p>这张表就阐述了整一个GroupBy的机制。一般来说，Split部分用groupby()完成，但apply部分可以用apply,agg以及其他一些特定的函数完成（如count，mean，sum等）。</p><p>在<em>‘python for data analysis’</em>一书中并没有很明确地指出这两者的区别，只是说apply比agg更具有普适性，但对应的运行速度也会偏慢（好比在agg中执行自建函数总要比执行已经规划好的优化函数要慢一样）。</p><p>看了网上很多资料，感觉agg与apply的区别主要是，agg只能对数组运算并产生标量值，而apply除此之外还可以返回一个pandas对象，这是agg做不到的，就比如想要对一个数组进行排序操作时，就只能用apply而不能用agg。</p><p>引用：</p><section class="footnotes"><div class="footnote-list"><ol><li><span id="fn:1" class="footnote-text"><span>源自<em>‘python for data analysis’ chapter 10</em><a href="#fnref:1" rev="footnote" class="footnote-backref"> ↩</a></span></span></li></ol></div></section>]]></content>
    
    
    <categories>
      
      <category>技术笔记</category>
      
      <category>python</category>
      
    </categories>
    
    
    <tags>
      
      <tag>数据聚合和分组运算</tag>
      
    </tags>
    
  </entry>
  
  
  
  <entry>
    <title>[学习笔记]插值与拟合</title>
    <link href="/2020/07/17/%E5%AD%A6%E4%B9%A0%E7%AC%94%E8%AE%B0-%E6%8F%92%E5%80%BC%E4%B8%8E%E6%8B%9F%E5%90%88/"/>
    <url>/2020/07/17/%E5%AD%A6%E4%B9%A0%E7%AC%94%E8%AE%B0-%E6%8F%92%E5%80%BC%E4%B8%8E%E6%8B%9F%E5%90%88/</url>
    
    <content type="html"><![CDATA[<p>插值的一般思路：根据已知数据点构造一个一般的函数，该函数对现有数据有较好的拟合效果，再用这个函数进行插值预测。构造函数的方法是一个重点（回归的<em>OLS、FSLS、GLS、WLS、Probit、Logit</em>等都是计量中评估的函数方法）。插值一般用来进行填补数据集，但不用做数据预测。 </p><h2 id="多项式插值"><a href="#多项式插值" class="headerlink" title="多项式插值"></a>多项式插值</h2><p>通过一个构造一个多项式函数去插值。原因：1.多项式函数比较简单2.<strong><em>Weierstrass</em>一致逼近定理</strong>：给定一个任意小的e，对于一段连续曲线，一定存在一个多项式，两者在定义域内的插值的绝对值小于任何给定的e。</p><p>那么，<strong>如何确定多项式的形式</strong>呢？在多项插值法中的要求是，要使估计函数在第i个观测值处的值f(xi)=实际观测值。</p><p>其优点是：1.可以确定<strong>唯一</strong>的一个估计函数（根据范德蒙行列式的结论，证明略）；2.在已知<strong>观测值附近，该函数的近似效果是非常好</strong>的（显然，对于一个连续函数，就是有这样的能力，高等数学里都有学到，这也是OLS这种总体误差最小方法所不具备的优点）。</p><p>并且，如果题目提供n+1个观测值，就可以据此列出一个n次多项式（因为n次多项式有包括截距在内有n+1个未知数，需要n+1个条件）。但这样也存在问题，当次数多，数据大时，<strong>容易出现<em>Runge</em>现象</strong>，即高次项数对数据很敏感，微小的扰动都会造成巨大的变化。因此，具有下列改进的方法：</p><h3 id="Lagrange插值法"><a href="#Lagrange插值法" class="headerlink" title="Lagrange插值法"></a><em>Lagrange</em>插值法</h3><p><img src="/2020/07/17/%E5%AD%A6%E4%B9%A0%E7%AC%94%E8%AE%B0-%E6%8F%92%E5%80%BC%E4%B8%8E%E6%8B%9F%E5%90%88/1.png" srcset="/img/loading.gif" alt></p><p>其中，<img src="/2020/07/17/%E5%AD%A6%E4%B9%A0%E7%AC%94%E8%AE%B0-%E6%8F%92%E5%80%BC%E4%B8%8E%E6%8B%9F%E5%90%88/2.png" srcset="/img/loading.gif" alt></p><h3 id="Newton插值法"><a href="#Newton插值法" class="headerlink" title="Newton插值法"></a><em>Newton</em>插值法</h3><p><img src="/2020/07/17/%E5%AD%A6%E4%B9%A0%E7%AC%94%E8%AE%B0-%E6%8F%92%E5%80%BC%E4%B8%8E%E6%8B%9F%E5%90%88/3.png" srcset="/img/loading.gif" alt></p><p>其中，<img src="/2020/07/17/%E5%AD%A6%E4%B9%A0%E7%AC%94%E8%AE%B0-%E6%8F%92%E5%80%BC%E4%B8%8E%E6%8B%9F%E5%90%88/4.png" srcset="/img/loading.gif" alt><img src="/2020/07/17/%E5%AD%A6%E4%B9%A0%E7%AC%94%E8%AE%B0-%E6%8F%92%E5%80%BC%E4%B8%8E%E6%8B%9F%E5%90%88/5.png" srcset="/img/loading.gif" alt></p><h3 id="分段插值法"><a href="#分段插值法" class="headerlink" title="分段插值法"></a>分段插值法</h3><p>分段插值法的建立主要是基于上述两种方法在观测点增多时，次数增加，仍会出现<em>Runge</em>现象，因此分段求函似乎会更好。</p><p>比较常见的分段求函就是两个数据点间的线性插值或者三个数据点间的抛物线插值。</p><h3 id="样条插值法"><a href="#样条插值法" class="headerlink" title="样条插值法"></a>样条插值法</h3><p>分段插值虽然避免了<em>Runge</em>现象，但也使曲线很不平滑。因此，用样条插值法改善这一现象。</p><p>三次样条插值：在相邻的两个结点间用一条三次多项式曲线来近似并插值。</p><p>现在的问题是，两个结点之间就需要构造一个三次函数意味着所有结点的三次函数需要4n个条件才能求解，而n+1个观测值只提供了n+1个条件，还缺少3n-1个条件。因此要保证在插值结点处满足衔接条件：<img src="/2020/07/17/%E5%AD%A6%E4%B9%A0%E7%AC%94%E8%AE%B0-%E6%8F%92%E5%80%BC%E4%B8%8E%E6%8B%9F%E5%90%88/6.png" srcset="/img/loading.gif" alt></p><p>这又提供了3n-3个条件，还缺2个条件需要自己定义。</p><ol><li>方法一：定义最初和最末两个结点处的斜率（实际意义是最初和最末的该变量增长速度如何）。</li><li>方法二：定义最初和最末两个结点的二阶导数，一般令其=0（几何意义是斜率为0&lt;—&gt;曲率为0）.</li><li>方法三：<strong>周期边界条件</strong>，即最初和最末两个结点函数值相同，斜率相同。这说明该段观测值会重复出现，这个数据集具有周期性。</li><li>方法四：根据具体问题具体分析，自己添加即可。</li></ol><h3 id="最邻近插值法"><a href="#最邻近插值法" class="headerlink" title="最邻近插值法"></a>最邻近插值法</h3><p>要估计的值最邻近哪个观测值结点，就将那个观测值作为估计值，是一种简单而不准确的估计方法。</p><h2 id="二维插值"><a href="#二维插值" class="headerlink" title="二维插值"></a>二维插值</h2><p>由单自变量变为双自变量问题。结点类型一般分为网格型结点和散乱型结点，根据不同的结点类型<em>Matlab</em>会选择不同的方法。</p><p>插值方法：</p><h3 id="最邻近插值法-1"><a href="#最邻近插值法-1" class="headerlink" title="最邻近插值法"></a>最邻近插值法</h3><p>同多项式插值法中的最邻近插值法原理。</p><h3 id="分片线性插值"><a href="#分片线性插值" class="headerlink" title="分片线性插值"></a>分片线性插值</h3><p>三角形区域连成一整块即可，具体求值用<em>Matlab</em>。</p><h3 id="双线性插值"><a href="#双线性插值" class="headerlink" title="双线性插值"></a>双线性插值</h3><p>对于四个结点构成的网格，构造一个z=(ax+b)(cy+d)，四个未知数用四个网格结点求解，得到一个双线性函数来估计该网格内某点的值。</p><h2 id="曲线拟合"><a href="#曲线拟合" class="headerlink" title="曲线拟合"></a>曲线拟合</h2><p>在前面我们已经给出了一种方法：多项式插值。这种方法要求用来近似未知函数f的n次插值多项式准确无误地经过已知的n+1个结点。然而当结点数据是由某种实验或者计算方法得出的，就难免带有误差，要求多项式严格经过这些结点，无形中就会将误差保留下来，而且如果每一个结点都有误差的话，由于误差累积的效应，也会导致整体的近似效果较差。</p><p>这促使我们寻求一种新的方法近似未知函数，这一方法并不要求用来近似的函数严格通过已知结点，而只要求在结点处误差，按某一标准最小。为了计算方便，通常就采用误差的平方和最小作为度量误差的标准，即<strong>最小二乘原则**</strong>（OLS）**。</p><p>具体计算在<em>Matlab</em>中用<em>polyfit</em>相关命令完成多项式拟合求解。其他类型的曲线则用其他类型的函数解决。</p><h3 id="一个变形：加权最小二乘法-WLS"><a href="#一个变形：加权最小二乘法-WLS" class="headerlink" title="一个变形：加权最小二乘法(WLS)"></a>一个变形：加权最小二乘法(WLS)</h3><p>使用的原因：在不同的观测值点，数据的偏差很不一样（异方差性？在计量经济学中用来解决异方差问题）。</p><h3 id="拟合效果的评价"><a href="#拟合效果的评价" class="headerlink" title="拟合效果的评价"></a>拟合效果的评价</h3><p>最大相对误差/平均相对误差/拟合优度….</p>]]></content>
    
    
    <categories>
      
      <category>学习笔记</category>
      
      <category>数学建模</category>
      
    </categories>
    
    
    <tags>
      
      <tag>插值</tag>
      
      <tag>拟合</tag>
      
    </tags>
    
  </entry>
  
  
  
  <entry>
    <title>[学习笔记]数学规划模型深入</title>
    <link href="/2020/07/16/%E5%AD%A6%E4%B9%A0%E7%AC%94%E8%AE%B0-%E6%95%B0%E5%AD%A6%E8%A7%84%E5%88%92%E6%A8%A1%E5%9E%8B%E6%B7%B1%E5%85%A5/"/>
    <url>/2020/07/16/%E5%AD%A6%E4%B9%A0%E7%AC%94%E8%AE%B0-%E6%95%B0%E5%AD%A6%E8%A7%84%E5%88%92%E6%A8%A1%E5%9E%8B%E6%B7%B1%E5%85%A5/</url>
    
    <content type="html"><![CDATA[<h2 id="一个例题"><a href="#一个例题" class="headerlink" title="一个例题"></a>一个例题</h2><p><img src="/2020/07/16/%E5%AD%A6%E4%B9%A0%E7%AC%94%E8%AE%B0-%E6%95%B0%E5%AD%A6%E8%A7%84%E5%88%92%E6%A8%A1%E5%9E%8B%E6%B7%B1%E5%85%A5/1.jpg" srcset="/img/loading.gif" alt></p><h3 id="第一小问"><a href="#第一小问" class="headerlink" title="第一小问"></a>第一小问</h3><p>第一小问比较好解决，典型的线性规划问题，列举出所有的切割模式（共7种）后，将第i种模式切割的原料钢管根数作为决策变量即可，唯一需要注意的是，约束条件不能是三种钢管个数恰好=(50,20,15)，而应该是&gt;=(50,20,15)，否则可能会造成无解。</p><h3 id="第二小问"><a href="#第二小问" class="headerlink" title="第二小问"></a>第二小问</h3><p>第二小问增加了一种需求和一个约束条件：5米10根；切割模式不超过3种。用枚举法确定合理切割模式较为复杂，因此不如将使用哪种模式也加入决策变量，让lingo自己解决这个问题。当然这需要一个人为的合理度量，此处选择为每根余料不超过3米，即如下附加约束条件：<br><img src="/2020/07/16/%E5%AD%A6%E4%B9%A0%E7%AC%94%E8%AE%B0-%E6%95%B0%E5%AD%A6%E8%A7%84%E5%88%92%E6%A8%A1%E5%9E%8B%E6%B7%B1%E5%85%A5/2.jpg" srcset="/img/loading.gif" alt></p><p>原本的线性约束条件也因此变成了未知量*未知量的非线性约束组合：<br><img src="/2020/07/16/%E5%AD%A6%E4%B9%A0%E7%AC%94%E8%AE%B0-%E6%95%B0%E5%AD%A6%E8%A7%84%E5%88%92%E6%A8%A1%E5%9E%8B%E6%B7%B1%E5%85%A5/3.jpg" srcset="/img/loading.gif" alt></p><p>还可以通过人为增加决策变量的约束减少计算量。</p><h2 id="一些小结"><a href="#一些小结" class="headerlink" title="一些小结"></a>一些小结</h2><h3 id="可能的解"><a href="#可能的解" class="headerlink" title="可能的解"></a>可能的解</h3><ol><li>全局最优解</li><li>局部最优解</li><li>中断解</li></ol><h3 id="基本类型"><a href="#基本类型" class="headerlink" title="基本类型"></a>基本类型</h3><ol><li>按照有无约束</li></ol><p>（1）约束优化（constrained optimization）</p><p>（2）无约束优化（unconstrained opt）</p><ol><li>按照决策变量x的分量取值</li></ol><p>（1）连续优化/数学规划（continuous opt / mathematical programming）</p><p>（2）离散优化/组合优化（discrete opt / combinatorial opt ）</p><ol><li>按照目标函数的个数</li></ol><p>单目标规划与多目标规划</p><ol><li>按照参数或者决策变量是否具有不确定性</li></ol><p>确定性规划与不确定性规划（如随机规划、模糊规划等）</p><ol><li>按照目标函数f，约束条件g、h是否连续可微</li></ol><p>光滑优化与非光滑优化</p>]]></content>
    
    
    <categories>
      
      <category>学习笔记</category>
      
      <category>数学建模</category>
      
    </categories>
    
    
    <tags>
      
      <tag>数学规划模型</tag>
      
    </tags>
    
  </entry>
  
  
  
  <entry>
    <title>[学习笔记]数学规划模型初识</title>
    <link href="/2020/07/16/%E5%AD%A6%E4%B9%A0%E7%AC%94%E8%AE%B0-%E6%95%B0%E5%AD%A6%E8%A7%84%E5%88%92%E6%A8%A1%E5%9E%8B%E5%88%9D%E8%AF%86/"/>
    <url>/2020/07/16/%E5%AD%A6%E4%B9%A0%E7%AC%94%E8%AE%B0-%E6%95%B0%E5%AD%A6%E8%A7%84%E5%88%92%E6%A8%A1%E5%9E%8B%E5%88%9D%E8%AF%86/</url>
    
    <content type="html"><![CDATA[<h2 id="数学规划模型的三要素"><a href="#数学规划模型的三要素" class="headerlink" title="数学规划模型的三要素"></a>数学规划模型的三要素</h2><ol><li>决策变量</li><li>目标函数</li><li>约束条件</li></ol><h2 id="0-1变量的运算特点"><a href="#0-1变量的运算特点" class="headerlink" title="0-1变量的运算特点"></a>0-1变量的运算特点</h2><p>在0-1变量中，<img src="/2020/07/16/%E5%AD%A6%E4%B9%A0%E7%AC%94%E8%AE%B0-%E6%95%B0%E5%AD%A6%E8%A7%84%E5%88%92%E6%A8%A1%E5%9E%8B%E5%88%9D%E8%AF%86/1.png" srcset="/img/loading.gif" alt>，两者互为充要条件，而在一般情形下，前者是后者的充分不必要条件。</p><p>0-1变量还可以描述约束条件（if-else）关系，<img src="/2020/07/16/%E5%AD%A6%E4%B9%A0%E7%AC%94%E8%AE%B0-%E6%95%B0%E5%AD%A6%E8%A7%84%E5%88%92%E6%A8%A1%E5%9E%8B%E5%88%9D%E8%AF%86/2.jpg" srcset="/img/loading.gif" alt>，如图例题所示。</p><h2 id="多目标规划模型的处理方法"><a href="#多目标规划模型的处理方法" class="headerlink" title="多目标规划模型的处理方法"></a>多目标规划模型的处理方法</h2><p>多目标规划下，往往这n个目标<strong>相互矛盾</strong>，其解决思路是转变多目标规划为单目标规划。</p><h3 id="方法一：按照目标的重要性分步求解"><a href="#方法一：按照目标的重要性分步求解" class="headerlink" title="方法一：按照目标的重要性分步求解"></a>方法一：按照目标的重要性分步求解</h3><p>如在选课策略模型中，任务要求选修课程最少，且学分尽量多，应学习哪些课程。首先认为选修课程最少为第一目标，在此基础上加入课程总门数的约束，再进行求解。</p><h4 id="缺点："><a href="#缺点：" class="headerlink" title="缺点："></a>缺点：</h4><p>如果有更多个目标，那么很难对目标的重要性进行排序。<br>即使排出顺序，也需要求解很多个单目标规划。<br>当第一个目标对应的单目标规划问题的最优解唯一时，后面的单目标规划丧失意义，并且对于整数规划，Lingo无法告诉我们最优解是否唯一。</p><h3 id="方法二：将多目标加权求和变为单目标"><a href="#方法二：将多目标加权求和变为单目标" class="headerlink" title="方法二：将多目标加权求和变为单目标"></a>方法二：将多目标加权求和变为单目标</h3><p>显然加权系数取决于该目标的重要性。</p><h4 id="缺点：-1"><a href="#缺点：-1" class="headerlink" title="缺点："></a>缺点：</h4><p>由于多个目标之间单位、数量级不一致，导致综合目标没有实际意义。<br>权重系数难以确定。</p><h4 id="注意点："><a href="#注意点：" class="headerlink" title="注意点："></a>注意点：</h4><p>在多个目标的方向不一致（max/min）时，如果综合目标是max，则需要将子目标是min的取相反数再综合。<br>权重还可以为函数，模型会变复杂，但稳健性提升了。</p>]]></content>
    
    
    <categories>
      
      <category>学习笔记</category>
      
      <category>数学建模</category>
      
    </categories>
    
    
    <tags>
      
      <tag>数学规划模型</tag>
      
    </tags>
    
  </entry>
  
  
  
  <entry>
    <title>[技术笔记]pandas中的逻辑运算符</title>
    <link href="/2020/07/14/%E6%8A%80%E6%9C%AF%E7%AC%94%E8%AE%B0-pandas%E4%B8%AD%E7%9A%84%E9%80%BB%E8%BE%91%E8%BF%90%E7%AE%97%E7%AC%A6/"/>
    <url>/2020/07/14/%E6%8A%80%E6%9C%AF%E7%AC%94%E8%AE%B0-pandas%E4%B8%AD%E7%9A%84%E9%80%BB%E8%BE%91%E8%BF%90%E7%AE%97%E7%AC%A6/</url>
    
    <content type="html"><![CDATA[<p>首先需要说明的是，在pandas中进行逻辑运算时，其运算符不再是<strong>and</strong>;<strong>or</strong>;<strong>not</strong>，转而变成了相对应的<strong>&amp;</strong>，<strong>|</strong>，<strong>～</strong>，<sup><a href="#fn_1" id="reffn_1">1</a></sup>如下列代码:</p><pre><code>In [129]: s = pd.Series(range(-3, 4)) In [132]: s[(s &lt; -1) | (s &gt; 0.5)] Out[132]:             0   -3            1   -2            4    1            5    2            6    3            dtype: int64 </code></pre><p>其原因是什么？查阅了网上的一些<a href="https://www.imooc.com/wenda/detail/567532" target="_blank" rel="noopener">资料</a>发现，是因为当我们使用and，or，not等运算符时，python自动将运算符两边的式子转换为bool类型再进行比较，而在pandas的Series、DataFrame以及numpy的array上，是没有bool值的，所以在元素级的操作上使用&amp;、|、～代替。</p><p>（题外话：当然更具体的我也不是很清楚，这有待后续学习了《流畅的python》后再验证，一想到github上就有电子版，我还傻乎乎花了一百多买了个新书我就很心痛<sup><a href="#fn_2" id="reffn_2">2</a></sup>）</p><p>值得注意的是，其<strong>元素符优先级</strong>也发生了改变，在pandas中，这类逻辑运算符优先级很高，因此运算符两侧最好时刻都<strong>加上括号</strong>，防止不必要的错误。比如：</p><pre><code>In[23]: army[(army.deaths &gt; 500) | (army.deaths &lt; 50)]Out[23]: regiment    company    deaths    battles    size    veterans    readiness    armored    desertersorigin                                    Arizona    Nighthawks    1st    523    5    1045    1    1    1    4Texas    Nighthawks    2nd    25    2    1099    62    3    1    31Florida    Nighthawks    2nd    616    2    1400    26    3    1    2Maine    Dragoons    1st    43    4    1592    73    2    0    3Alaska    Dragoons    2nd    523    8    987    949    2    0    24Louisana    Scouts    2nd    37    8    1099    63    2    1    2Georgia    Scouts    2nd    35    9    1523    345    3    1    3</code></pre><p>是正确的，而army[army.deaths &gt; 500 | army.deaths &lt; 50]则会报错：<em>ValueError: The truth value of a Series is ambiguous. Use a.empty, a.bool(), a.item(), a.any() or a.all().</em></p><h3 id="参考"><a href="#参考" class="headerlink" title="参考"></a>参考</h3><p><sup><a href="#fn_1" id="reffn_1">1</a></sup>： 来源：<a href="https://blog.csdn.net/claroja/article/details/65661826" target="_blank" rel="noopener">https://blog.csdn.net/claroja/article/details/65661826</a> </p><p><sup><a href="#fn_2" id="reffn_2">2</a></sup>：后来在看《python数据科学手册》p67有了答案，是因为其内部比较的是<strong>每个对象中的比特位</strong></p>]]></content>
    
    
    <categories>
      
      <category>技术笔记</category>
      
      <category>python</category>
      
    </categories>
    
    
    <tags>
      
      <tag>逻辑运算符</tag>
      
    </tags>
    
  </entry>
  
  
  
  <entry>
    <title>[学习笔记]模型的灵敏度分析和稳健性分析方法</title>
    <link href="/2020/07/13/%E6%8A%80%E6%9C%AF%E7%AC%94%E8%AE%B0-%E6%A8%A1%E5%9E%8B%E7%9A%84%E7%81%B5%E6%95%8F%E5%BA%A6%E5%88%86%E6%9E%90%E5%92%8C%E7%A8%B3%E5%81%A5%E6%80%A7%E5%88%86%E6%9E%90%E6%96%B9%E6%B3%95/"/>
    <url>/2020/07/13/%E6%8A%80%E6%9C%AF%E7%AC%94%E8%AE%B0-%E6%A8%A1%E5%9E%8B%E7%9A%84%E7%81%B5%E6%95%8F%E5%BA%A6%E5%88%86%E6%9E%90%E5%92%8C%E7%A8%B3%E5%81%A5%E6%80%A7%E5%88%86%E6%9E%90%E6%96%B9%E6%B3%95/</url>
    
    <content type="html"><![CDATA[<p>在完成做出假设，用符号表示有关量，列出数学表达式，求解得到答案后，还需要对所得到的答案进行<em>灵敏度分析</em>和<em>稳健性分析</em>。本文旨在复习所学到的检验分析方法。</p><p><strong><em>灵敏度分析</em></strong>的意义在于，所得数据为测量值，与实际值可能存在差异，如果模型的输出对模型的输入很敏感，可能导致模型的偏误被放大，因此要对模型进行灵敏度分析。这让我联想到伍德里奇《计量经济学》第九章对于数据问题的再讨论，即解释变量的测量误差在CEV假定下，会对有误差的估计量造成衰减偏误，其他解释变量同样受到影响。</p><p>而<strong><em>稳健性分析</em></strong>在旨在放松假定，对更一般化的情况进行检验，毕竟假设往往线性、简单、理想化，可能与实际结果不符合。</p><h2 id="灵敏度分析"><a href="#灵敏度分析" class="headerlink" title="灵敏度分析"></a>灵敏度分析</h2><h3 id="方法一：数值法"><a href="#方法一：数值法" class="headerlink" title="方法一：数值法"></a>方法一：数值法</h3><p>对可能存在的误差大小进行估计，将观测值根据误差范围进行调整再输入模型，观察观测值的改变量大小对输出值改变量大小的影响（当然都是相对指标，一般以百分比衡量）。在输入时多参数的情况下，一般有两种思路：（1）只改变一个参数，保持其他参数不变，用来检验最不容易确定的参数；（2）改变若干参数，考察一组参数的稳定性，因为可能参数之间本就存在协同性。</p><h3 id="方法二：解析法"><a href="#方法二：解析法" class="headerlink" title="方法二：解析法"></a>方法二：解析法</h3><p>数值法是直接带入数据进行计算，而解析法则是通过对公式的分析，从数学模型上得到一个相对变化率，再带入数值检验，<strong>更加精确</strong>。如单输入-单输出情形下，变化率的求解就很简单。但其也存在其显而易见的缺点：在多输入-多输出情况下，<strong>获得精确的解析式非常困难</strong>；<strong>很多问题是离散的</strong>。</p><h2 id="稳健性分析"><a href="#稳健性分析" class="headerlink" title="稳健性分析"></a>稳健性分析</h2><p>在很多实际问题中，为了简单起见，我们往往会做出许多线性化的假设，同时也会将某些与时间有关的变量假设成与时间无关的常量，这使得得到的数学模型有很大的局限性。</p><p>对已有模型进行强健性分析是指将模型中线性化的假设改为更一般的非线性情形，同时将常量改为变量，然后重新分析、建模、求解。</p>]]></content>
    
    
    <categories>
      
      <category>学习笔记</category>
      
      <category>数学建模</category>
      
    </categories>
    
    
    <tags>
      
      <tag>灵敏度分析</tag>
      
      <tag>稳健性分析</tag>
      
    </tags>
    
  </entry>
  
  
  
  
</search>
