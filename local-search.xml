<?xml version="1.0" encoding="utf-8"?>
<search>
  
  
  
  <entry>
    <title>[技术笔记]机器学习初识</title>
    <link href="/2020/09/15/%E6%8A%80%E6%9C%AF%E7%AC%94%E8%AE%B0-%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0%E5%88%9D%E8%AF%86/"/>
    <url>/2020/09/15/%E6%8A%80%E6%9C%AF%E7%AC%94%E8%AE%B0-%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0%E5%88%9D%E8%AF%86/</url>
    
    <content type="html"><![CDATA[<p>一般的Machine Learning步骤是：</p><p>搜据数据—数据清洗—确定预测的column—选择特征变量—建立模型（选择合适的模型—带入数据进行学习—预测—评估模型准确性、稳定性等）</p><p>下面以最简单的决策树模型为例，过一下整个流程（代码来自Kaggle的课程）</p><p><strong>Selecting Data for Modeling</strong></p><pre><code># Code you have previously used to load dataimport pandas as pd# Path of the file to readiowa_file_path = &#39;../input/home-data-for-ml-course/train.csv&#39;home_data = pd.read_csv(iowa_file_path)# Set up code checkingfrom learntools.core import binderbinder.bind(globals())from learntools.machine_learning.ex3 import *print(&quot;Setup Complete&quot;)</code></pre><p><strong>Selecting The Prediction Target</strong></p><p>约定俗称的是用y代表要预测的序列</p><pre><code>y = home_data.SalePrice</code></pre><p><strong>Choosing “Features”</strong></p><p>这一串Featues通常被称为X</p><pre><code># Create the list of features belowfeature_names = [&#39;LotArea&#39;,&#39;YearBuilt&#39;,&#39;1stFlrSF&#39;,&#39;2ndFlrSF&#39;,&#39;FullBath&#39;,&#39;BedroomAbvGr&#39;,&#39;TotRmsAbvGrd&#39;]# Select data corresponding to features in feature_namesX = home_data[feature_names]</code></pre><p><strong>Building Model</strong></p><p>The steps to building and using a model are:</p><p><strong>Define:</strong> What type of model will it be? A decision tree? Some other type of model? Some other parameters of the model type are specified too.</p><p>这里选择决策树模型</p><pre><code>from sklearn.tree import DecisionTreeRegressor#specify the model. #For model reproducibility, set a numeric value for random_state when specifying the modeliowa_model = DecisionTreeRegressor(random_state = 1)</code></pre><p><strong>Fit:</strong>Capture patterns from provided data. This is the heart of modeling.</p><pre><code>iowa_model.fit(X,y)</code></pre><p><strong>Predict:</strong> Just what it sounds like</p><pre><code>predictions = iowa_model.predict(X)print(predictions)</code></pre><p><strong>Evaluate:</strong> Determine how accurate the model’s predictions are.</p><p>one method for summarizing model quality: <strong>Mean Absolute Error(MSE)</strong></p><p>在Evaluate模型时’In-Sample’的问题：sample可能与整体不是同分布的，对样本的过度拟合会使模型带上一些样本显著二总体不显著的特征（这里举的一个例子是可能样本中带绿色门的房子都很贵，模型就将绿色门和贵相联系，但其实总体中可能根本没有这种特征）。</p><p>其他注意点：</p><p>决策树张有许多可以选择的变量，其中最重要的就是树枝的分支数，但要注意的是，分支太多，可能造成overfitting的问题；分支太少，可能造成uderfitting的问题。可以使用max_leaf_nodes这个参数来控制分支数。</p><pre><code>def get_mae(max_leaf_nodes, train_X, val_X, train_y, val_y):    model = DecisionTreeRegressor(max_leaf_nodes=max_leaf_nodes, random_state=0)    model.fit(train_X, train_y)    val_predictions = model.predict(val_X)    mae = mean_absolute_error(val_y, preds_val)    return(mae)# compare MAE with differing values of max_leaf_nodesfor max_leaf_nodes in [5, 50, 500, 5000]:    my_mae = get_mae(max_leaf_nodes, train_X, val_X, train_y, val_y)    print(&quot;Max leaf nodes: %d  \t\t Mean Absolute Error:  %d&quot; %(max_leaf_nodes, my_mae))</code></pre><p>在决策树模型的基础上诞生的另一种模型：random forest（随机森林）。</p><p>The random forest uses many trees, and it makes a prediction by averaging the predictions of each component tree. It generally has much better predictive accuracy than a single decision tree and <strong>it works well with default parameters.</strong></p><p>其他算法可能会比random forest更加精确，但这需要更精确的参数匹配，不像random forest跑默认参数也运行地很好。</p>]]></content>
    
    
    <categories>
      
      <category>技术笔记</category>
      
      <category>python</category>
      
    </categories>
    
    
    <tags>
      
      <tag>机器学习</tag>
      
      <tag>决策树模型</tag>
      
      <tag>随机森林模型</tag>
      
    </tags>
    
  </entry>
  
  
  
  <entry>
    <title>[技术笔记]序列的一些用法</title>
    <link href="/2020/09/09/%E6%8A%80%E6%9C%AF%E7%AC%94%E8%AE%B0-%E5%BA%8F%E5%88%97%E7%9A%84%E4%B8%80%E4%BA%9B%E8%AF%AD%E6%B3%95%E7%B3%96/"/>
    <url>/2020/09/09/%E6%8A%80%E6%9C%AF%E7%AC%94%E8%AE%B0-%E5%BA%8F%E5%88%97%E7%9A%84%E4%B8%80%E4%BA%9B%E8%AF%AD%E6%B3%95%E7%B3%96/</url>
    
    <content type="html"><![CDATA[<p>容器序列如list,tuple,collections.deque可以存放不同类型的数据，而扁平序列如str,bytes,array.array则只可以存放同一类型的数据。</p><p>但是，容器序列存放的是它们所包含的对象的引用，扁平序列则存放值，是一段更加紧凑的内存空间。</p><h2 id="列表推导和生成器表达式"><a href="#列表推导和生成器表达式" class="headerlink" title="列表推导和生成器表达式"></a>列表推导和生成器表达式</h2><h3 id="列表推导式"><a href="#列表推导式" class="headerlink" title="列表推导式"></a>列表推导式</h3><p>列表推导式是用来创建新列表的一个方法，通常能够对for循环、if条件语句等进行精简，是非常好用的语法糖。例如：</p><pre><code>方法一：symbols = &#39;ABCDE&#39;codes = []for symbol in symbols:    codes.append(ord(symbol))codes方法二：codes = [ord(symbol) for symbol in symbols]    codes</code></pre><p>两者的输出都是[65, 66, 67, 68, 69]，但显然方法二在可读性和简洁性上更胜一筹。</p><p><strong>列表推导式可以结合条件语句</strong>，如[ord(x) for x in xs if len(x) &gt;10].</p><p><strong>列表推导式还可以构成多循环结构</strong>，如[(x,y) for x in xs for y in ys].</p><h3 id="生成器表达式"><a href="#生成器表达式" class="headerlink" title="生成器表达式"></a>生成器表达式</h3><p>用来初始化元组、数组或其他序列类型，与列表推导式相比，表面上看只是将[]换为了()，但其原理上有本质的不同。</p><p>生成器表达式背后遵守了迭代器协议，可以逐个地产出元素，而不是先建立一个完整的列表，当数据规模很大时，可以有效地节省内存。</p><h2 id="元组"><a href="#元组" class="headerlink" title="元组"></a>元组</h2><h3 id="元组拆包"><a href="#元组拆包" class="headerlink" title="元组拆包"></a>元组拆包</h3><ol><li><p>平行赋值</p><pre><code> In[3]:a,b,c = (1,2,3)     a,b,c Out[3]:(1,2,3)</code></pre></li><li><p>用运算符把一个可迭代对象拆开（<strong>只有传参的时候可以这样用</strong>）</p><pre><code> In[6]:t = (20, 8)       divmod(*t) Out[6]:(2,4)</code></pre></li><li><p>占位符_在元组拆包中的运用</p><pre><code> In[9]:sample = [(1,a), (2,b), (3,c)]       for x, _ in sample:           print(x) Out[9]:1         2         3</code></pre></li><li><p>用*args来获取不确定数量的参数</p><pre><code> In[10]:a,b,*rest = range(5)        rest Out[10]:[2,3,4]</code></pre></li></ol><h2 id="切片"><a href="#切片" class="headerlink" title="切片"></a>切片</h2><h3 id="为什么切片和区间操作会忽略最后一个元素"><a href="#为什么切片和区间操作会忽略最后一个元素" class="headerlink" title="为什么切片和区间操作会忽略最后一个元素"></a>为什么切片和区间操作会忽略最后一个元素</h3><p>这样做的好处有：range(3)、list[:3]这种只有单个位置信息的一看就知道里面有三个元素；</p><p>stop-start即为所包含的元素数；</p><p>可以用任意一个下标把序列分割成不重叠的两部分。</p><h3 id="多维切片和省略"><a href="#多维切片和省略" class="headerlink" title="多维切片和省略"></a>多维切片和省略</h3><p>如pandas库中的df.iloc[1:3, 5:20]或者numpy库中的a[1:2, 4:5]都是多维切片。</p><p>省略是在numpy中比较有用，等学到了再用。</p><h3 id="给切片赋值"><a href="#给切片赋值" class="headerlink" title="给切片赋值"></a>给切片赋值</h3><p>如果赋值的对象是一个切片，那么赋值语句的右侧必须是一个可迭代对象。<strong>即便只有单独的一个值，也要把它转换成一个序列，如列表。</strong>例如 a[2:5] = 100是错误的，但a[2:5] = [100]就是正确的，并且只回替换a序列中第一个值为100。</p>]]></content>
    
    
    <categories>
      
      <category>技术笔记</category>
      
      <category>python</category>
      
    </categories>
    
    
    <tags>
      
      <tag>序列</tag>
      
      <tag>语法糖</tag>
      
    </tags>
    
  </entry>
  
  
  
  <entry>
    <title>[技术笔记]Python数据模型</title>
    <link href="/2020/09/09/%E6%8A%80%E6%9C%AF%E7%AC%94%E8%AE%B0-Python%E6%95%B0%E6%8D%AE%E6%A8%A1%E5%9E%8B%E4%B9%8B%E9%AD%94%E6%9C%AF%E6%96%B9%E6%B3%95/"/>
    <url>/2020/09/09/%E6%8A%80%E6%9C%AF%E7%AC%94%E8%AE%B0-Python%E6%95%B0%E6%8D%AE%E6%A8%A1%E5%9E%8B%E4%B9%8B%E9%AD%94%E6%9C%AF%E6%96%B9%E6%B3%95/</url>
    
    <content type="html"><![CDATA[<p><strong>参考代码：</strong></p><pre><code>from  math import hypotclass Vector:    def __init__(self, x=0, y=0):        self.x = x         self.y = y    def __repr__(self):        return &#39;Vector(%r,%r)&#39; % (self.x, self.y)    def __abs__(self):        return hypot(self.x, self.y)    def __add__(self, other):        y = self.y + other.y        x = self.x + other.x        return Vector(x, y)</code></pre><h3 id="字符串表现形式"><a href="#字符串表现形式" class="headerlink" title="字符串表现形式"></a>字符串表现形式</h3><p>python的一个内置函数是repr(),其本质是调用了魔术方法__repr__，它能把一个对象用字符串的形式表达出来，以便辨认。</p><p>字符串的格式化方法<strong>%和format</strong>本质上也是调用了该魔术方法。</p><p>注意点：__str__和__repr__都有讲对象字符串化的作用，但在自定义类时，应优先构造repr的魔术方法，因为如果一个对象没有str函数，而python又需要调用它时，解释器会使用repr作为替代，反之则不会。</p><h3 id="算术运算符"><a href="#算术运算符" class="headerlink" title="算术运算符"></a>算术运算符</h3><p>通过__add__可以实现+的运算，同理加入mul可以实现*的运算</p><h3 id="其他魔术方法"><a href="#其他魔术方法" class="headerlink" title="其他魔术方法"></a>其他魔术方法</h3><p>Python语言参考手册的“Data Model”一章列出了83个特殊方法，其中47个用于实现算术运算、位运算和比较操作。</p>]]></content>
    
    
    <categories>
      
      <category>技术笔记</category>
      
      <category>python</category>
      
    </categories>
    
    
    <tags>
      
      <tag>魔术方法</tag>
      
    </tags>
    
  </entry>
  
  
  
  <entry>
    <title>[学习笔记]短面板数据回归模型</title>
    <link href="/2020/09/07/%E5%AD%A6%E4%B9%A0%E7%AC%94%E8%AE%B0-%E9%9D%A2%E6%9D%BF%E6%95%B0%E6%8D%AE%E5%9B%9E%E5%BD%92%E6%A8%A1%E5%9E%8B/"/>
    <url>/2020/09/07/%E5%AD%A6%E4%B9%A0%E7%AC%94%E8%AE%B0-%E9%9D%A2%E6%9D%BF%E6%95%B0%E6%8D%AE%E5%9B%9E%E5%BD%92%E6%A8%A1%E5%9E%8B/</url>
    
    <content type="html"><![CDATA[<h2 id="面板数据的分类"><a href="#面板数据的分类" class="headerlink" title="面板数据的分类"></a>面板数据的分类</h2><h2 id="面板数据的优势"><a href="#面板数据的优势" class="headerlink" title="面板数据的优势"></a>面板数据的优势</h2><p><strong>可以处理一些不可观测的遗漏变量</strong>——如果漏掉的变量不随时间变化，则面板数据可以帮助消除遗漏变量偏差。</p><p>由上一篇笔记可知，由于各人/地/企业…各自存在一些属于自己的，影响因变量而不随时间变化的特征（异质性特征），横截面数据很难消除这些固定效应，因此选择面板数据回归模型进行处理。</p><h2 id="差分估计"><a href="#差分估计" class="headerlink" title="差分估计"></a>差分估计</h2><h3 id="两期差分模型"><a href="#两期差分模型" class="headerlink" title="两期差分模型"></a>两期差分模型</h3><p><img src="/2020/09/07/%E5%AD%A6%E4%B9%A0%E7%AC%94%E8%AE%B0-%E9%9D%A2%E6%9D%BF%E6%95%B0%E6%8D%AE%E5%9B%9E%E5%BD%92%E6%A8%A1%E5%9E%8B/1.jpg" srcset="/img/loading.gif" alt></p><h3 id="多期差分模型"><a href="#多期差分模型" class="headerlink" title="多期差分模型"></a>多期差分模型</h3><h4 id="方法一：个体中心化方法处理固定效应"><a href="#方法一：个体中心化方法处理固定效应" class="headerlink" title="方法一：个体中心化方法处理固定效应"></a>方法一：个体中心化方法处理固定效应</h4><p><img src="/2020/09/07/%E5%AD%A6%E4%B9%A0%E7%AC%94%E8%AE%B0-%E9%9D%A2%E6%9D%BF%E6%95%B0%E6%8D%AE%E5%9B%9E%E5%BD%92%E6%A8%A1%E5%9E%8B/2.jpg" srcset="/img/loading.gif" alt></p><p>其原理是针对同一样本，将其不同时期的做均值化处理，而<strong>个体与组均值的离差</strong>这个差分方程就巧妙地消除了固定效应的影响。</p><p>该方法类似于差分，但不同的是此处为’中心化’的数据，标准误也需要重新计算。</p><h4 id="方法二：’n-1个二值变量’模型"><a href="#方法二：’n-1个二值变量’模型" class="headerlink" title="方法二：’n-1个二值变量’模型"></a>方法二：’n-1个二值变量’模型</h4><p>以一个样本为基础，例如：要考虑江苏、浙江、广州三个省的面板数据，将江苏作为基础，赋予浙江一个虚拟变量ZJ，广州一个虚拟变量GZ，引入这n-1个虚拟变量就可以刻画n条截距项不同的回归直线。</p><p>优点：可以描绘出各个样本具体的异质性大小，还可以检验个体固定效应的显著性</p><p>缺点：在截面样本量很大时实现起来比较困难且耗费自由度高</p><h2 id="时间固定效应"><a href="#时间固定效应" class="headerlink" title="时间固定效应"></a>时间固定效应</h2><h3 id="定义"><a href="#定义" class="headerlink" title="定义"></a>定义</h3><p>遗漏的变量可能随时间而变化，但不随个体的变化而变化。</p><h3 id="只有时间固定效应的模型"><a href="#只有时间固定效应的模型" class="headerlink" title="只有时间固定效应的模型"></a>只有时间固定效应的模型</h3><p>将时间固定效应与截距项合并，形成一个新的截距项。</p><p>方法一：做<strong>‘年份中心化’</strong>处理：将某一时间点，这一横截面的所有数据做中心化处理，以消除这个新的截距项（固定时间点不变，对该时间点所有样本取了平均值）。</p><p>方法二：’T-1二值变量’形式</p><h3 id="同时包含个体和时间固定效应的模型"><a href="#同时包含个体和时间固定效应的模型" class="headerlink" title="同时包含个体和时间固定效应的模型"></a>同时包含个体和时间固定效应的模型</h3><p>当T=2时，继续使用一阶差分即可。</p><p>当T&gt;2时，有2*2=4种处理方法，其中最常用的时对个体中心化&amp;加入时间虚拟变量的方法。</p><h2 id="个体固定效应模型假设"><a href="#个体固定效应模型假设" class="headerlink" title="个体固定效应模型假设"></a>个体固定效应模型假设</h2><ol><li>假设一：给定某个x的所有时期的取值和该个体的固定效应时，u的均值为0</li></ol><p>该假设要求u的条件均值不依赖于任何时期的x值。</p><ol><li>假设二：个体与个体之间是要求相互独立的，但对于某一个体不同时期的相关性不做要求，即允许数据存在自相关（序列相关）性</li></ol><p>结果：OLS估计量是无偏、一致且接近正态的，但一般的OLS估计的标准误是错误的，这个问题可以通过<strong>‘群聚’</strong>解决。面板数据中群聚标准误是横截面数据中异方差—稳健标准误的推广。在面板数据中，无论是否存在异方差或序列相关，群聚标准误均有效。</p><h2 id="Hausman检验"><a href="#Hausman检验" class="headerlink" title="Hausman检验"></a>Hausman检验</h2><p>这是用来检验个体存在固定效应还是随机效应。</p><p>基本思想：<strong>在a和其他解释变量不相关假定下</strong>，采用中心化变换法估计固定效应模型和采用GLS法随机效应模型得到的参数估计都是无偏且一致的，只是前者不具有效性。<br>若原假设不成立，则固定效应模型的参数估计仍然是一致的，但随机效应模型不一致。因此，在原假设下，二者的参数估计应该不会有显著的差异，<strong>可以基于二者参数估计的差异构造统计检验量</strong>。</p><p><strong><em>H0：a和其他解释变量不相关</em></strong></p><p>注意点：当模型误差项存在序列相关或异方差时，经典的Hausman检验不再试用，需要做其他考虑。</p>]]></content>
    
    
    <categories>
      
      <category>学习笔记</category>
      
      <category>计量经济学</category>
      
    </categories>
    
    
    <tags>
      
      <tag>面板数据</tag>
      
    </tags>
    
  </entry>
  
  
  
  <entry>
    <title>[学习笔记]跨时横截面的混合：简单面板数据方法</title>
    <link href="/2020/09/07/%E5%AD%A6%E4%B9%A0%E7%AC%94%E8%AE%B0-%E8%B7%A8%E6%97%B6%E6%A8%AA%E6%88%AA%E9%9D%A2%E7%9A%84%E6%B7%B7%E5%90%88%EF%BC%9A%E7%AE%80%E5%8D%95%E9%9D%A2%E6%9D%BF%E6%95%B0%E6%8D%AE%E6%96%B9%E6%B3%95/"/>
    <url>/2020/09/07/%E5%AD%A6%E4%B9%A0%E7%AC%94%E8%AE%B0-%E8%B7%A8%E6%97%B6%E6%A8%AA%E6%88%AA%E9%9D%A2%E7%9A%84%E6%B7%B7%E5%90%88%EF%BC%9A%E7%AE%80%E5%8D%95%E9%9D%A2%E6%9D%BF%E6%95%B0%E6%8D%AE%E6%96%B9%E6%B3%95/</url>
    
    <content type="html"><![CDATA[<h2 id="跨时独立横截面的混合"><a href="#跨时独立横截面的混合" class="headerlink" title="跨时独立横截面的混合"></a>跨时独立横截面的混合</h2><h3 id="定义"><a href="#定义" class="headerlink" title="定义"></a>定义</h3><p>跨时独立混合横截面数据指的是在不同时点从一个大总体里进行随机抽样的结果，各个时期都是各自进行一次随机抽样，样本量可以不同，完全独立。这可能造成<strong>观测点不是同分布的</strong>。</p><h3 id="年度虚拟变量"><a href="#年度虚拟变量" class="headerlink" title="年度虚拟变量"></a>年度虚拟变量</h3><p>年度虚拟变量就是用来解决不同时间的观测点不是同分布问题的，即以最初一年为基年，后续几年分别设立一个虚拟变量，容许截距项甚至斜率（通过交互项）随时间的改变而改变。</p><h3 id="利用混合截面做政策分析"><a href="#利用混合截面做政策分析" class="headerlink" title="利用混合截面做政策分析"></a>利用混合截面做政策分析</h3><p>当某些外生事件（常常是政府的政策改变）改变了个人、家庭、企业或城市运行的环境时，便产生了<strong>自然实验</strong>。可以用混合截面的处理方法来处理自然实验的数据。</p><h2 id="两时期面板数据分析"><a href="#两时期面板数据分析" class="headerlink" title="两时期面板数据分析"></a>两时期面板数据分析</h2><h3 id="一些名词解释"><a href="#一些名词解释" class="headerlink" title="一些名词解释"></a>一些名词解释</h3><p><img src="/2020/09/07/%E5%AD%A6%E4%B9%A0%E7%AC%94%E8%AE%B0-%E8%B7%A8%E6%97%B6%E6%A8%AA%E6%88%AA%E9%9D%A2%E7%9A%84%E6%B7%B7%E5%90%88%EF%BC%9A%E7%AE%80%E5%8D%95%E9%9D%A2%E6%9D%BF%E6%95%B0%E6%8D%AE%E6%96%B9%E6%B3%95/1.jpg" srcset="/img/loading.gif" alt></p><ol><li><strong>非观测效应（固定效应）</strong>：指变量a这样影响着y但又不随时间而变化的所有无法观测的因素</li><li><strong>特异性误差（时变误差）</strong>：指误差u这样因时而便影响着y的所有无法观测的因素</li><li><strong>异质性偏误</strong>：遗漏了固定效应而造成的误差，存在遗漏变量问题</li></ol><h3 id="一阶差分方程"><a href="#一阶差分方程" class="headerlink" title="一阶差分方程"></a>一阶差分方程</h3><p><img src="/2020/09/07/%E5%AD%A6%E4%B9%A0%E7%AC%94%E8%AE%B0-%E8%B7%A8%E6%97%B6%E6%A8%AA%E6%88%AA%E9%9D%A2%E7%9A%84%E6%B7%B7%E5%90%88%EF%BC%9A%E7%AE%80%E5%8D%95%E9%9D%A2%E6%9D%BF%E6%95%B0%E6%8D%AE%E6%96%B9%E6%B3%95/2.jpg" srcset="/img/loading.gif" alt></p><p>（13.17）就被称为一阶差分方程，相应的系数被称为一阶差分估计量（<em>first-differenced estimator</em>）。</p>]]></content>
    
    
    <categories>
      
      <category>学习笔记</category>
      
      <category>计量经济学</category>
      
    </categories>
    
    
    <tags>
      
      <tag>面板数据</tag>
      
      <tag>混合横截面</tag>
      
    </tags>
    
  </entry>
  
  
  
  <entry>
    <title>[学习笔记]计量小复习</title>
    <link href="/2020/09/07/%E5%AD%A6%E4%B9%A0%E7%AC%94%E8%AE%B0-%E8%AE%A1%E9%87%8F%E5%B0%8F%E5%A4%8D%E4%B9%A0/"/>
    <url>/2020/09/07/%E5%AD%A6%E4%B9%A0%E7%AC%94%E8%AE%B0-%E8%AE%A1%E9%87%8F%E5%B0%8F%E5%A4%8D%E4%B9%A0/</url>
    
    <content type="html"><![CDATA[<p>1、<strong>方差膨胀因子（VIF）</strong>：测度某一自变量是否存在多重共线性，一般认为VIF&gt;10则存在较强的多重共线性，VIF&gt;100则存在严重的多重共线性。</p><p>2、<strong>含ln的回归系数的解释</strong>：</p><p>lny = alnx x变动1%，y变动a%</p><p>lny = ax x变动1，y变动100a%</p><p>y = alnx x变动1%，y变动a/100</p><p>3、<strong>Wald Test注意点</strong>：在WT中，c(n)的n是从1开始的，不是从0开始的。</p><p>4、<strong>异方差性注意点</strong>：异方差性不会改变系数的无偏性，也不会对拟合优度产生影响，但会造成假设检验无效。</p><p>4.1 检验异方差的方法：<strong>BP检验</strong>（布罗施-帕甘异方差检验），原理是检验残差平方和各自变量的线性关系；<strong>WHite检验</strong>（怀特检验），是BP检验的升级版，加上了一些非线性关系，但会消耗大量的自由度。</p><p>EViwes操作：eq01—View—Residual Diagnostics—Heteroskedasticity Test（怀特检验是在此基础上勾选<em>Include White cross terms</em>）</p><p>4.2 异方差修正的方法：稳健标准误法；加权最小二乘法（WLS），一定要知道异方差的具体形式才好用。</p><p>5、工具变量注意点：是对遗漏变量的另一种解决方法，有点复杂，等用到了再重新复习。</p>]]></content>
    
    
    <categories>
      
      <category>学习笔记</category>
      
      <category>计量经济学</category>
      
    </categories>
    
    
    <tags>
      
      <tag>计量经济学</tag>
      
    </tags>
    
  </entry>
  
  
  
  <entry>
    <title>[技术笔记]pandas学习小笔记1</title>
    <link href="/2020/08/30/%E6%8A%80%E6%9C%AF%E7%AC%94%E8%AE%B0-pandas%E5%AD%A6%E4%B9%A0%E5%B0%8F%E7%AC%94%E8%AE%B01/"/>
    <url>/2020/08/30/%E6%8A%80%E6%9C%AF%E7%AC%94%E8%AE%B0-pandas%E5%AD%A6%E4%B9%A0%E5%B0%8F%E7%AC%94%E8%AE%B01/</url>
    
    <content type="html"><![CDATA[<p>1、在使用<strong>pd.to_datetime()</strong>替换相关数据时，可能<em>df[XXX] = pd.to_datetime(df[XXX])</em>还是很好想到的，但如要对df的行标签进行转换，就应该是<em>df.index = pd.to_datetime(df.index)</em>这样子。</p><p>2、<strong>当要删除某些具有特定数据的行或者列时</strong>，应该使用df.replace()和df.dropna()结合的方法。</p><p>如想要删除那些全是0的列，可以写如下代码：</p><pre><code>df.replace(0, np.nan, inplace = True)cleaned = df.dropna()</code></pre><p>3、除了一般情况下的直接赋值，大部分情况下函数和方法都有<strong>inplace = True</strong>的属性，不说pd下的方法，就是set_index,fillna,dropna这些Series和DataFrame自带的方法都有inplace属性。</p><p>一个技巧：在jupyter notebook下，打出这样一行代码，直接产生交互的表格之类的，说明这就是一个新的表格，想要其直接继承就表格，就要使用inplace = True。</p><p>4、<strong>删除某行/列的两种方法：</strong>1.如果只想删除列，在df中，用del df[XXX]即可。 2.如果想对行或者列进行操作，则使用df.drop(‘’,axis = XXX, inpalace = XXX)</p><p>5、<strong>检查是否有缺失数据：</strong>对于比较小的数据量，直接使用df.isnull()即可，但是对于很大的数据量，df中间一些数据是省略的，这样做非常不直观。</p><p>所以在这里使用：<strong>df.isnull().sum()</strong>,直接就输出各列存在的缺失值数(因为Flase对应的是0，True对应的是1，全是False则自然是0，没有缺失值)。</p><p>6、<strong>Reset the index so it begins with 0 again:</strong> df.reset_index(drop = True,inplace = True)</p><p>7、<strong>解决使用drop方法删除多列时想要使用列整数索引指定而不是列索引名指定的问题</strong>：</p><p>问题描述：在使用df.drop()方法时，若要删除多行/列，只能输入一个包含行/列名的列表，而不能输入一个整数索引的列表，在使用整数索引更方便的时候就很难搞。</p><p>解决思想：我们可以把整数索引通过某种方式转换成名称组成的索引，再带入drop()中。</p><p>解决方法：若要删除df的1，3，7，9列，则应使用df.drop(df.columns[[0,2,6,8]], axis = 1)，巧妙地将整数索引进行了转化。</p><p>8、关于loc的优化</p><p>平常我们可能使用的是df.loc[1],df.loc[‘xxx’]这样的形式，但其实<strong>women = train.loc[train.Sex == ‘female’,”Survived”]</strong>这样将a condition expression带进去。</p><p>所以除了column names, row labels，这里用这种方法能够更加specific地索引一些需要的值。</p>]]></content>
    
    
    <categories>
      
      <category>技术笔记</category>
      
      <category>python</category>
      
    </categories>
    
    
    <tags>
      
      <tag>pandas</tag>
      
    </tags>
    
  </entry>
  
  
  
  <entry>
    <title>[技术笔记]重装硬盘后安装软件遇到的各种问题及解决办法</title>
    <link href="/2020/08/17/%E6%8A%80%E6%9C%AF%E7%AC%94%E8%AE%B0-%E9%87%8D%E8%A3%85%E7%B3%BB%E7%BB%9F%E5%90%8E%E5%AE%89%E8%A3%85%E8%BD%AF%E4%BB%B6%E9%81%87%E5%88%B0%E7%9A%84%E5%90%84%E7%A7%8D%E9%97%AE%E9%A2%98%E5%8F%8A%E8%A7%A3%E5%86%B3%E5%8A%9E%E6%B3%95/"/>
    <url>/2020/08/17/%E6%8A%80%E6%9C%AF%E7%AC%94%E8%AE%B0-%E9%87%8D%E8%A3%85%E7%B3%BB%E7%BB%9F%E5%90%8E%E5%AE%89%E8%A3%85%E8%BD%AF%E4%BB%B6%E9%81%87%E5%88%B0%E7%9A%84%E5%90%84%E7%A7%8D%E9%97%AE%E9%A2%98%E5%8F%8A%E8%A7%A3%E5%86%B3%E5%8A%9E%E6%B3%95/</url>
    
    <content type="html"><![CDATA[<h3 id="win10安装nodejs，报错there-is-a-problem-in-the-windows-installer-package…"><a href="#win10安装nodejs，报错there-is-a-problem-in-the-windows-installer-package…" class="headerlink" title="win10安装nodejs，报错there is a problem in the windows installer package…"></a>win10安装nodejs，报错there is a problem in the windows installer package…</h3><p>原因：win10和win8下必须以管理员模式打开此exe文件。</p><p>解决方法：首先以管理员身份打开cmd，将cmd路径通过cd方法转到nodejs.exe所在文件夹，再通过c：和键入文件名（注意要加后缀.msi）打开此程序。</p><h3 id="markdownpad2没有预览界面，一打文字就报错"><a href="#markdownpad2没有预览界面，一打文字就报错" class="headerlink" title="markdownpad2没有预览界面，一打文字就报错"></a>markdownpad2没有预览界面，一打文字就报错</h3><p>原因：装markdownpad的时候少装了一个html的渲染文件。</p><p>解决方法：补装一个即可。<a href="https://pan.baidu.com/s/1Gs1raE_8L0-A9oWSpGOIhg" target="_blank" rel="noopener">地址</a></p><p>提取码：qd0x</p><h3 id="迁移之前的python环境"><a href="#迁移之前的python环境" class="headerlink" title="迁移之前的python环境"></a>迁移之前的python环境</h3><p>原因：把库再装一遍太折磨了，建议是迁移一下环境。</p><p>解决方法：在原电脑上git下输入：</p><pre><code>pip freeze &gt; requirements.txt #会在当前目录下创建一个txt文档，保存了所有环境信息，可能会报错，不用管它。</code></pre><p>把这个文件转移到新电脑，git下输入：</p><pre><code>pip install -r requirements.txt #然后git就开始进行缓慢的拷贝过程了- -，它其实是去网上找所有的库再下载一遍，不是完全意义上的拷贝，然而此刻我却发现，我没有把pip换源...难怪下载速度这么慢，建议是换源了再下载。</code></pre><h3 id="把pip换成国内源"><a href="#把pip换成国内源" class="headerlink" title="把pip换成国内源"></a>把pip换成国内源</h3><p>原因：默认的源下载太慢了，除非时刻开着vpn…</p><p>解决方法：</p><pre><code>pip config set global.index-url https://mirrors.aliyun.com/pypi/simple/</code></pre>]]></content>
    
    
    
    <tags>
      
      <tag>git</tag>
      
      <tag>nodejs</tag>
      
      <tag>markdownpad2</tag>
      
      <tag>pip</tag>
      
    </tags>
    
  </entry>
  
  
  
  <entry>
    <title>Hello World</title>
    <link href="/2020/08/17/hello-world/"/>
    <url>/2020/08/17/hello-world/</url>
    
    <content type="html"><![CDATA[<p>Welcome to <a href="https://hexo.io/" target="_blank" rel="noopener">Hexo</a>! This is your very first post. Check <a href="https://hexo.io/docs/" target="_blank" rel="noopener">documentation</a> for more info. If you get any problems when using Hexo, you can find the answer in <a href="https://hexo.io/docs/troubleshooting.html" target="_blank" rel="noopener">troubleshooting</a> or you can ask me on <a href="https://github.com/hexojs/hexo/issues" target="_blank" rel="noopener">GitHub</a>.</p><h2 id="Quick-Start"><a href="#Quick-Start" class="headerlink" title="Quick Start"></a>Quick Start</h2><h3 id="Create-a-new-post"><a href="#Create-a-new-post" class="headerlink" title="Create a new post"></a>Create a new post</h3><pre><code class="hljs bash">$ hexo new <span class="hljs-string">"My New Post"</span></code></pre><p>More info: <a href="https://hexo.io/docs/writing.html" target="_blank" rel="noopener">Writing</a></p><h3 id="Run-server"><a href="#Run-server" class="headerlink" title="Run server"></a>Run server</h3><pre><code class="hljs bash">$ hexo server</code></pre><p>More info: <a href="https://hexo.io/docs/server.html" target="_blank" rel="noopener">Server</a></p><h3 id="Generate-static-files"><a href="#Generate-static-files" class="headerlink" title="Generate static files"></a>Generate static files</h3><pre><code class="hljs bash">$ hexo generate</code></pre><p>More info: <a href="https://hexo.io/docs/generating.html" target="_blank" rel="noopener">Generating</a></p><h3 id="Deploy-to-remote-sites"><a href="#Deploy-to-remote-sites" class="headerlink" title="Deploy to remote sites"></a>Deploy to remote sites</h3><pre><code class="hljs bash">$ hexo deploy</code></pre><p>More info: <a href="https://hexo.io/docs/one-command-deployment.html" target="_blank" rel="noopener">Deployment</a></p>]]></content>
    
    
    
  </entry>
  
  
  
  <entry>
    <title>[技术笔记]一些常用库的引入规定（持续更新）</title>
    <link href="/2020/08/13/%E6%8A%80%E6%9C%AF%E7%AC%94%E8%AE%B0-%E4%B8%80%E4%BA%9B%E5%B8%B8%E7%94%A8%E5%BA%93%E7%9A%84%E5%BC%95%E5%85%A5%E8%A7%84%E5%AE%9A%EF%BC%88%E6%8C%81%E7%BB%AD%E6%9B%B4%E6%96%B0%EF%BC%89/"/>
    <url>/2020/08/13/%E6%8A%80%E6%9C%AF%E7%AC%94%E8%AE%B0-%E4%B8%80%E4%BA%9B%E5%B8%B8%E7%94%A8%E5%BA%93%E7%9A%84%E5%BC%95%E5%85%A5%E8%A7%84%E5%AE%9A%EF%BC%88%E6%8C%81%E7%BB%AD%E6%9B%B4%E6%96%B0%EF%BC%89/</url>
    
    <content type="html"><![CDATA[<pre><code>import pandas as pdfrom pandas import Series, DataFrameimport matplotlib.pyplot as plt # 常用的绘图库from datetime import datetime/date/time/timedelta # python标准库里常用的时间方法from dateutil.parser import prase # pandas自动安装的时间包，parse方法可以解析几乎所有人类能够理解的日期表达形式import pytz #下载pandas自带的一个时区库from sklearn.tree import DecisionTreeRegressor #引用决策树模型from sklearn.model_Selection import train_test_split #用于在将数据带入模型前先将清理好的数据分成train类和test类from sklearn.metrics import mean_absolute_error # 引入平均绝对离差from sklearn.ensamble import RandomForestRegressor # 引入随机森林模型</code></pre>]]></content>
    
    
    <categories>
      
      <category>技术笔记</category>
      
      <category>python</category>
      
    </categories>
    
    
    <tags>
      
      <tag>常用库</tag>
      
    </tags>
    
  </entry>
  
  
  
  <entry>
    <title>[技术笔记]plt.plot()的marker、color、linestyle参数</title>
    <link href="/2020/08/04/%E6%8A%80%E6%9C%AF%E7%AC%94%E8%AE%B0-plt-plot-%E7%9A%84marker%E3%80%81color%E3%80%81linestyle%E5%8F%82%E6%95%B0/"/>
    <url>/2020/08/04/%E6%8A%80%E6%9C%AF%E7%AC%94%E8%AE%B0-plt-plot-%E7%9A%84marker%E3%80%81color%E3%80%81linestyle%E5%8F%82%E6%95%B0/</url>
    
    <content type="html"><![CDATA[<p><em>ax.plot(x, y, ‘g—‘)</em>和<em>ax.plot(x, y, linestyle=’—‘, color=’g’)</em>是等价的，前者通过格式字符串书写，较为简单，其格式可以为：</p><pre><code>fmt = &#39;[marker][line][color]&#39;</code></pre><p>或者：</p><pre><code>fmt = &#39;[color][marker][line]&#39;</code></pre><p>当然也可以通过color(c) = …, linestyle(ls) = …, marker = …获得。三者的具体常用标记如下：</p><h3 id="Colors"><a href="#Colors" class="headerlink" title="Colors"></a>Colors</h3><div class="table-container"><table><thead><tr><th>character</th><th>color</th></tr></thead><tbody><tr><td>‘b’</td><td>blue</td></tr><tr><td>‘g’</td><td>green</td></tr><tr><td>‘r’</td><td>red</td></tr><tr><td>‘c’</td><td>青色</td></tr><tr><td>‘m’</td><td>品红</td></tr><tr><td>‘y’</td><td>yellow</td></tr><tr><td>‘k’</td><td>black</td></tr><tr><td>‘w’</td><td>white</td></tr></tbody></table></div><p>如果颜色是格式字符串的唯一部分，则可以另外使用任何<a href="https://matplotlib.org/api/colors_api.html#module-matplotlib.colors" target="_blank" rel="noopener">matplotlib.colors</a>规格，例如全名（’green’）或十六进制字符串（’#008000’）。</p><h3 id="Markers"><a href="#Markers" class="headerlink" title="Markers"></a>Markers</h3><div class="table-container"><table><thead><tr><th>character</th><th>marker</th></tr></thead><tbody><tr><td>‘.’</td><td>点标记</td></tr><tr><td>‘,’</td><td>像素标记</td></tr><tr><td>‘o’</td><td>圆圈标记</td></tr><tr><td>‘v’</td><td>triangle_down标记</td></tr><tr><td>‘^’</td><td>三角形标记</td></tr><tr><td>‘&lt;’</td><td>triangle_left标记</td></tr><tr><td>‘&gt;’</td><td>triangle_right标记</td></tr><tr><td>‘1’</td><td>tri_down标记</td></tr><tr><td>‘2’</td><td>tri_up标记</td></tr><tr><td>‘3’</td><td>tri_left标记</td></tr><tr><td>‘4’</td><td>tri_right标记</td></tr><tr><td>‘s’</td><td>方形标记</td></tr><tr><td>‘p’</td><td>五边形标记</td></tr><tr><td>‘*’</td><td>星标</td></tr><tr><td>‘h’</td><td>六角形标记1</td></tr><tr><td>‘H’</td><td>六角形标记2</td></tr><tr><td>‘+’</td><td>加号</td></tr><tr><td>‘x’</td><td>X标记</td></tr><tr><td>‘D’</td><td>钻石标记</td></tr><tr><td>‘d’</td><td>小钻石标记</td></tr><tr><td>‘_’</td><td>水平线标记</td></tr></tbody></table></div><h3 id="Linestyles"><a href="#Linestyles" class="headerlink" title="Linestyles"></a>Linestyles</h3><div class="table-container"><table><thead><tr><th>character</th><th>linestyle</th></tr></thead><tbody><tr><td>‘-‘</td><td>实线</td></tr><tr><td>‘—‘</td><td>虚线</td></tr><tr><td>‘-.’</td><td>点划线</td></tr><tr><td>‘:’</td><td>点线</td></tr></tbody></table></div>]]></content>
    
    
    <categories>
      
      <category>技术笔记</category>
      
      <category>python</category>
      
    </categories>
    
    
    <tags>
      
      <tag>matplotlib</tag>
      
    </tags>
    
  </entry>
  
  
  
  <entry>
    <title>[技术笔记]Jupyter Notebook 和绘图有关的几个魔术指令（%matplotlib inline, auto, notebook）</title>
    <link href="/2020/08/02/%E6%8A%80%E6%9C%AF%E7%AC%94%E8%AE%B0-Jupyter-Notebook-%E5%92%8C%E7%BB%98%E5%9B%BE%E6%9C%89%E5%85%B3%E7%9A%84%E5%87%A0%E4%B8%AA%E9%AD%94%E6%9C%AF%E6%8C%87%E4%BB%A4%EF%BC%88-matplotlib-inline-auto-notebook%EF%BC%89/"/>
    <url>/2020/08/02/%E6%8A%80%E6%9C%AF%E7%AC%94%E8%AE%B0-Jupyter-Notebook-%E5%92%8C%E7%BB%98%E5%9B%BE%E6%9C%89%E5%85%B3%E7%9A%84%E5%87%A0%E4%B8%AA%E9%AD%94%E6%9C%AF%E6%8C%87%E4%BB%A4%EF%BC%88-matplotlib-inline-auto-notebook%EF%BC%89/</url>
    
    <content type="html"><![CDATA[<p>Jupyter notebook默认输出的图片是静态的，无法进行放大等操作，可以添加一条魔术指令：</p><pre><code>%matplotlib notebook</code></pre><p>这样就能够在notebook中进行放大缩小等交互操作了。</p><p>在notebook中使用plt绘图共有三种模式：</p><ol><li>%matplotlib inline：这是默认的模式，输出的图片是静态的</li><li>%matplotlib auto：在这个模式下会弹出一个单独 的绘图窗口，和在pycharm中一样</li><li>%matplotlib notebook：在这个模式下会在notebook中产生一个绘图窗口，能够对图片进行放大缩小等操作。</li></ol><p>注：本文为转载，原文链接：<a href="https://blog.csdn.net/qq_26822029/article/details/103064856" target="_blank" rel="noopener">https://blog.csdn.net/qq_26822029/article/details/103064856</a></p>]]></content>
    
    
    <categories>
      
      <category>技术笔记</category>
      
      <category>python</category>
      
    </categories>
    
    
    <tags>
      
      <tag>Jupyter Notebook</tag>
      
      <tag>转载</tag>
      
    </tags>
    
  </entry>
  
  
  
  <entry>
    <title>[技术笔记]pandas中常用的汇总和统计方法</title>
    <link href="/2020/07/30/%E6%8A%80%E6%9C%AF%E7%AC%94%E8%AE%B0-pandas%E4%B8%AD%E5%B8%B8%E7%94%A8%E7%9A%84%E6%B1%87%E6%80%BB%E5%92%8C%E7%BB%9F%E8%AE%A1%E6%96%B9%E6%B3%95/"/>
    <url>/2020/07/30/%E6%8A%80%E6%9C%AF%E7%AC%94%E8%AE%B0-pandas%E4%B8%AD%E5%B8%B8%E7%94%A8%E7%9A%84%E6%B1%87%E6%80%BB%E5%92%8C%E7%BB%9F%E8%AE%A1%E6%96%B9%E6%B3%95/</url>
    
    <content type="html"><![CDATA[<div class="table-container"><table><thead><tr><th>方法</th><th>说明</th></tr></thead><tbody><tr><td>count</td><td>计算非NA值的数量</td></tr><tr><td>describe</td><td>汇总统计</td></tr><tr><td>min、max</td><td>计算最大最小值</td></tr><tr><td>argmin、argmax</td><td>最大最小值所在的索引位置（整数）</td></tr><tr><td>idxmin、idxmax</td><td>最大最小值所在的索引标签</td></tr><tr><td>quantile</td><td>计算样本的分位数</td></tr><tr><td>sum</td><td>值的总和</td></tr><tr><td>mean</td><td>值的平均数</td></tr><tr><td>median</td><td>值的算术中位数</td></tr><tr><td>mad</td><td>平均绝对离差</td></tr><tr><td>var</td><td>方差</td></tr><tr><td>std</td><td>标准差</td></tr><tr><td>skew</td><td>偏度</td></tr><tr><td>kurt</td><td>峰度</td></tr><tr><td>cumsum</td><td>累计和</td></tr><tr><td>cummin、cummax</td><td>累计最大值和累计最小值</td></tr><tr><td>cumprod</td><td>累计积</td></tr><tr><td>diff</td><td>一阶差分</td></tr><tr><td>pct_change</td><td>百分数变化</td></tr></tbody></table></div><p><sup id="fnref:1" class="footnote-ref"><a href="#fn:1" rel="footnote"><span class="hint--top hint--rounded" aria-label="上述统计方法都是基于样本而言，自由度为N-1">[1]</span></a></sup></p><p>注释：</p><section class="footnotes"><div class="footnote-list"><ol><li><span id="fn:1" class="footnote-text"><span>上述统计方法都是基于样本而言，自由度为N-1<a href="#fnref:1" rev="footnote" class="footnote-backref"> ↩</a></span></span></li></ol></div></section>]]></content>
    
    
    <categories>
      
      <category>技术笔记</category>
      
      <category>python</category>
      
    </categories>
    
    
    <tags>
      
      <tag>统计</tag>
      
    </tags>
    
  </entry>
  
  
  
  <entry>
    <title>[技术笔记]dataframe.apply和groupby.apply的区别</title>
    <link href="/2020/07/28/%E6%8A%80%E6%9C%AF%E7%AC%94%E8%AE%B0-dataframe-apply%E5%92%8Cgroupby-apply%E7%9A%84%E5%8C%BA%E5%88%AB/"/>
    <url>/2020/07/28/%E6%8A%80%E6%9C%AF%E7%AC%94%E8%AE%B0-dataframe-apply%E5%92%8Cgroupby-apply%E7%9A%84%E5%8C%BA%E5%88%AB/</url>
    
    <content type="html"><![CDATA[<p>在看书学习apply函数的过程中，我发现书上还是比较集中于讲解apply在groupby分组、聚合这方面的作用，如下面这个用特定于分组的值填充缺失值<sup id="fnref:1" class="footnote-ref"><a href="#fn:1" rel="footnote"><span class="hint--top hint--rounded" aria-label="参考了书上代码">[1]</span></a></sup>：<br>    In [91]: s = pd.Series(np.random.randn(6))</p><pre><code>In [92]: s[::2] = np.nanIn [93]: sOut[93]: 0         NaN1   -0.1259212         NaN3   -0.8844754         NaN5    0.227290dtype: float64In [94]: s.fillna(s.mean())Out[94]: 0   -0.2610351   -0.1259212   -0.2610353   -0.8844754   -0.2610355    0.227290dtype: float64</code></pre><p>这里用mean()函数对整体做了平均，而事实上我们大多数时候可能需要对各分组赋予不同的填充值，于是可以用以下方法实现填充：</p><p>假设你需要对不同的分组填充不同的值。一种方法是将数据分组，并使用apply和一个能够对各数据块调用fillna的函数即可。下面是一些有关美国几个州的示例数据，这些州又被分为东部和西部：</p><pre><code>In [95]: states = [&#39;Ohio&#39;, &#39;New York&#39;, &#39;Vermont&#39;, &#39;Florida&#39;,   ....:           &#39;Oregon&#39;, &#39;Nevada&#39;, &#39;California&#39;, &#39;Idaho&#39;]In [96]: group_key = [&#39;East&#39;] * 4 + [&#39;West&#39;] * 4In [97]: data = pd.Series(np.random.randn(8), index=states)In [98]: dataOut[98]: Ohio          0.922264New York     -2.153545Vermont      -0.365757Florida      -0.375842Oregon        0.329939Nevada        0.981994California    1.105913Idaho        -1.613716dtype: float64#将一些数据点设置为缺失值In [99]: data[[&#39;Vermont&#39;, &#39;Nevada&#39;, &#39;Idaho&#39;]] = np.nanIn [100]: dataOut[100]: Ohio          0.922264New York     -2.153545Vermont            NaNFlorida      -0.375842Oregon        0.329939Nevada             NaNCalifornia    1.105913Idaho              NaNdtype: float64In [101]: data.groupby(group_key).mean()Out[101]: East   -0.535707West    0.717926dtype: float64</code></pre><p>接下来可以用分组平均值去填充NA：</p><pre><code>In [102]: fill_mean = lambda g: g.fillna(g.mean())In [103]: data.groupby(group_key).apply(fill_mean)Out[103]: Ohio          0.922264New York     -2.153545Vermont      -0.535707Florida      -0.375842Oregon        0.329939Nevada        0.717926California    1.105913Idaho         0.717926dtype: float64</code></pre><p>可以看出，当apply函数作用与groupby时，<strong>他的对象就是groupby()中的分组键，或者更确切地说，是分组键分割开来的各个组</strong>，因此，apply中函数的对象也应该就考虑是一个dataframe或者series。</p><p>但这一点再直接应用到DataFrame时就有所不同，<strong>此时apply中函数的对象是dataframe的一列或者一行的每一个元素。</strong></p><p><img src="/2020/07/28/%E6%8A%80%E6%9C%AF%E7%AC%94%E8%AE%B0-dataframe-apply%E5%92%8Cgroupby-apply%E7%9A%84%E5%8C%BA%E5%88%AB/1.jpg" srcset="/img/loading.gif" alt></p><p><strong>可以看到majority函数的x的对象就是column age的每一个元素。</strong></p><p>参考：</p><section class="footnotes"><div class="footnote-list"><ol><li><span id="fn:1" class="footnote-text"><span>参考了书上代码<a href="#fnref:1" rev="footnote" class="footnote-backref"> ↩</a></span></span></li></ol></div></section>]]></content>
    
    
    <categories>
      
      <category>技术笔记</category>
      
      <category>python</category>
      
    </categories>
    
    
    <tags>
      
      <tag>apply()函数</tag>
      
    </tags>
    
  </entry>
  
  
  
  <entry>
    <title>[学习笔记]综合评价模型</title>
    <link href="/2020/07/27/%E5%AD%A6%E4%B9%A0%E7%AC%94%E8%AE%B0-%E7%BB%BC%E5%90%88%E8%AF%84%E4%BB%B7%E6%A8%A1%E5%9E%8B/"/>
    <url>/2020/07/27/%E5%AD%A6%E4%B9%A0%E7%AC%94%E8%AE%B0-%E7%BB%BC%E5%90%88%E8%AF%84%E4%BB%B7%E6%A8%A1%E5%9E%8B/</url>
    
    <content type="html"><![CDATA[<p>综合评价问题：综合考虑事物的多个指标所包含的信息，对各个备选决策方案优劣进行排序，最终选出最优方案。</p><p>主要步骤：（1）选择综合评价指标（不遗漏、不重复、尽可能独立）；（2）确定各参评方案的指标值，形成决策矩阵；（3）指标值预处理（目的：消除指标值在单位、数量级、方向性三个方面的差异）；（4）确定各项指标的权重系数（重要程度）；（5）对预处理后的指标值进行加权综合，给出各方案的综合得分，按照综合得分对各个参评方案进行优劣排序。</p><p>评价方法分类：（1）主观复权法：综合指数法、模糊综合评判法、层次分析法、功效系数法等。（2）客观赋权法：主成分分析法、因子分析法、熵权法、理想解法（TOPSIS法）等。</p><h2 id="层次分析法（AHP）"><a href="#层次分析法（AHP）" class="headerlink" title="层次分析法（AHP）"></a>层次分析法（AHP）</h2><p>假设有n个指标，我们虽然不知道他们的各自重要程度（权重），但知道它们的重要程度之比，则可以以这个比值建立一个成对比较矩阵A，根据矩阵获得各个指标的权重。</p><p>根据特征向量的定义，可以得出这个矩<strong>阵A具有特征值n和特征向量W = (W1,W2,W3,W4….Wn).T</strong>。</p><p><img src="/2020/07/27/%E5%AD%A6%E4%B9%A0%E7%AC%94%E8%AE%B0-%E7%BB%BC%E5%90%88%E8%AF%84%E4%BB%B7%E6%A8%A1%E5%9E%8B/1.jpg" srcset="/img/loading.gif" alt></p><p>并且有定理：1、A的秩为1，A的唯一非零特征值为n；2、A的任一列向量都是对应于特征值n 的特征向量。在此定理下，对任一列向量归一化后，就给出了这n个指标的权重的真实值。</p><p><strong>比值的确定就是主观的</strong>,Saaty等人提出1~9尺度——aij 取值1,2,… , 9及其互反数1,1/2, … , 1/9，因为心理学家认为成对比较的因素不宜超过9个。需要注意的是，对影响因素为负的指标，要提前做处理，不然性质不符，无法使用此方法。</p><p>性质1和性质2是较好满足的，但性质3这种传递性在主观下很难满足。但Saaty认为，我们在实际操作时不需要完全满足一致性，只要能通过<strong>一致性检验</strong>即可。</p><h3 id="一致性检验"><a href="#一致性检验" class="headerlink" title="一致性检验"></a>一致性检验</h3><p><img src="/2020/07/27/%E5%AD%A6%E4%B9%A0%E7%AC%94%E8%AE%B0-%E7%BB%BC%E5%90%88%E8%AF%84%E4%BB%B7%E6%A8%A1%E5%9E%8B/2.png" srcset="/img/loading.gif" alt></p><p>CI越大，不一致越严重。为衡量CI的大小，引入随机一致性指标RI——随机模拟得到aij, 形成A，计算CI即得RI。</p><p>令<strong>CR = CI/RI</strong>，一般认为当CR&lt;0.1时，通过一致性检验。</p><h2 id="熵权法"><a href="#熵权法" class="headerlink" title="熵权法"></a>熵权法</h2><p>熵权法是一种<strong>客观赋权法</strong>，基础是各项指标都已经量化好，利用指标值数据的离散程度来确定各项指标在综合评价中的权重，离散程度越大，该项指标权重越大。</p><p>在信息论中，熵是对不确定性的一种度量。不确定性越大，熵就越小。</p><h3 id="step1：数据预处理"><a href="#step1：数据预处理" class="headerlink" title="step1：数据预处理"></a>step1：数据预处理</h3><p><img src="/2020/07/27/%E5%AD%A6%E4%B9%A0%E7%AC%94%E8%AE%B0-%E7%BB%BC%E5%90%88%E8%AF%84%E4%BB%B7%E6%A8%A1%E5%9E%8B/2.jpg" srcset="/img/loading.gif" alt></p><h3 id="step2：数据归一化"><a href="#step2：数据归一化" class="headerlink" title="step2：数据归一化"></a>step2：数据归一化</h3><p>让各个指标数据的和为1，即Pi = Yi / （Y1+Y2+Y3+….+Yn）。</p><h3 id="step3：计算第j项指标的熵"><a href="#step3：计算第j项指标的熵" class="headerlink" title="step3：计算第j项指标的熵"></a>step3：计算第j项指标的熵</h3><p><img src="/2020/07/27/%E5%AD%A6%E4%B9%A0%E7%AC%94%E8%AE%B0-%E7%BB%BC%E5%90%88%E8%AF%84%E4%BB%B7%E6%A8%A1%E5%9E%8B/3.png" srcset="/img/loading.gif" alt></p><h3 id="step4：计算指标的离散程度并计算权重"><a href="#step4：计算指标的离散程度并计算权重" class="headerlink" title="step4：计算指标的离散程度并计算权重"></a>step4：计算指标的离散程度并计算权重</h3><p>令Dj = 1 - Ej（因为熵越大，不确定性越小），接下来再把各个指标的离散程度归一化处理。</p><h3 id="step6：计算结果并排序"><a href="#step6：计算结果并排序" class="headerlink" title="step6：计算结果并排序"></a>step6：计算结果并排序</h3><h2 id="理想点法"><a href="#理想点法" class="headerlink" title="理想点法"></a>理想点法</h2><p>理想点法是综合各个方案与理想的最优方案以及最差方案之间的距离，对各个方案的优劣进行排序，与最优方案越接近同时与最差方案距离越远的方案，综合得分越高。</p><h3 id="step1：数据的预处理"><a href="#step1：数据的预处理" class="headerlink" title="step1：数据的预处理"></a>step1：数据的预处理</h3><p>方法有很多，此处就不再赘述了。</p><h3 id="step2：确定各个指标的权重"><a href="#step2：确定各个指标的权重" class="headerlink" title="step2：确定各个指标的权重"></a>step2：确定各个指标的权重</h3><p>可以用所有用于确定指标权重的方法。</p><h3 id="step3：计算加权的指标值"><a href="#step3：计算加权的指标值" class="headerlink" title="step3：计算加权的指标值"></a>step3：计算加权的指标值</h3><h3 id="step4：确定正理想方案和负理想方案"><a href="#step4：确定正理想方案和负理想方案" class="headerlink" title="step4：确定正理想方案和负理想方案"></a>step4：确定正理想方案和负理想方案</h3><h3 id="step5：计算各个方案到正负理想方案的距离"><a href="#step5：计算各个方案到正负理想方案的距离" class="headerlink" title="step5：计算各个方案到正负理想方案的距离"></a>step5：计算各个方案到正负理想方案的距离</h3><h3 id="step6：计算各个方案的综合得分"><a href="#step6：计算各个方案的综合得分" class="headerlink" title="step6：计算各个方案的综合得分"></a>step6：计算各个方案的综合得分</h3>]]></content>
    
    
    <categories>
      
      <category>学习笔记</category>
      
      <category>数学建模</category>
      
    </categories>
    
    
    <tags>
      
      <tag>综合评价模型</tag>
      
    </tags>
    
  </entry>
  
  
  
  <entry>
    <title>[学习笔记]微分方程模型</title>
    <link href="/2020/07/27/%E5%AD%A6%E4%B9%A0%E7%AC%94%E8%AE%B0-%E5%BE%AE%E5%88%86%E6%96%B9%E7%A8%8B%E6%A8%A1%E5%9E%8B/"/>
    <url>/2020/07/27/%E5%AD%A6%E4%B9%A0%E7%AC%94%E8%AE%B0-%E5%BE%AE%E5%88%86%E6%96%B9%E7%A8%8B%E6%A8%A1%E5%9E%8B/</url>
    
    <content type="html"><![CDATA[<p><strong>微分方程模型的思想</strong>：假设我们要研究量x,y,z 与t的关系,微分方程模型的思想是从考察量x,y,z对t的导数(即x,y,z对t的变化率)入手，找出导数符合的规律，建立包含未知函数的导数(偏导数)的方程(方程组)，通过分析、求解微分方程（组）来获得x,y,z与t的函数关系。</p><p>以下是几个常见的根据微分方程构建的模型：</p><h2 id="人口增长模型"><a href="#人口增长模型" class="headerlink" title="人口增长模型"></a>人口增长模型</h2><h3 id="马尔萨斯的指数增长模型"><a href="#马尔萨斯的指数增长模型" class="headerlink" title="马尔萨斯的指数增长模型"></a>马尔萨斯的指数增长模型</h3><p>基本假设：单位时间内人口的增长率为常数r，即<img src="/2020/07/27/%E5%AD%A6%E4%B9%A0%E7%AC%94%E8%AE%B0-%E5%BE%AE%E5%88%86%E6%96%B9%E7%A8%8B%E6%A8%A1%E5%9E%8B/1.png" srcset="/img/loading.gif" alt></p><p>x(t)可以用指数形式来表示，再通过求导即可得到每年的人口增长速度。这个模型有它的优点和缺陷：<strong>可用于短期人口增长预测</strong>（与19世纪以前欧洲一些地区人口统计数据吻合/适用于19世纪后迁往加拿大的欧洲移民后代），但<strong>不能预测较长期的人口增长过程</strong>（不符合19世纪后多数地区人口增长规律，人口增长率r逐渐下降）。</p><h3 id="阻滞增长模型（Logistic模型）"><a href="#阻滞增长模型（Logistic模型）" class="headerlink" title="阻滞增长模型（Logistic模型）"></a>阻滞增长模型（Logistic模型）</h3><p>基本思想：人口增长到一定程度时，由于资源、环境等约束，人口本身会对r产生影响，即r是x的减函数。最简单的函数是线性函数，因此令<strong>r（x） = r - sx， 其中s = r/Smax</strong>，在此条件下可以求得<img src="/2020/07/27/%E5%AD%A6%E4%B9%A0%E7%AC%94%E8%AE%B0-%E5%BE%AE%E5%88%86%E6%96%B9%E7%A8%8B%E6%A8%A1%E5%9E%8B/2.png" srcset="/img/loading.gif" alt></p><p>两个未知参数r和Smax可以用以前的数据去拟合（ols）。</p><p>进一步改进则引入其他的非线性函数，并求解相关系数。</p><h3 id="传染病传播模型"><a href="#传染病传播模型" class="headerlink" title="传染病传播模型"></a>传染病传播模型</h3><p>比较科学的两个模型：SIS（传染病可治愈但无免疫性）和SIR（传染病可治愈且有免疫性）。</p>]]></content>
    
    
    <categories>
      
      <category>学习笔记</category>
      
      <category>数学建模</category>
      
    </categories>
    
    
    <tags>
      
      <tag>微分方程模型</tag>
      
    </tags>
    
  </entry>
  
  
  
  <entry>
    <title>[技术笔记]jupyter不能通过浏览器自动打开</title>
    <link href="/2020/07/27/%E6%8A%80%E6%9C%AF%E7%AC%94%E8%AE%B0-jupyter%E4%B8%8D%E8%83%BD%E9%80%9A%E8%BF%87%E6%B5%8F%E8%A7%88%E5%99%A8%E8%87%AA%E5%8A%A8%E6%89%93%E5%BC%80/"/>
    <url>/2020/07/27/%E6%8A%80%E6%9C%AF%E7%AC%94%E8%AE%B0-jupyter%E4%B8%8D%E8%83%BD%E9%80%9A%E8%BF%87%E6%B5%8F%E8%A7%88%E5%99%A8%E8%87%AA%E5%8A%A8%E6%89%93%E5%BC%80/</url>
    
    <content type="html"><![CDATA[<p>这两天用win+R打开juypter的时候发现不能通过浏览器自动打开了，只能手动打开。之前我配置的默认浏览器是chrome，中间因为chrome版本太低Google帮我重装过一次，怀疑是重装过后的chrome被改了文件路径，从而导致打不开了，因此决定重新配置juypter的路径即可：</p><p>1、在cmd下执行<em>jupyter notebook —generate-config</em>，会提示该文件所在的目录，我的是C:\Users\Administrator.jupyter\jupyter_notebook_config.py。</p><p>2、进入该目录，用编辑器打开这个文件（我用的是Geany，应该txt编辑器也可以）。</p><p>3、用crtl+F找到<em>#c.NotebookApp.browser</em>，在其下方复制</p><pre><code>import webbrowserwebbrowser.register(&quot;chrome&quot;,None,webbrowser.GenericBrowser(r&quot;C:\Program Files (x86)\Google\Chrome\Application\chrome.exe&quot;))c.NotebookApp.browser = &#39;chrome&#39;</code></pre><p>我这里用的是chrome，其他浏览器同理，位置路径的确变了，因此替换了位置路径。如果不想改变字符串中的反斜杠\，则在字符串前加上r。</p><p>4、保存并运行，发现成功自动打开浏览器了。</p>]]></content>
    
    
    <categories>
      
      <category>技术笔记</category>
      
      <category>python</category>
      
    </categories>
    
    
    <tags>
      
      <tag>jupyter notebook</tag>
      
    </tags>
    
  </entry>
  
  
  
  <entry>
    <title>[学习笔记]差分方程模型</title>
    <link href="/2020/07/26/%E5%AD%A6%E4%B9%A0%E7%AC%94%E8%AE%B0-%E5%B7%AE%E5%88%86%E6%96%B9%E7%A8%8B%E6%A8%A1%E5%9E%8B/"/>
    <url>/2020/07/26/%E5%AD%A6%E4%B9%A0%E7%AC%94%E8%AE%B0-%E5%B7%AE%E5%88%86%E6%96%B9%E7%A8%8B%E6%A8%A1%E5%9E%8B/</url>
    
    <content type="html"><![CDATA[<p>差分方程，顾名思义，研究的是一组有规律序列相邻两个时间段间的规律，这种规律能够全部（部分）运用（使用迭代或递推）到一个总体，从而求解问题。</p><h2 id="一阶线性差分方程模型"><a href="#一阶线性差分方程模型" class="headerlink" title="一阶线性差分方程模型"></a>一阶线性差分方程模型</h2><p><strong><em>ΔAn = An+1 - An = f(An,其他因素)</em></strong> 这样一个方程可以被称为一阶差分方程模型，如果f(An,其他因素)是关于An的线性模式，则被称为一阶线性差分方程模型，即<img src="/2020/07/26/%E5%AD%A6%E4%B9%A0%E7%AC%94%E8%AE%B0-%E5%B7%AE%E5%88%86%E6%96%B9%E7%A8%8B%E6%A8%A1%E5%9E%8B/1.png" srcset="/img/loading.gif" alt></p><h3 id="一阶线性差分方程的解及其长期行为"><a href="#一阶线性差分方程的解及其长期行为" class="headerlink" title="一阶线性差分方程的解及其长期行为"></a>一阶线性差分方程的解及其长期行为</h3><p>很容易得到<img src="/2020/07/26/%E5%AD%A6%E4%B9%A0%E7%AC%94%E8%AE%B0-%E5%B7%AE%E5%88%86%E6%96%B9%E7%A8%8B%E6%A8%A1%E5%9E%8B/2.png" srcset="/img/loading.gif" alt></p><p>当n趋于无穷时，<img src="/2020/07/26/%E5%AD%A6%E4%B9%A0%E7%AC%94%E8%AE%B0-%E5%B7%AE%E5%88%86%E6%96%B9%E7%A8%8B%E6%A8%A1%E5%9E%8B/3.png" srcset="/img/loading.gif" alt><img src="/2020/07/26/%E5%AD%A6%E4%B9%A0%E7%AC%94%E8%AE%B0-%E5%B7%AE%E5%88%86%E6%96%B9%E7%A8%8B%E6%A8%A1%E5%9E%8B/4.jpg" srcset="/img/loading.gif" alt></p><h3 id="差分方程模型的平衡点"><a href="#差分方程模型的平衡点" class="headerlink" title="差分方程模型的平衡点"></a>差分方程模型的平衡点</h3><p>平衡点是指An = a, An+1 = a 的情况，如果长期行为等于平衡点，则称之为稳定的平衡点。</p><h2 id="一阶非线性差分方程模型"><a href="#一阶非线性差分方程模型" class="headerlink" title="一阶非线性差分方程模型"></a>一阶非线性差分方程模型</h2><p>我们一般通过变化的散点图，猜想出ΔAn变化的规律，即f(An,其他因素)的形式，再和OLS相结合来拟合关于ΔAn的曲线。当然，差分方程也只是解决拟合问题的一种方法，存在其他更加合适的方法时，也可以用其他方法解决。</p>]]></content>
    
    
    <categories>
      
      <category>学习笔记</category>
      
      <category>数学建模</category>
      
    </categories>
    
    
    <tags>
      
      <tag>差分方程模型</tag>
      
      <tag>动力系统模型</tag>
      
    </tags>
    
  </entry>
  
  
  
  <entry>
    <title>[技术笔记]pandas中agg()与apply()的区别</title>
    <link href="/2020/07/19/%E6%8A%80%E6%9C%AF%E7%AC%94%E8%AE%B0-pandas%E4%B8%ADagg-%E4%B8%8Eapply-%E7%9A%84%E5%8C%BA%E5%88%AB/"/>
    <url>/2020/07/19/%E6%8A%80%E6%9C%AF%E7%AC%94%E8%AE%B0-pandas%E4%B8%ADagg-%E4%B8%8Eapply-%E7%9A%84%E5%8C%BA%E5%88%AB/</url>
    
    <content type="html"><![CDATA[<p>对数据集进行分组并对各组应用一个函数（无论是聚合还是转换），通常是数据分析工作中的重要环节<sup id="fnref:1" class="footnote-ref"><a href="#fn:1" rel="footnote"><span class="hint--top hint--rounded" aria-label="源自‘python for data analysis’ chapter 10">[1]</span></a></sup>。<br><img src="/2020/07/19/%E6%8A%80%E6%9C%AF%E7%AC%94%E8%AE%B0-pandas%E4%B8%ADagg-%E4%B8%8Eapply-%E7%9A%84%E5%8C%BA%E5%88%AB/1.png" srcset="/img/loading.gif" alt></p><p>这张表就阐述了整一个GroupBy的机制。一般来说，Split部分用groupby()完成，但apply部分可以用apply,agg以及其他一些特定的函数完成（如count，mean，sum等）。</p><p>在<em>‘python for data analysis’</em>一书中并没有很明确地指出这两者的区别，只是说apply比agg更具有普适性，但对应的运行速度也会偏慢（好比在agg中执行自建函数总要比执行已经规划好的优化函数要慢一样）。</p><p>看了网上很多资料，感觉agg与apply的区别主要是，agg只能对数组运算并产生标量值，而apply除此之外还可以返回一个pandas对象，这是agg做不到的，就比如想要对一个数组进行排序操作时，就只能用apply而不能用agg。</p><p>引用：</p><section class="footnotes"><div class="footnote-list"><ol><li><span id="fn:1" class="footnote-text"><span>源自<em>‘python for data analysis’ chapter 10</em><a href="#fnref:1" rev="footnote" class="footnote-backref"> ↩</a></span></span></li></ol></div></section>]]></content>
    
    
    <categories>
      
      <category>技术笔记</category>
      
      <category>python</category>
      
    </categories>
    
    
    <tags>
      
      <tag>数据聚合和分组运算</tag>
      
    </tags>
    
  </entry>
  
  
  
  <entry>
    <title>[学习笔记]插值与拟合</title>
    <link href="/2020/07/17/%E5%AD%A6%E4%B9%A0%E7%AC%94%E8%AE%B0-%E6%8F%92%E5%80%BC%E4%B8%8E%E6%8B%9F%E5%90%88/"/>
    <url>/2020/07/17/%E5%AD%A6%E4%B9%A0%E7%AC%94%E8%AE%B0-%E6%8F%92%E5%80%BC%E4%B8%8E%E6%8B%9F%E5%90%88/</url>
    
    <content type="html"><![CDATA[<p>插值的一般思路：根据已知数据点构造一个一般的函数，该函数对现有数据有较好的拟合效果，再用这个函数进行插值预测。构造函数的方法是一个重点（回归的<em>OLS、FSLS、GLS、WLS、Probit、Logit</em>等都是计量中评估的函数方法）。插值一般用来进行填补数据集，但不用做数据预测。 </p><h2 id="多项式插值"><a href="#多项式插值" class="headerlink" title="多项式插值"></a>多项式插值</h2><p>通过一个构造一个多项式函数去插值。原因：1.多项式函数比较简单2.<strong><em>Weierstrass</em>一致逼近定理</strong>：给定一个任意小的e，对于一段连续曲线，一定存在一个多项式，两者在定义域内的插值的绝对值小于任何给定的e。</p><p>那么，<strong>如何确定多项式的形式</strong>呢？在多项插值法中的要求是，要使估计函数在第i个观测值处的值f(xi)=实际观测值。</p><p>其优点是：1.可以确定<strong>唯一</strong>的一个估计函数（根据范德蒙行列式的结论，证明略）；2.在已知<strong>观测值附近，该函数的近似效果是非常好</strong>的（显然，对于一个连续函数，就是有这样的能力，高等数学里都有学到，这也是OLS这种总体误差最小方法所不具备的优点）。</p><p>并且，如果题目提供n+1个观测值，就可以据此列出一个n次多项式（因为n次多项式有包括截距在内有n+1个未知数，需要n+1个条件）。但这样也存在问题，当次数多，数据大时，<strong>容易出现<em>Runge</em>现象</strong>，即高次项数对数据很敏感，微小的扰动都会造成巨大的变化。因此，具有下列改进的方法：</p><h3 id="Lagrange插值法"><a href="#Lagrange插值法" class="headerlink" title="Lagrange插值法"></a><em>Lagrange</em>插值法</h3><p><img src="/2020/07/17/%E5%AD%A6%E4%B9%A0%E7%AC%94%E8%AE%B0-%E6%8F%92%E5%80%BC%E4%B8%8E%E6%8B%9F%E5%90%88/1.png" srcset="/img/loading.gif" alt></p><p>其中，<img src="/2020/07/17/%E5%AD%A6%E4%B9%A0%E7%AC%94%E8%AE%B0-%E6%8F%92%E5%80%BC%E4%B8%8E%E6%8B%9F%E5%90%88/2.png" srcset="/img/loading.gif" alt></p><h3 id="Newton插值法"><a href="#Newton插值法" class="headerlink" title="Newton插值法"></a><em>Newton</em>插值法</h3><p><img src="/2020/07/17/%E5%AD%A6%E4%B9%A0%E7%AC%94%E8%AE%B0-%E6%8F%92%E5%80%BC%E4%B8%8E%E6%8B%9F%E5%90%88/3.png" srcset="/img/loading.gif" alt></p><p>其中，<img src="/2020/07/17/%E5%AD%A6%E4%B9%A0%E7%AC%94%E8%AE%B0-%E6%8F%92%E5%80%BC%E4%B8%8E%E6%8B%9F%E5%90%88/4.png" srcset="/img/loading.gif" alt><img src="/2020/07/17/%E5%AD%A6%E4%B9%A0%E7%AC%94%E8%AE%B0-%E6%8F%92%E5%80%BC%E4%B8%8E%E6%8B%9F%E5%90%88/5.png" srcset="/img/loading.gif" alt></p><h3 id="分段插值法"><a href="#分段插值法" class="headerlink" title="分段插值法"></a>分段插值法</h3><p>分段插值法的建立主要是基于上述两种方法在观测点增多时，次数增加，仍会出现<em>Runge</em>现象，因此分段求函似乎会更好。</p><p>比较常见的分段求函就是两个数据点间的线性插值或者三个数据点间的抛物线插值。</p><h3 id="样条插值法"><a href="#样条插值法" class="headerlink" title="样条插值法"></a>样条插值法</h3><p>分段插值虽然避免了<em>Runge</em>现象，但也使曲线很不平滑。因此，用样条插值法改善这一现象。</p><p>三次样条插值：在相邻的两个结点间用一条三次多项式曲线来近似并插值。</p><p>现在的问题是，两个结点之间就需要构造一个三次函数意味着所有结点的三次函数需要4n个条件才能求解，而n+1个观测值只提供了n+1个条件，还缺少3n-1个条件。因此要保证在插值结点处满足衔接条件：<img src="/2020/07/17/%E5%AD%A6%E4%B9%A0%E7%AC%94%E8%AE%B0-%E6%8F%92%E5%80%BC%E4%B8%8E%E6%8B%9F%E5%90%88/6.png" srcset="/img/loading.gif" alt></p><p>这又提供了3n-3个条件，还缺2个条件需要自己定义。</p><ol><li>方法一：定义最初和最末两个结点处的斜率（实际意义是最初和最末的该变量增长速度如何）。</li><li>方法二：定义最初和最末两个结点的二阶导数，一般令其=0（几何意义是斜率为0&lt;—&gt;曲率为0）.</li><li>方法三：<strong>周期边界条件</strong>，即最初和最末两个结点函数值相同，斜率相同。这说明该段观测值会重复出现，这个数据集具有周期性。</li><li>方法四：根据具体问题具体分析，自己添加即可。</li></ol><h3 id="最邻近插值法"><a href="#最邻近插值法" class="headerlink" title="最邻近插值法"></a>最邻近插值法</h3><p>要估计的值最邻近哪个观测值结点，就将那个观测值作为估计值，是一种简单而不准确的估计方法。</p><h2 id="二维插值"><a href="#二维插值" class="headerlink" title="二维插值"></a>二维插值</h2><p>由单自变量变为双自变量问题。结点类型一般分为网格型结点和散乱型结点，根据不同的结点类型<em>Matlab</em>会选择不同的方法。</p><p>插值方法：</p><h3 id="最邻近插值法-1"><a href="#最邻近插值法-1" class="headerlink" title="最邻近插值法"></a>最邻近插值法</h3><p>同多项式插值法中的最邻近插值法原理。</p><h3 id="分片线性插值"><a href="#分片线性插值" class="headerlink" title="分片线性插值"></a>分片线性插值</h3><p>三角形区域连成一整块即可，具体求值用<em>Matlab</em>。</p><h3 id="双线性插值"><a href="#双线性插值" class="headerlink" title="双线性插值"></a>双线性插值</h3><p>对于四个结点构成的网格，构造一个z=(ax+b)(cy+d)，四个未知数用四个网格结点求解，得到一个双线性函数来估计该网格内某点的值。</p><h2 id="曲线拟合"><a href="#曲线拟合" class="headerlink" title="曲线拟合"></a>曲线拟合</h2><p>在前面我们已经给出了一种方法：多项式插值。这种方法要求用来近似未知函数f的n次插值多项式准确无误地经过已知的n+1个结点。然而当结点数据是由某种实验或者计算方法得出的，就难免带有误差，要求多项式严格经过这些结点，无形中就会将误差保留下来，而且如果每一个结点都有误差的话，由于误差累积的效应，也会导致整体的近似效果较差。</p><p>这促使我们寻求一种新的方法近似未知函数，这一方法并不要求用来近似的函数严格通过已知结点，而只要求在结点处误差，按某一标准最小。为了计算方便，通常就采用误差的平方和最小作为度量误差的标准，即<strong>最小二乘原则**</strong>（OLS）**。</p><p>具体计算在<em>Matlab</em>中用<em>polyfit</em>相关命令完成多项式拟合求解。其他类型的曲线则用其他类型的函数解决。</p><h3 id="一个变形：加权最小二乘法-WLS"><a href="#一个变形：加权最小二乘法-WLS" class="headerlink" title="一个变形：加权最小二乘法(WLS)"></a>一个变形：加权最小二乘法(WLS)</h3><p>使用的原因：在不同的观测值点，数据的偏差很不一样（异方差性？在计量经济学中用来解决异方差问题）。</p><h3 id="拟合效果的评价"><a href="#拟合效果的评价" class="headerlink" title="拟合效果的评价"></a>拟合效果的评价</h3><p>最大相对误差/平均相对误差/拟合优度….</p>]]></content>
    
    
    <categories>
      
      <category>学习笔记</category>
      
      <category>数学建模</category>
      
    </categories>
    
    
    <tags>
      
      <tag>插值</tag>
      
      <tag>拟合</tag>
      
    </tags>
    
  </entry>
  
  
  
  <entry>
    <title>[学习笔记]数学规划模型深入</title>
    <link href="/2020/07/16/%E5%AD%A6%E4%B9%A0%E7%AC%94%E8%AE%B0-%E6%95%B0%E5%AD%A6%E8%A7%84%E5%88%92%E6%A8%A1%E5%9E%8B%E6%B7%B1%E5%85%A5/"/>
    <url>/2020/07/16/%E5%AD%A6%E4%B9%A0%E7%AC%94%E8%AE%B0-%E6%95%B0%E5%AD%A6%E8%A7%84%E5%88%92%E6%A8%A1%E5%9E%8B%E6%B7%B1%E5%85%A5/</url>
    
    <content type="html"><![CDATA[<h2 id="一个例题"><a href="#一个例题" class="headerlink" title="一个例题"></a>一个例题</h2><p><img src="/2020/07/16/%E5%AD%A6%E4%B9%A0%E7%AC%94%E8%AE%B0-%E6%95%B0%E5%AD%A6%E8%A7%84%E5%88%92%E6%A8%A1%E5%9E%8B%E6%B7%B1%E5%85%A5/1.jpg" srcset="/img/loading.gif" alt></p><h3 id="第一小问"><a href="#第一小问" class="headerlink" title="第一小问"></a>第一小问</h3><p>第一小问比较好解决，典型的线性规划问题，列举出所有的切割模式（共7种）后，将第i种模式切割的原料钢管根数作为决策变量即可，唯一需要注意的是，约束条件不能是三种钢管个数恰好=(50,20,15)，而应该是&gt;=(50,20,15)，否则可能会造成无解。</p><h3 id="第二小问"><a href="#第二小问" class="headerlink" title="第二小问"></a>第二小问</h3><p>第二小问增加了一种需求和一个约束条件：5米10根；切割模式不超过3种。用枚举法确定合理切割模式较为复杂，因此不如将使用哪种模式也加入决策变量，让lingo自己解决这个问题。当然这需要一个人为的合理度量，此处选择为每根余料不超过3米，即如下附加约束条件：<br><img src="/2020/07/16/%E5%AD%A6%E4%B9%A0%E7%AC%94%E8%AE%B0-%E6%95%B0%E5%AD%A6%E8%A7%84%E5%88%92%E6%A8%A1%E5%9E%8B%E6%B7%B1%E5%85%A5/2.jpg" srcset="/img/loading.gif" alt></p><p>原本的线性约束条件也因此变成了未知量*未知量的非线性约束组合：<br><img src="/2020/07/16/%E5%AD%A6%E4%B9%A0%E7%AC%94%E8%AE%B0-%E6%95%B0%E5%AD%A6%E8%A7%84%E5%88%92%E6%A8%A1%E5%9E%8B%E6%B7%B1%E5%85%A5/3.jpg" srcset="/img/loading.gif" alt></p><p>还可以通过人为增加决策变量的约束减少计算量。</p><h2 id="一些小结"><a href="#一些小结" class="headerlink" title="一些小结"></a>一些小结</h2><h3 id="可能的解"><a href="#可能的解" class="headerlink" title="可能的解"></a>可能的解</h3><ol><li>全局最优解</li><li>局部最优解</li><li>中断解</li></ol><h3 id="基本类型"><a href="#基本类型" class="headerlink" title="基本类型"></a>基本类型</h3><ol><li>按照有无约束</li></ol><p>（1）约束优化（constrained optimization）</p><p>（2）无约束优化（unconstrained opt）</p><ol><li>按照决策变量x的分量取值</li></ol><p>（1）连续优化/数学规划（continuous opt / mathematical programming）</p><p>（2）离散优化/组合优化（discrete opt / combinatorial opt ）</p><ol><li>按照目标函数的个数</li></ol><p>单目标规划与多目标规划</p><ol><li>按照参数或者决策变量是否具有不确定性</li></ol><p>确定性规划与不确定性规划（如随机规划、模糊规划等）</p><ol><li>按照目标函数f，约束条件g、h是否连续可微</li></ol><p>光滑优化与非光滑优化</p>]]></content>
    
    
    <categories>
      
      <category>学习笔记</category>
      
      <category>数学建模</category>
      
    </categories>
    
    
    <tags>
      
      <tag>数学规划模型</tag>
      
    </tags>
    
  </entry>
  
  
  
  <entry>
    <title>[学习笔记]数学规划模型初识</title>
    <link href="/2020/07/16/%E5%AD%A6%E4%B9%A0%E7%AC%94%E8%AE%B0-%E6%95%B0%E5%AD%A6%E8%A7%84%E5%88%92%E6%A8%A1%E5%9E%8B%E5%88%9D%E8%AF%86/"/>
    <url>/2020/07/16/%E5%AD%A6%E4%B9%A0%E7%AC%94%E8%AE%B0-%E6%95%B0%E5%AD%A6%E8%A7%84%E5%88%92%E6%A8%A1%E5%9E%8B%E5%88%9D%E8%AF%86/</url>
    
    <content type="html"><![CDATA[<h2 id="数学规划模型的三要素"><a href="#数学规划模型的三要素" class="headerlink" title="数学规划模型的三要素"></a>数学规划模型的三要素</h2><ol><li>决策变量</li><li>目标函数</li><li>约束条件</li></ol><h2 id="0-1变量的运算特点"><a href="#0-1变量的运算特点" class="headerlink" title="0-1变量的运算特点"></a>0-1变量的运算特点</h2><p>在0-1变量中，<img src="/2020/07/16/%E5%AD%A6%E4%B9%A0%E7%AC%94%E8%AE%B0-%E6%95%B0%E5%AD%A6%E8%A7%84%E5%88%92%E6%A8%A1%E5%9E%8B%E5%88%9D%E8%AF%86/1.png" srcset="/img/loading.gif" alt>，两者互为充要条件，而在一般情形下，前者是后者的充分不必要条件。</p><p>0-1变量还可以描述约束条件（if-else）关系，<img src="/2020/07/16/%E5%AD%A6%E4%B9%A0%E7%AC%94%E8%AE%B0-%E6%95%B0%E5%AD%A6%E8%A7%84%E5%88%92%E6%A8%A1%E5%9E%8B%E5%88%9D%E8%AF%86/2.jpg" srcset="/img/loading.gif" alt>，如图例题所示。</p><h2 id="多目标规划模型的处理方法"><a href="#多目标规划模型的处理方法" class="headerlink" title="多目标规划模型的处理方法"></a>多目标规划模型的处理方法</h2><p>多目标规划下，往往这n个目标<strong>相互矛盾</strong>，其解决思路是转变多目标规划为单目标规划。</p><h3 id="方法一：按照目标的重要性分步求解"><a href="#方法一：按照目标的重要性分步求解" class="headerlink" title="方法一：按照目标的重要性分步求解"></a>方法一：按照目标的重要性分步求解</h3><p>如在选课策略模型中，任务要求选修课程最少，且学分尽量多，应学习哪些课程。首先认为选修课程最少为第一目标，在此基础上加入课程总门数的约束，再进行求解。</p><h4 id="缺点："><a href="#缺点：" class="headerlink" title="缺点："></a>缺点：</h4><p>如果有更多个目标，那么很难对目标的重要性进行排序。<br>即使排出顺序，也需要求解很多个单目标规划。<br>当第一个目标对应的单目标规划问题的最优解唯一时，后面的单目标规划丧失意义，并且对于整数规划，Lingo无法告诉我们最优解是否唯一。</p><h3 id="方法二：将多目标加权求和变为单目标"><a href="#方法二：将多目标加权求和变为单目标" class="headerlink" title="方法二：将多目标加权求和变为单目标"></a>方法二：将多目标加权求和变为单目标</h3><p>显然加权系数取决于该目标的重要性。</p><h4 id="缺点：-1"><a href="#缺点：-1" class="headerlink" title="缺点："></a>缺点：</h4><p>由于多个目标之间单位、数量级不一致，导致综合目标没有实际意义。<br>权重系数难以确定。</p><h4 id="注意点："><a href="#注意点：" class="headerlink" title="注意点："></a>注意点：</h4><p>在多个目标的方向不一致（max/min）时，如果综合目标是max，则需要将子目标是min的取相反数再综合。<br>权重还可以为函数，模型会变复杂，但稳健性提升了。</p>]]></content>
    
    
    <categories>
      
      <category>学习笔记</category>
      
      <category>数学建模</category>
      
    </categories>
    
    
    <tags>
      
      <tag>数学规划模型</tag>
      
    </tags>
    
  </entry>
  
  
  
  <entry>
    <title>[技术笔记]pandas中的逻辑运算符</title>
    <link href="/2020/07/14/%E6%8A%80%E6%9C%AF%E7%AC%94%E8%AE%B0-pandas%E4%B8%AD%E7%9A%84%E9%80%BB%E8%BE%91%E8%BF%90%E7%AE%97%E7%AC%A6/"/>
    <url>/2020/07/14/%E6%8A%80%E6%9C%AF%E7%AC%94%E8%AE%B0-pandas%E4%B8%AD%E7%9A%84%E9%80%BB%E8%BE%91%E8%BF%90%E7%AE%97%E7%AC%A6/</url>
    
    <content type="html"><![CDATA[<p>首先需要说明的是，在pandas中进行逻辑运算时，其运算符不再是<strong>and</strong>;<strong>or</strong>;<strong>not</strong>，转而变成了相对应的<strong>&amp;</strong>，<strong>|</strong>，<strong>～</strong>，<sup><a href="#fn_1" id="reffn_1">1</a></sup>如下列代码:</p><pre><code>In [129]: s = pd.Series(range(-3, 4)) In [132]: s[(s &lt; -1) | (s &gt; 0.5)] Out[132]:             0   -3            1   -2            4    1            5    2            6    3            dtype: int64 </code></pre><p>其原因是什么？查阅了网上的一些<a href="https://www.imooc.com/wenda/detail/567532" target="_blank" rel="noopener">资料</a>发现，是因为当我们使用and，or，not等运算符时，python自动将运算符两边的式子转换为bool类型再进行比较，而在pandas的Series、DataFrame以及numpy的array上，是没有bool值的，所以在元素级的操作上使用&amp;、|、～代替。</p><p>（题外话：当然更具体的我也不是很清楚，这有待后续学习了《流畅的python》后再验证，一想到github上就有电子版，我还傻乎乎花了一百多买了个新书我就很心痛）</p><p>值得注意的是，其<strong>元素符优先级</strong>也发生了改变，在pandas中，这类逻辑运算符优先级很高，因此运算符两侧最好时刻都<strong>加上括号</strong>，防止不必要的错误。比如：</p><pre><code>In[23]: army[(army.deaths &gt; 500) | (army.deaths &lt; 50)]Out[23]: regiment    company    deaths    battles    size    veterans    readiness    armored    desertersorigin                                    Arizona    Nighthawks    1st    523    5    1045    1    1    1    4Texas    Nighthawks    2nd    25    2    1099    62    3    1    31Florida    Nighthawks    2nd    616    2    1400    26    3    1    2Maine    Dragoons    1st    43    4    1592    73    2    0    3Alaska    Dragoons    2nd    523    8    987    949    2    0    24Louisana    Scouts    2nd    37    8    1099    63    2    1    2Georgia    Scouts    2nd    35    9    1523    345    3    1    3</code></pre><p>是正确的，而army[army.deaths &gt; 500 | army.deaths &lt; 50]则会报错：<em>ValueError: The truth value of a Series is ambiguous. Use a.empty, a.bool(), a.item(), a.any() or a.all().</em></p><h3 id="参考"><a href="#参考" class="headerlink" title="参考"></a>参考</h3><p><sup><a href="#fn_1" id="reffn_1">1</a></sup>： 来源：<a href="https://blog.csdn.net/claroja/article/details/65661826" target="_blank" rel="noopener">https://blog.csdn.net/claroja/article/details/65661826</a> </p>]]></content>
    
    
    <categories>
      
      <category>技术笔记</category>
      
      <category>python</category>
      
    </categories>
    
    
    <tags>
      
      <tag>逻辑运算符</tag>
      
    </tags>
    
  </entry>
  
  
  
  <entry>
    <title>[学习笔记]模型的灵敏度分析和稳健性分析方法</title>
    <link href="/2020/07/13/%E6%8A%80%E6%9C%AF%E7%AC%94%E8%AE%B0-%E6%A8%A1%E5%9E%8B%E7%9A%84%E7%81%B5%E6%95%8F%E5%BA%A6%E5%88%86%E6%9E%90%E5%92%8C%E7%A8%B3%E5%81%A5%E6%80%A7%E5%88%86%E6%9E%90%E6%96%B9%E6%B3%95/"/>
    <url>/2020/07/13/%E6%8A%80%E6%9C%AF%E7%AC%94%E8%AE%B0-%E6%A8%A1%E5%9E%8B%E7%9A%84%E7%81%B5%E6%95%8F%E5%BA%A6%E5%88%86%E6%9E%90%E5%92%8C%E7%A8%B3%E5%81%A5%E6%80%A7%E5%88%86%E6%9E%90%E6%96%B9%E6%B3%95/</url>
    
    <content type="html"><![CDATA[<p>在完成做出假设，用符号表示有关量，列出数学表达式，求解得到答案后，还需要对所得到的答案进行<em>灵敏度分析</em>和<em>稳健性分析</em>。本文旨在复习所学到的检验分析方法。</p><p><strong><em>灵敏度分析</em></strong>的意义在于，所得数据为测量值，与实际值可能存在差异，如果模型的输出对模型的输入很敏感，可能导致模型的偏误被放大，因此要对模型进行灵敏度分析。这让我联想到伍德里奇《计量经济学》第九章对于数据问题的再讨论，即解释变量的测量误差在CEV假定下，会对有误差的估计量造成衰减偏误，其他解释变量同样受到影响。</p><p>而<strong><em>稳健性分析</em></strong>在旨在放松假定，对更一般化的情况进行检验，毕竟假设往往线性、简单、理想化，可能与实际结果不符合。</p><h2 id="灵敏度分析"><a href="#灵敏度分析" class="headerlink" title="灵敏度分析"></a>灵敏度分析</h2><h3 id="方法一：数值法"><a href="#方法一：数值法" class="headerlink" title="方法一：数值法"></a>方法一：数值法</h3><p>对可能存在的误差大小进行估计，将观测值根据误差范围进行调整再输入模型，观察观测值的改变量大小对输出值改变量大小的影响（当然都是相对指标，一般以百分比衡量）。在输入时多参数的情况下，一般有两种思路：（1）只改变一个参数，保持其他参数不变，用来检验最不容易确定的参数；（2）改变若干参数，考察一组参数的稳定性，因为可能参数之间本就存在协同性。</p><h3 id="方法二：解析法"><a href="#方法二：解析法" class="headerlink" title="方法二：解析法"></a>方法二：解析法</h3><p>数值法是直接带入数据进行计算，而解析法则是通过对公式的分析，从数学模型上得到一个相对变化率，再带入数值检验，<strong>更加精确</strong>。如单输入-单输出情形下，变化率的求解就很简单。但其也存在其显而易见的缺点：在多输入-多输出情况下，<strong>获得精确的解析式非常困难</strong>；<strong>很多问题是离散的</strong>。</p><h2 id="稳健性分析"><a href="#稳健性分析" class="headerlink" title="稳健性分析"></a>稳健性分析</h2><p>在很多实际问题中，为了简单起见，我们往往会做出许多线性化的假设，同时也会将某些与时间有关的变量假设成与时间无关的常量，这使得得到的数学模型有很大的局限性。</p><p>对已有模型进行强健性分析是指将模型中线性化的假设改为更一般的非线性情形，同时将常量改为变量，然后重新分析、建模、求解。</p>]]></content>
    
    
    <categories>
      
      <category>学习笔记</category>
      
      <category>数学建模</category>
      
    </categories>
    
    
    <tags>
      
      <tag>灵敏度分析</tag>
      
      <tag>稳健性分析</tag>
      
    </tags>
    
  </entry>
  
  
  
  
</search>
